# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['StreamProcessorArgs', 'StreamProcessor']

@pulumi.input_type
class StreamProcessorArgs:
    def __init__(__self__, *,
                 pipeline: pulumi.Input[_builtins.str],
                 processor_name: pulumi.Input[_builtins.str],
                 project_id: pulumi.Input[_builtins.str],
                 delete_on_create_timeout: Optional[pulumi.Input[_builtins.bool]] = None,
                 instance_name: Optional[pulumi.Input[_builtins.str]] = None,
                 options: Optional[pulumi.Input['StreamProcessorOptionsArgs']] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None,
                 tier: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input['StreamProcessorTimeoutsArgs']] = None,
                 workspace_name: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The set of arguments for constructing a StreamProcessor resource.
        :param pulumi.Input[_builtins.str] pipeline: Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        :param pulumi.Input[_builtins.str] processor_name: Label that identifies the stream processor.
        :param pulumi.Input[_builtins.str] project_id: Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        :param pulumi.Input[_builtins.bool] delete_on_create_timeout: Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        :param pulumi.Input[_builtins.str] instance_name: Label that identifies the stream processing workspace.
        :param pulumi.Input['StreamProcessorOptionsArgs'] options: Optional configuration for the stream processor.
        :param pulumi.Input[_builtins.str] state: The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
               
               **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        :param pulumi.Input[_builtins.str] tier: Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        :param pulumi.Input[_builtins.str] workspace_name: Label that identifies the stream processing workspace.
        """
        pulumi.set(__self__, "pipeline", pipeline)
        pulumi.set(__self__, "processor_name", processor_name)
        pulumi.set(__self__, "project_id", project_id)
        if delete_on_create_timeout is not None:
            pulumi.set(__self__, "delete_on_create_timeout", delete_on_create_timeout)
        if instance_name is not None:
            warnings.warn("""This parameter is deprecated. Please transition to workspace_name.""", DeprecationWarning)
            pulumi.log.warn("""instance_name is deprecated: This parameter is deprecated. Please transition to workspace_name.""")
        if instance_name is not None:
            pulumi.set(__self__, "instance_name", instance_name)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if tier is not None:
            pulumi.set(__self__, "tier", tier)
        if timeouts is not None:
            pulumi.set(__self__, "timeouts", timeouts)
        if workspace_name is not None:
            pulumi.set(__self__, "workspace_name", workspace_name)

    @_builtins.property
    @pulumi.getter
    def pipeline(self) -> pulumi.Input[_builtins.str]:
        """
        Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        """
        return pulumi.get(self, "pipeline")

    @pipeline.setter
    def pipeline(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "pipeline", value)

    @_builtins.property
    @pulumi.getter(name="processorName")
    def processor_name(self) -> pulumi.Input[_builtins.str]:
        """
        Label that identifies the stream processor.
        """
        return pulumi.get(self, "processor_name")

    @processor_name.setter
    def processor_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "processor_name", value)

    @_builtins.property
    @pulumi.getter(name="projectId")
    def project_id(self) -> pulumi.Input[_builtins.str]:
        """
        Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        """
        return pulumi.get(self, "project_id")

    @project_id.setter
    def project_id(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "project_id", value)

    @_builtins.property
    @pulumi.getter(name="deleteOnCreateTimeout")
    def delete_on_create_timeout(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        """
        return pulumi.get(self, "delete_on_create_timeout")

    @delete_on_create_timeout.setter
    def delete_on_create_timeout(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "delete_on_create_timeout", value)

    @_builtins.property
    @pulumi.getter(name="instanceName")
    @_utilities.deprecated("""This parameter is deprecated. Please transition to workspace_name.""")
    def instance_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "instance_name")

    @instance_name.setter
    def instance_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "instance_name", value)

    @_builtins.property
    @pulumi.getter
    def options(self) -> Optional[pulumi.Input['StreamProcessorOptionsArgs']]:
        """
        Optional configuration for the stream processor.
        """
        return pulumi.get(self, "options")

    @options.setter
    def options(self, value: Optional[pulumi.Input['StreamProcessorOptionsArgs']]):
        pulumi.set(self, "options", value)

    @_builtins.property
    @pulumi.getter
    def state(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 

        **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "state", value)

    @_builtins.property
    @pulumi.getter
    def tier(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        """
        return pulumi.get(self, "tier")

    @tier.setter
    def tier(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "tier", value)

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> Optional[pulumi.Input['StreamProcessorTimeoutsArgs']]:
        return pulumi.get(self, "timeouts")

    @timeouts.setter
    def timeouts(self, value: Optional[pulumi.Input['StreamProcessorTimeoutsArgs']]):
        pulumi.set(self, "timeouts", value)

    @_builtins.property
    @pulumi.getter(name="workspaceName")
    def workspace_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "workspace_name")

    @workspace_name.setter
    def workspace_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "workspace_name", value)


@pulumi.input_type
class _StreamProcessorState:
    def __init__(__self__, *,
                 delete_on_create_timeout: Optional[pulumi.Input[_builtins.bool]] = None,
                 instance_name: Optional[pulumi.Input[_builtins.str]] = None,
                 options: Optional[pulumi.Input['StreamProcessorOptionsArgs']] = None,
                 pipeline: Optional[pulumi.Input[_builtins.str]] = None,
                 processor_name: Optional[pulumi.Input[_builtins.str]] = None,
                 project_id: Optional[pulumi.Input[_builtins.str]] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None,
                 stats: Optional[pulumi.Input[_builtins.str]] = None,
                 tier: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input['StreamProcessorTimeoutsArgs']] = None,
                 workspace_name: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Input properties used for looking up and filtering StreamProcessor resources.
        :param pulumi.Input[_builtins.bool] delete_on_create_timeout: Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        :param pulumi.Input[_builtins.str] instance_name: Label that identifies the stream processing workspace.
        :param pulumi.Input['StreamProcessorOptionsArgs'] options: Optional configuration for the stream processor.
        :param pulumi.Input[_builtins.str] pipeline: Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        :param pulumi.Input[_builtins.str] processor_name: Label that identifies the stream processor.
        :param pulumi.Input[_builtins.str] project_id: Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        :param pulumi.Input[_builtins.str] state: The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
               
               **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        :param pulumi.Input[_builtins.str] stats: The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        :param pulumi.Input[_builtins.str] tier: Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        :param pulumi.Input[_builtins.str] workspace_name: Label that identifies the stream processing workspace.
        """
        if delete_on_create_timeout is not None:
            pulumi.set(__self__, "delete_on_create_timeout", delete_on_create_timeout)
        if instance_name is not None:
            warnings.warn("""This parameter is deprecated. Please transition to workspace_name.""", DeprecationWarning)
            pulumi.log.warn("""instance_name is deprecated: This parameter is deprecated. Please transition to workspace_name.""")
        if instance_name is not None:
            pulumi.set(__self__, "instance_name", instance_name)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if pipeline is not None:
            pulumi.set(__self__, "pipeline", pipeline)
        if processor_name is not None:
            pulumi.set(__self__, "processor_name", processor_name)
        if project_id is not None:
            pulumi.set(__self__, "project_id", project_id)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if stats is not None:
            pulumi.set(__self__, "stats", stats)
        if tier is not None:
            pulumi.set(__self__, "tier", tier)
        if timeouts is not None:
            pulumi.set(__self__, "timeouts", timeouts)
        if workspace_name is not None:
            pulumi.set(__self__, "workspace_name", workspace_name)

    @_builtins.property
    @pulumi.getter(name="deleteOnCreateTimeout")
    def delete_on_create_timeout(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        """
        return pulumi.get(self, "delete_on_create_timeout")

    @delete_on_create_timeout.setter
    def delete_on_create_timeout(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "delete_on_create_timeout", value)

    @_builtins.property
    @pulumi.getter(name="instanceName")
    @_utilities.deprecated("""This parameter is deprecated. Please transition to workspace_name.""")
    def instance_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "instance_name")

    @instance_name.setter
    def instance_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "instance_name", value)

    @_builtins.property
    @pulumi.getter
    def options(self) -> Optional[pulumi.Input['StreamProcessorOptionsArgs']]:
        """
        Optional configuration for the stream processor.
        """
        return pulumi.get(self, "options")

    @options.setter
    def options(self, value: Optional[pulumi.Input['StreamProcessorOptionsArgs']]):
        pulumi.set(self, "options", value)

    @_builtins.property
    @pulumi.getter
    def pipeline(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        """
        return pulumi.get(self, "pipeline")

    @pipeline.setter
    def pipeline(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "pipeline", value)

    @_builtins.property
    @pulumi.getter(name="processorName")
    def processor_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Label that identifies the stream processor.
        """
        return pulumi.get(self, "processor_name")

    @processor_name.setter
    def processor_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "processor_name", value)

    @_builtins.property
    @pulumi.getter(name="projectId")
    def project_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        """
        return pulumi.get(self, "project_id")

    @project_id.setter
    def project_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "project_id", value)

    @_builtins.property
    @pulumi.getter
    def state(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 

        **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        """
        return pulumi.get(self, "state")

    @state.setter
    def state(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "state", value)

    @_builtins.property
    @pulumi.getter
    def stats(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        """
        return pulumi.get(self, "stats")

    @stats.setter
    def stats(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "stats", value)

    @_builtins.property
    @pulumi.getter
    def tier(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        """
        return pulumi.get(self, "tier")

    @tier.setter
    def tier(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "tier", value)

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> Optional[pulumi.Input['StreamProcessorTimeoutsArgs']]:
        return pulumi.get(self, "timeouts")

    @timeouts.setter
    def timeouts(self, value: Optional[pulumi.Input['StreamProcessorTimeoutsArgs']]):
        pulumi.set(self, "timeouts", value)

    @_builtins.property
    @pulumi.getter(name="workspaceName")
    def workspace_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "workspace_name")

    @workspace_name.setter
    def workspace_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "workspace_name", value)


@pulumi.type_token("mongodbatlas:index/streamProcessor:StreamProcessor")
class StreamProcessor(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 delete_on_create_timeout: Optional[pulumi.Input[_builtins.bool]] = None,
                 instance_name: Optional[pulumi.Input[_builtins.str]] = None,
                 options: Optional[pulumi.Input[Union['StreamProcessorOptionsArgs', 'StreamProcessorOptionsArgsDict']]] = None,
                 pipeline: Optional[pulumi.Input[_builtins.str]] = None,
                 processor_name: Optional[pulumi.Input[_builtins.str]] = None,
                 project_id: Optional[pulumi.Input[_builtins.str]] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None,
                 tier: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input[Union['StreamProcessorTimeoutsArgs', 'StreamProcessorTimeoutsArgsDict']]] = None,
                 workspace_name: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        """
        `StreamProcessor` provides a Stream Processor resource. The resource lets you create, delete, import, start and stop a stream processor in a stream instance.

        **NOTE**: When updating an Atlas Stream Processor, the following behavior applies:
        1. If the processor is in a `STARTED` state, it will automatically be stopped before the update is applied
        2. The update will be performed while the processor is in `STOPPED` state
        3. If the processor was originally in `STARTED` state, it will be restarted after the update

        ## Example Usage

        ### S

        ```python
        import pulumi
        import json
        import pulumi_mongodbatlas as mongodbatlas

        example = mongodbatlas.StreamInstance("example",
            project_id=project_id,
            instance_name="InstanceName",
            data_process_region={
                "region": "VIRGINIA_USA",
                "cloud_provider": "AWS",
            })
        example_sample = mongodbatlas.StreamConnection("example-sample",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="sample_stream_solar",
            type="Sample")
        example_cluster = mongodbatlas.StreamConnection("example-cluster",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="ClusterConnection",
            type="Cluster",
            cluster_name=cluster_name,
            db_role_to_execute={
                "role": "atlasAdmin",
                "type": "BUILT_IN",
            })
        example_kafka = mongodbatlas.StreamConnection("example-kafka",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="KafkaPlaintextConnection",
            type="Kafka",
            authentication={
                "mechanism": "PLAIN",
                "username": kafka_username,
                "password": kafka_password,
            },
            bootstrap_servers="localhost:9092,localhost:9092",
            config={
                "auto.offset.reset": "earliest",
            },
            security={
                "protocol": "SASL_PLAINTEXT",
            })
        stream_processor_sample_example = mongodbatlas.StreamProcessor("stream-processor-sample-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="sampleProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-sample"]["connectionName"],
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                        "db": "sample",
                        "coll": "solar",
                        "timeseries": {
                            "timeField": "_ts",
                        },
                    },
                },
            ]),
            state="STARTED",
            tier="SP30")
        stream_processor_cluster_to_kafka_example = mongodbatlas.StreamProcessor("stream-processor-cluster-to-kafka-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="clusterProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-kafka"]["connectionName"],
                        "topic": "topic_from_cluster",
                    },
                },
            ]),
            state="CREATED")
        stream_processor_kafka_to_cluster_example = mongodbatlas.StreamProcessor("stream-processor-kafka-to-cluster-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="kafkaProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-kafka"]["connectionName"],
                        "topic": "topic_source",
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                        "db": "kafka",
                        "coll": "topic_source",
                        "timeseries": {
                            "timeField": "ts",
                        },
                    },
                },
            ]),
            state="CREATED",
            options={
                "dlq": {
                    "coll": "exampleColumn",
                    "connection_name": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                    "db": "exampleDb",
                },
            })
        example_stream_processors = example.instance_name.apply(lambda instance_name: mongodbatlas.get_stream_processors_output(project_id=project_id,
            workspace_name=instance_name))
        example_stream_processor = pulumi.Output.all(
            instance_name=example.instance_name,
            processor_name=stream_processor_sample_example.processor_name
        ).apply(lambda resolved_outputs: mongodbatlas.get_stream_processor_output(project_id=project_id,
            workspace_name=resolved_outputs['instance_name'],
            processor_name=resolved_outputs['processor_name']))

        pulumi.export("streamProcessorsState", example_stream_processor.state)
        pulumi.export("streamProcessorsResults", example_stream_processors.results)
        ```

        ### Further Examples
        - Atlas Stream Processor

        ## Import

        Stream Processor resource can be imported using the Project ID, Stream Instance name and Stream Processor name, in the format `INSTANCE_NAME-PROJECT_ID-PROCESSOR_NAME`, e.g.

        For more information see: [MongoDB Atlas API - Stream Processor](https://www.mongodb.com/docs/api/doc/atlas-admin-api-v2/operation/operation-createstreamprocessor) Documentation.

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[_builtins.bool] delete_on_create_timeout: Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        :param pulumi.Input[_builtins.str] instance_name: Label that identifies the stream processing workspace.
        :param pulumi.Input[Union['StreamProcessorOptionsArgs', 'StreamProcessorOptionsArgsDict']] options: Optional configuration for the stream processor.
        :param pulumi.Input[_builtins.str] pipeline: Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        :param pulumi.Input[_builtins.str] processor_name: Label that identifies the stream processor.
        :param pulumi.Input[_builtins.str] project_id: Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        :param pulumi.Input[_builtins.str] state: The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
               
               **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        :param pulumi.Input[_builtins.str] tier: Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        :param pulumi.Input[_builtins.str] workspace_name: Label that identifies the stream processing workspace.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: StreamProcessorArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        `StreamProcessor` provides a Stream Processor resource. The resource lets you create, delete, import, start and stop a stream processor in a stream instance.

        **NOTE**: When updating an Atlas Stream Processor, the following behavior applies:
        1. If the processor is in a `STARTED` state, it will automatically be stopped before the update is applied
        2. The update will be performed while the processor is in `STOPPED` state
        3. If the processor was originally in `STARTED` state, it will be restarted after the update

        ## Example Usage

        ### S

        ```python
        import pulumi
        import json
        import pulumi_mongodbatlas as mongodbatlas

        example = mongodbatlas.StreamInstance("example",
            project_id=project_id,
            instance_name="InstanceName",
            data_process_region={
                "region": "VIRGINIA_USA",
                "cloud_provider": "AWS",
            })
        example_sample = mongodbatlas.StreamConnection("example-sample",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="sample_stream_solar",
            type="Sample")
        example_cluster = mongodbatlas.StreamConnection("example-cluster",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="ClusterConnection",
            type="Cluster",
            cluster_name=cluster_name,
            db_role_to_execute={
                "role": "atlasAdmin",
                "type": "BUILT_IN",
            })
        example_kafka = mongodbatlas.StreamConnection("example-kafka",
            project_id=project_id,
            workspace_name=example.instance_name,
            connection_name="KafkaPlaintextConnection",
            type="Kafka",
            authentication={
                "mechanism": "PLAIN",
                "username": kafka_username,
                "password": kafka_password,
            },
            bootstrap_servers="localhost:9092,localhost:9092",
            config={
                "auto.offset.reset": "earliest",
            },
            security={
                "protocol": "SASL_PLAINTEXT",
            })
        stream_processor_sample_example = mongodbatlas.StreamProcessor("stream-processor-sample-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="sampleProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-sample"]["connectionName"],
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                        "db": "sample",
                        "coll": "solar",
                        "timeseries": {
                            "timeField": "_ts",
                        },
                    },
                },
            ]),
            state="STARTED",
            tier="SP30")
        stream_processor_cluster_to_kafka_example = mongodbatlas.StreamProcessor("stream-processor-cluster-to-kafka-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="clusterProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-kafka"]["connectionName"],
                        "topic": "topic_from_cluster",
                    },
                },
            ]),
            state="CREATED")
        stream_processor_kafka_to_cluster_example = mongodbatlas.StreamProcessor("stream-processor-kafka-to-cluster-example",
            project_id=project_id,
            workspace_name=example.instance_name,
            processor_name="kafkaProcessorName",
            pipeline=json.dumps([
                {
                    "$source": {
                        "connectionName": mongodbatlas_stream_connection["example-kafka"]["connectionName"],
                        "topic": "topic_source",
                    },
                },
                {
                    "$emit": {
                        "connectionName": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                        "db": "kafka",
                        "coll": "topic_source",
                        "timeseries": {
                            "timeField": "ts",
                        },
                    },
                },
            ]),
            state="CREATED",
            options={
                "dlq": {
                    "coll": "exampleColumn",
                    "connection_name": mongodbatlas_stream_connection["example-cluster"]["connectionName"],
                    "db": "exampleDb",
                },
            })
        example_stream_processors = example.instance_name.apply(lambda instance_name: mongodbatlas.get_stream_processors_output(project_id=project_id,
            workspace_name=instance_name))
        example_stream_processor = pulumi.Output.all(
            instance_name=example.instance_name,
            processor_name=stream_processor_sample_example.processor_name
        ).apply(lambda resolved_outputs: mongodbatlas.get_stream_processor_output(project_id=project_id,
            workspace_name=resolved_outputs['instance_name'],
            processor_name=resolved_outputs['processor_name']))

        pulumi.export("streamProcessorsState", example_stream_processor.state)
        pulumi.export("streamProcessorsResults", example_stream_processors.results)
        ```

        ### Further Examples
        - Atlas Stream Processor

        ## Import

        Stream Processor resource can be imported using the Project ID, Stream Instance name and Stream Processor name, in the format `INSTANCE_NAME-PROJECT_ID-PROCESSOR_NAME`, e.g.

        For more information see: [MongoDB Atlas API - Stream Processor](https://www.mongodb.com/docs/api/doc/atlas-admin-api-v2/operation/operation-createstreamprocessor) Documentation.

        :param str resource_name: The name of the resource.
        :param StreamProcessorArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(StreamProcessorArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 delete_on_create_timeout: Optional[pulumi.Input[_builtins.bool]] = None,
                 instance_name: Optional[pulumi.Input[_builtins.str]] = None,
                 options: Optional[pulumi.Input[Union['StreamProcessorOptionsArgs', 'StreamProcessorOptionsArgsDict']]] = None,
                 pipeline: Optional[pulumi.Input[_builtins.str]] = None,
                 processor_name: Optional[pulumi.Input[_builtins.str]] = None,
                 project_id: Optional[pulumi.Input[_builtins.str]] = None,
                 state: Optional[pulumi.Input[_builtins.str]] = None,
                 tier: Optional[pulumi.Input[_builtins.str]] = None,
                 timeouts: Optional[pulumi.Input[Union['StreamProcessorTimeoutsArgs', 'StreamProcessorTimeoutsArgsDict']]] = None,
                 workspace_name: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = StreamProcessorArgs.__new__(StreamProcessorArgs)

            __props__.__dict__["delete_on_create_timeout"] = delete_on_create_timeout
            __props__.__dict__["instance_name"] = instance_name
            __props__.__dict__["options"] = options
            if pipeline is None and not opts.urn:
                raise TypeError("Missing required property 'pipeline'")
            __props__.__dict__["pipeline"] = pipeline
            if processor_name is None and not opts.urn:
                raise TypeError("Missing required property 'processor_name'")
            __props__.__dict__["processor_name"] = processor_name
            if project_id is None and not opts.urn:
                raise TypeError("Missing required property 'project_id'")
            __props__.__dict__["project_id"] = project_id
            __props__.__dict__["state"] = state
            __props__.__dict__["tier"] = tier
            __props__.__dict__["timeouts"] = timeouts
            __props__.__dict__["workspace_name"] = workspace_name
            __props__.__dict__["stats"] = None
        super(StreamProcessor, __self__).__init__(
            'mongodbatlas:index/streamProcessor:StreamProcessor',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            delete_on_create_timeout: Optional[pulumi.Input[_builtins.bool]] = None,
            instance_name: Optional[pulumi.Input[_builtins.str]] = None,
            options: Optional[pulumi.Input[Union['StreamProcessorOptionsArgs', 'StreamProcessorOptionsArgsDict']]] = None,
            pipeline: Optional[pulumi.Input[_builtins.str]] = None,
            processor_name: Optional[pulumi.Input[_builtins.str]] = None,
            project_id: Optional[pulumi.Input[_builtins.str]] = None,
            state: Optional[pulumi.Input[_builtins.str]] = None,
            stats: Optional[pulumi.Input[_builtins.str]] = None,
            tier: Optional[pulumi.Input[_builtins.str]] = None,
            timeouts: Optional[pulumi.Input[Union['StreamProcessorTimeoutsArgs', 'StreamProcessorTimeoutsArgsDict']]] = None,
            workspace_name: Optional[pulumi.Input[_builtins.str]] = None) -> 'StreamProcessor':
        """
        Get an existing StreamProcessor resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[_builtins.bool] delete_on_create_timeout: Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        :param pulumi.Input[_builtins.str] instance_name: Label that identifies the stream processing workspace.
        :param pulumi.Input[Union['StreamProcessorOptionsArgs', 'StreamProcessorOptionsArgsDict']] options: Optional configuration for the stream processor.
        :param pulumi.Input[_builtins.str] pipeline: Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        :param pulumi.Input[_builtins.str] processor_name: Label that identifies the stream processor.
        :param pulumi.Input[_builtins.str] project_id: Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        :param pulumi.Input[_builtins.str] state: The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
               
               **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        :param pulumi.Input[_builtins.str] stats: The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        :param pulumi.Input[_builtins.str] tier: Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        :param pulumi.Input[_builtins.str] workspace_name: Label that identifies the stream processing workspace.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _StreamProcessorState.__new__(_StreamProcessorState)

        __props__.__dict__["delete_on_create_timeout"] = delete_on_create_timeout
        __props__.__dict__["instance_name"] = instance_name
        __props__.__dict__["options"] = options
        __props__.__dict__["pipeline"] = pipeline
        __props__.__dict__["processor_name"] = processor_name
        __props__.__dict__["project_id"] = project_id
        __props__.__dict__["state"] = state
        __props__.__dict__["stats"] = stats
        __props__.__dict__["tier"] = tier
        __props__.__dict__["timeouts"] = timeouts
        __props__.__dict__["workspace_name"] = workspace_name
        return StreamProcessor(resource_name, opts=opts, __props__=__props__)

    @_builtins.property
    @pulumi.getter(name="deleteOnCreateTimeout")
    def delete_on_create_timeout(self) -> pulumi.Output[_builtins.bool]:
        """
        Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
        """
        return pulumi.get(self, "delete_on_create_timeout")

    @_builtins.property
    @pulumi.getter(name="instanceName")
    @_utilities.deprecated("""This parameter is deprecated. Please transition to workspace_name.""")
    def instance_name(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "instance_name")

    @_builtins.property
    @pulumi.getter
    def options(self) -> pulumi.Output[Optional['outputs.StreamProcessorOptions']]:
        """
        Optional configuration for the stream processor.
        """
        return pulumi.get(self, "options")

    @_builtins.property
    @pulumi.getter
    def pipeline(self) -> pulumi.Output[_builtins.str]:
        """
        Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        """
        return pulumi.get(self, "pipeline")

    @_builtins.property
    @pulumi.getter(name="processorName")
    def processor_name(self) -> pulumi.Output[_builtins.str]:
        """
        Label that identifies the stream processor.
        """
        return pulumi.get(self, "processor_name")

    @_builtins.property
    @pulumi.getter(name="projectId")
    def project_id(self) -> pulumi.Output[_builtins.str]:
        """
        Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        """
        return pulumi.get(self, "project_id")

    @_builtins.property
    @pulumi.getter
    def state(self) -> pulumi.Output[_builtins.str]:
        """
        The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 

        **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        """
        return pulumi.get(self, "state")

    @_builtins.property
    @pulumi.getter
    def stats(self) -> pulumi.Output[_builtins.str]:
        """
        The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        """
        return pulumi.get(self, "stats")

    @_builtins.property
    @pulumi.getter
    def tier(self) -> pulumi.Output[_builtins.str]:
        """
        Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
        """
        return pulumi.get(self, "tier")

    @_builtins.property
    @pulumi.getter
    def timeouts(self) -> pulumi.Output[Optional['outputs.StreamProcessorTimeouts']]:
        return pulumi.get(self, "timeouts")

    @_builtins.property
    @pulumi.getter(name="workspaceName")
    def workspace_name(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Label that identifies the stream processing workspace.
        """
        return pulumi.get(self, "workspace_name")

