// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.mongodbatlas;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.mongodbatlas.AdvancedClusterArgs;
import com.pulumi.mongodbatlas.Utilities;
import com.pulumi.mongodbatlas.inputs.AdvancedClusterState;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterAdvancedConfiguration;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterBiConnectorConfig;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterConnectionString;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterLabel;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterPinnedFcv;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterReplicationSpec;
import com.pulumi.mongodbatlas.outputs.AdvancedClusterTag;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.String;
import java.util.List;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * ## Example Usage
 * 
 * ### Example single provider and single region
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var test = new AdvancedCluster("test", AdvancedClusterArgs.builder()
 *             .projectId("PROJECT ID")
 *             .name("NAME OF CLUSTER")
 *             .clusterType("REPLICASET")
 *             .replicationSpecs(AdvancedClusterReplicationSpecArgs.builder()
 *                 .regionConfigs(AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                     .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                         .instanceSize("M10")
 *                         .nodeCount(3)
 *                         .build())
 *                     .analyticsSpecs(AdvancedClusterReplicationSpecRegionConfigAnalyticsSpecsArgs.builder()
 *                         .instanceSize("M10")
 *                         .nodeCount(1)
 *                         .build())
 *                     .providerName("AWS")
 *                     .priority(7)
 *                     .regionName("US_EAST_1")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ### Example Tenant Cluster
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var test = new AdvancedCluster("test", AdvancedClusterArgs.builder()
 *             .projectId("PROJECT ID")
 *             .name("NAME OF CLUSTER")
 *             .clusterType("REPLICASET")
 *             .replicationSpecs(AdvancedClusterReplicationSpecArgs.builder()
 *                 .regionConfigs(AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                     .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                         .instanceSize("M0")
 *                         .build())
 *                     .providerName("TENANT")
 *                     .backingProviderName("AWS")
 *                     .regionName("US_EAST_1")
 *                     .priority(7)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * **NOTE:** There can only be one M0 cluster per project.
 * 
 * **NOTE**: Upgrading the shared tier is supported. Any change from a shared tier cluster (a tenant) to a different instance size will be considered a tenant upgrade. When upgrading from the shared tier, change the `provider_name` from &#34;TENANT&#34; to your preferred provider (AWS, GCP or Azure) and remove the variable `backing_provider_name`.  See the Example Tenant Cluster Upgrade below. You can upgrade a shared tier cluster only to a single provider on an M10-tier cluster or greater.
 * 
 * When upgrading from the shared tier, *only* the upgrade changes will be applied. This helps avoid a corrupt state file in the event that the upgrade succeeds but subsequent updates fail within the same `pulumi up`. To apply additional cluster changes, run a secondary `pulumi up` after the upgrade succeeds.
 * 
 * ### Example Tenant Cluster Upgrade
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var test = new AdvancedCluster("test", AdvancedClusterArgs.builder()
 *             .projectId("PROJECT ID")
 *             .name("NAME OF CLUSTER")
 *             .clusterType("REPLICASET")
 *             .replicationSpecs(AdvancedClusterReplicationSpecArgs.builder()
 *                 .regionConfigs(AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                     .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                         .instanceSize("M10")
 *                         .build())
 *                     .providerName("AWS")
 *                     .regionName("US_EAST_1")
 *                     .priority(7)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ### Example Multi-Cloud Cluster
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var test = new AdvancedCluster("test", AdvancedClusterArgs.builder()
 *             .projectId("PROJECT ID")
 *             .name("NAME OF CLUSTER")
 *             .clusterType("REPLICASET")
 *             .replicationSpecs(AdvancedClusterReplicationSpecArgs.builder()
 *                 .regionConfigs(                
 *                     AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                         .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                             .instanceSize("M10")
 *                             .nodeCount(3)
 *                             .build())
 *                         .analyticsSpecs(AdvancedClusterReplicationSpecRegionConfigAnalyticsSpecsArgs.builder()
 *                             .instanceSize("M10")
 *                             .nodeCount(1)
 *                             .build())
 *                         .providerName("AWS")
 *                         .priority(7)
 *                         .regionName("US_EAST_1")
 *                         .build(),
 *                     AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                         .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                             .instanceSize("M10")
 *                             .nodeCount(2)
 *                             .build())
 *                         .providerName("GCP")
 *                         .priority(6)
 *                         .regionName("NORTH_AMERICA_NORTHEAST_1")
 *                         .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * ### Example of a Multi Cloud Sharded Cluster with 2 shards
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterAdvancedConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var cluster = new AdvancedCluster("cluster", AdvancedClusterArgs.builder()
 *             .projectId(project.id())
 *             .name(clusterName)
 *             .clusterType("SHARDED")
 *             .backupEnabled(true)
 *             .replicationSpecs(            
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("US_EAST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("US_EAST_2")
 *                             .build())
 *                     .build(),
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("US_EAST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("US_EAST_2")
 *                             .build())
 *                     .build())
 *             .advancedConfiguration(AdvancedClusterAdvancedConfigurationArgs.builder()
 *                 .javascriptEnabled(true)
 *                 .oplogSizeMb(991)
 *                 .sampleRefreshIntervalBiConnector(300)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ### Example of a Global Cluster with 2 zones
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.mongodbatlas.AdvancedCluster;
 * import com.pulumi.mongodbatlas.AdvancedClusterArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterReplicationSpecArgs;
 * import com.pulumi.mongodbatlas.inputs.AdvancedClusterAdvancedConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var cluster = new AdvancedCluster("cluster", AdvancedClusterArgs.builder()
 *             .projectId(project.id())
 *             .name(clusterName)
 *             .clusterType("GEOSHARDED")
 *             .backupEnabled(true)
 *             .replicationSpecs(            
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .zoneName("zone n1")
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("US_EAST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("US_EAST_2")
 *                             .build())
 *                     .build(),
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .zoneName("zone n1")
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("US_EAST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("US_EAST_2")
 *                             .build())
 *                     .build(),
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .zoneName("zone n2")
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("EU_WEST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("EUROPE_NORTH")
 *                             .build())
 *                     .build(),
 *                 AdvancedClusterReplicationSpecArgs.builder()
 *                     .zoneName("zone n2")
 *                     .regionConfigs(                    
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(3)
 *                                 .build())
 *                             .providerName("AWS")
 *                             .priority(7)
 *                             .regionName("EU_WEST_1")
 *                             .build(),
 *                         AdvancedClusterReplicationSpecRegionConfigArgs.builder()
 *                             .electableSpecs(AdvancedClusterReplicationSpecRegionConfigElectableSpecsArgs.builder()
 *                                 .instanceSize("M30")
 *                                 .nodeCount(2)
 *                                 .build())
 *                             .providerName("AZURE")
 *                             .priority(6)
 *                             .regionName("EUROPE_NORTH")
 *                             .build())
 *                     .build())
 *             .advancedConfiguration(AdvancedClusterAdvancedConfigurationArgs.builder()
 *                 .javascriptEnabled(true)
 *                 .oplogSizeMb(999)
 *                 .sampleRefreshIntervalBiConnector(300)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ### Example - Return a Connection String
 * Standard
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         ctx.export("standard", cluster.connectionStrings()[0].standard());
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * Standard srv
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         ctx.export("standardSrv", cluster.connectionStrings()[0].standardSrv());
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * Private with Network peering and Custom DNS AWS enabled
 * ## Import
 * 
 * Clusters can be imported using project ID and cluster name, in the format `PROJECTID-CLUSTERNAME`, e.g.
 * 
 * ```sh
 * $ pulumi import mongodbatlas:index/advancedCluster:AdvancedCluster my_cluster 1112222b3bf99403840e8934-Cluster0
 * ```
 * See detailed information for arguments and attributes: [MongoDB API Advanced Clusters](https://docs.atlas.mongodb.com/reference/api/cluster-advanced/create-one-cluster-advanced/)
 * 
 * ~&gt; __IMPORTANT:__
 * \n\n &amp;#8226; When a cluster is imported, the resulting schema structure will always return the new schema including `replication_specs` per independent shards of the cluster.
 * \n\n &amp;#8226;  Note: The first time `pulumi up` command is run __after__ updating the configuration of an imported cluster, you may receive a `500 Internal Server Error (Error code: &#34;SERVICE_UNAVAILABLE&#34;)` error. This is a known temporary issue. If you encounter this, please re-run `pulumi up` and this time the update should succeed.
 * 
 */
@ResourceType(type="mongodbatlas:index/advancedCluster:AdvancedCluster")
public class AdvancedCluster extends com.pulumi.resources.CustomResource {
    /**
     * If reconfiguration is necessary to regain a primary due to a regional outage, submit this field alongside your topology reconfiguration to request a new regional outage resistant topology. Forced reconfigurations during an outage of the majority of electable nodes carry a risk of data loss if replicated writes (even majority committed writes) have not been replicated to the new primary node. MongoDB Atlas docs contain more information. To proceed with an operation which carries that risk, set `accept_data_risks_and_force_replica_set_reconfig` to the current date. Learn more about Reconfiguring a Replica Set during a regional outage [here](https://dochub.mongodb.org/core/regional-outage-reconfigure-replica-set).
     * 
     */
    @Export(name="acceptDataRisksAndForceReplicaSetReconfig", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> acceptDataRisksAndForceReplicaSetReconfig;

    /**
     * @return If reconfiguration is necessary to regain a primary due to a regional outage, submit this field alongside your topology reconfiguration to request a new regional outage resistant topology. Forced reconfigurations during an outage of the majority of electable nodes carry a risk of data loss if replicated writes (even majority committed writes) have not been replicated to the new primary node. MongoDB Atlas docs contain more information. To proceed with an operation which carries that risk, set `accept_data_risks_and_force_replica_set_reconfig` to the current date. Learn more about Reconfiguring a Replica Set during a regional outage [here](https://dochub.mongodb.org/core/regional-outage-reconfigure-replica-set).
     * 
     */
    public Output<Optional<String>> acceptDataRisksAndForceReplicaSetReconfig() {
        return Codegen.optional(this.acceptDataRisksAndForceReplicaSetReconfig);
    }
    @Export(name="advancedConfiguration", refs={AdvancedClusterAdvancedConfiguration.class}, tree="[0]")
    private Output<AdvancedClusterAdvancedConfiguration> advancedConfiguration;

    public Output<AdvancedClusterAdvancedConfiguration> advancedConfiguration() {
        return this.advancedConfiguration;
    }
    /**
     * Flag that indicates whether the cluster can perform backups.
     * If `true`, the cluster can perform backups. You must set this value to `true` for NVMe clusters.
     * 
     * Backup uses:
     * [Cloud Backups](https://docs.atlas.mongodb.com/backup/cloud-backup/overview/#std-label-backup-cloud-provider) for dedicated clusters.
     * [Shared Cluster Backups](https://docs.atlas.mongodb.com/backup/shared-tier/overview/#std-label-m2-m5-snapshots) for tenant clusters.
     * If &#34;`backup_enabled`&#34; : `false`, the cluster doesn&#39;t use Atlas backups.
     * 
     * This parameter defaults to false.
     * 
     */
    @Export(name="backupEnabled", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> backupEnabled;

    /**
     * @return Flag that indicates whether the cluster can perform backups.
     * If `true`, the cluster can perform backups. You must set this value to `true` for NVMe clusters.
     * 
     * Backup uses:
     * [Cloud Backups](https://docs.atlas.mongodb.com/backup/cloud-backup/overview/#std-label-backup-cloud-provider) for dedicated clusters.
     * [Shared Cluster Backups](https://docs.atlas.mongodb.com/backup/shared-tier/overview/#std-label-m2-m5-snapshots) for tenant clusters.
     * If &#34;`backup_enabled`&#34; : `false`, the cluster doesn&#39;t use Atlas backups.
     * 
     * This parameter defaults to false.
     * 
     */
    public Output<Boolean> backupEnabled() {
        return this.backupEnabled;
    }
    /**
     * Configuration settings applied to BI Connector for Atlas on this cluster. The MongoDB Connector for Business Intelligence for Atlas (BI Connector) is only available for M10 and larger clusters. The BI Connector is a powerful tool which provides users SQL-based access to their MongoDB databases. As a result, the BI Connector performs operations which may be CPU and memory intensive. Given the limited hardware resources on M10 and M20 cluster tiers, you may experience performance degradation of the cluster when enabling the BI Connector. If this occurs, upgrade to an M30 or larger cluster or disable the BI Connector. See below.
     * 
     */
    @Export(name="biConnectorConfig", refs={AdvancedClusterBiConnectorConfig.class}, tree="[0]")
    private Output<AdvancedClusterBiConnectorConfig> biConnectorConfig;

    /**
     * @return Configuration settings applied to BI Connector for Atlas on this cluster. The MongoDB Connector for Business Intelligence for Atlas (BI Connector) is only available for M10 and larger clusters. The BI Connector is a powerful tool which provides users SQL-based access to their MongoDB databases. As a result, the BI Connector performs operations which may be CPU and memory intensive. Given the limited hardware resources on M10 and M20 cluster tiers, you may experience performance degradation of the cluster when enabling the BI Connector. If this occurs, upgrade to an M30 or larger cluster or disable the BI Connector. See below.
     * 
     */
    public Output<AdvancedClusterBiConnectorConfig> biConnectorConfig() {
        return this.biConnectorConfig;
    }
    /**
     * The cluster ID.
     * 
     */
    @Export(name="clusterId", refs={String.class}, tree="[0]")
    private Output<String> clusterId;

    /**
     * @return The cluster ID.
     * 
     */
    public Output<String> clusterId() {
        return this.clusterId;
    }
    /**
     * Type of the cluster that you want to create.
     * Accepted values include:
     * - `REPLICASET` Replica set
     * - `SHARDED`	Sharded cluster
     * - `GEOSHARDED` Global Cluster
     * 
     */
    @Export(name="clusterType", refs={String.class}, tree="[0]")
    private Output<String> clusterType;

    /**
     * @return Type of the cluster that you want to create.
     * Accepted values include:
     * - `REPLICASET` Replica set
     * - `SHARDED`	Sharded cluster
     * - `GEOSHARDED` Global Cluster
     * 
     */
    public Output<String> clusterType() {
        return this.clusterType;
    }
    /**
     * Config Server Management Mode for creating or updating a sharded cluster. Valid values are `ATLAS_MANAGED` (default) and `FIXED_TO_DEDICATED`. When configured as `ATLAS_MANAGED`, Atlas may automatically switch the cluster&#39;s config server type for optimal performance and savings. When configured as `FIXED_TO_DEDICATED`, the cluster will always use a dedicated config server. To learn more, see the [Sharded Cluster Config Servers documentation](https://dochub.mongodb.org/docs/manual/core/sharded-cluster-config-servers/).
     * 
     */
    @Export(name="configServerManagementMode", refs={String.class}, tree="[0]")
    private Output<String> configServerManagementMode;

    /**
     * @return Config Server Management Mode for creating or updating a sharded cluster. Valid values are `ATLAS_MANAGED` (default) and `FIXED_TO_DEDICATED`. When configured as `ATLAS_MANAGED`, Atlas may automatically switch the cluster&#39;s config server type for optimal performance and savings. When configured as `FIXED_TO_DEDICATED`, the cluster will always use a dedicated config server. To learn more, see the [Sharded Cluster Config Servers documentation](https://dochub.mongodb.org/docs/manual/core/sharded-cluster-config-servers/).
     * 
     */
    public Output<String> configServerManagementMode() {
        return this.configServerManagementMode;
    }
    /**
     * Describes a sharded cluster&#39;s config server type. Valid values are `DEDICATED` and `EMBEDDED`. To learn more, see the [Sharded Cluster Config Servers documentation](https://dochub.mongodb.org/docs/manual/core/sharded-cluster-config-servers/).
     * 
     */
    @Export(name="configServerType", refs={String.class}, tree="[0]")
    private Output<String> configServerType;

    /**
     * @return Describes a sharded cluster&#39;s config server type. Valid values are `DEDICATED` and `EMBEDDED`. To learn more, see the [Sharded Cluster Config Servers documentation](https://dochub.mongodb.org/docs/manual/core/sharded-cluster-config-servers/).
     * 
     */
    public Output<String> configServerType() {
        return this.configServerType;
    }
    /**
     * Set of connection strings that your applications use to connect to this cluster. More info in [Connection-strings](https://docs.mongodb.com/manual/reference/connection-string/). Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see [Connection String Options](https://docs.atlas.mongodb.com/reference/faq/connection-changes/). NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.
     * 
     */
    @Export(name="connectionStrings", refs={List.class,AdvancedClusterConnectionString.class}, tree="[0,1]")
    private Output<List<AdvancedClusterConnectionString>> connectionStrings;

    /**
     * @return Set of connection strings that your applications use to connect to this cluster. More info in [Connection-strings](https://docs.mongodb.com/manual/reference/connection-string/). Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see [Connection String Options](https://docs.atlas.mongodb.com/reference/faq/connection-changes/). NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.
     * 
     */
    public Output<List<AdvancedClusterConnectionString>> connectionStrings() {
        return this.connectionStrings;
    }
    @Export(name="createDate", refs={String.class}, tree="[0]")
    private Output<String> createDate;

    public Output<String> createDate() {
        return this.createDate;
    }
    /**
     * Capacity, in gigabytes, of the host&#39;s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (4 TB). This value must be a positive number. You can&#39;t set this value with clusters with local [NVMe SSDs](https://docs.atlas.mongodb.com/cluster-tier/#std-label-nvme-storage). The minimum disk size for dedicated clusters is 10 GB for AWS and GCP. If you specify diskSizeGB with a lower disk size, Atlas defaults to the minimum disk size value. If your cluster includes Azure nodes, this value must correspond to an existing Azure disk type (8, 16, 32, 64, 128, 256, 512, 1024, 2048, or 4095)Atlas calculates storage charges differently depending on whether you choose the default value or a custom value. The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require additional storage space beyond this limitation, consider [upgrading your cluster](https://docs.atlas.mongodb.com/scale-cluster/#std-label-scale-cluster-instance) to a higher tier. If your cluster spans cloud service providers, this value defaults to the minimum default of the providers involved. **(DEPRECATED)** Use `replication_specs.#.region_config.#.(analytics_specs|electable_specs|read_only_specs).disk_size_gb` instead. To learn more, see the 1.18.0 upgrade guide.
     * 
     * @deprecated
     * This parameter is deprecated. Please refer to our examples, documentation, and 1.18.0 migration guide for more details at https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs/guides/1.18.0-upgrade-guide.html.markdown
     * 
     */
    @Deprecated /* This parameter is deprecated. Please refer to our examples, documentation, and 1.18.0 migration guide for more details at https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs/guides/1.18.0-upgrade-guide.html.markdown */
    @Export(name="diskSizeGb", refs={Double.class}, tree="[0]")
    private Output<Double> diskSizeGb;

    /**
     * @return Capacity, in gigabytes, of the host&#39;s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (4 TB). This value must be a positive number. You can&#39;t set this value with clusters with local [NVMe SSDs](https://docs.atlas.mongodb.com/cluster-tier/#std-label-nvme-storage). The minimum disk size for dedicated clusters is 10 GB for AWS and GCP. If you specify diskSizeGB with a lower disk size, Atlas defaults to the minimum disk size value. If your cluster includes Azure nodes, this value must correspond to an existing Azure disk type (8, 16, 32, 64, 128, 256, 512, 1024, 2048, or 4095)Atlas calculates storage charges differently depending on whether you choose the default value or a custom value. The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require additional storage space beyond this limitation, consider [upgrading your cluster](https://docs.atlas.mongodb.com/scale-cluster/#std-label-scale-cluster-instance) to a higher tier. If your cluster spans cloud service providers, this value defaults to the minimum default of the providers involved. **(DEPRECATED)** Use `replication_specs.#.region_config.#.(analytics_specs|electable_specs|read_only_specs).disk_size_gb` instead. To learn more, see the 1.18.0 upgrade guide.
     * 
     */
    public Output<Double> diskSizeGb() {
        return this.diskSizeGb;
    }
    /**
     * Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see [Encryption at Rest using Customer Key Management](https://docs.atlas.mongodb.com/security-kms-encryption/) for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For Documentation, see [AWS](https://docs.atlas.mongodb.com/security-aws-kms/), [GCP](https://docs.atlas.mongodb.com/security-kms-encryption/) and [Azure](https://docs.atlas.mongodb.com/security-azure-kms/#std-label-security-azure-kms). Requirements are if `replication_specs.#.region_configs.#.&lt;type&gt;Specs.instance_size` is M10 or greater and `backup_enabled` is false or omitted.
     * 
     */
    @Export(name="encryptionAtRestProvider", refs={String.class}, tree="[0]")
    private Output<String> encryptionAtRestProvider;

    /**
     * @return Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see [Encryption at Rest using Customer Key Management](https://docs.atlas.mongodb.com/security-kms-encryption/) for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For Documentation, see [AWS](https://docs.atlas.mongodb.com/security-aws-kms/), [GCP](https://docs.atlas.mongodb.com/security-kms-encryption/) and [Azure](https://docs.atlas.mongodb.com/security-azure-kms/#std-label-security-azure-kms). Requirements are if `replication_specs.#.region_configs.#.&lt;type&gt;Specs.instance_size` is M10 or greater and `backup_enabled` is false or omitted.
     * 
     */
    public Output<String> encryptionAtRestProvider() {
        return this.encryptionAtRestProvider;
    }
    /**
     * Flag that indicates if cluster uses Atlas-Managed Sharding (false, default) or Self-Managed Sharding (true). It can only be enabled for Global Clusters (`GEOSHARDED`). It cannot be changed once the cluster is created. Use this mode if you&#39;re an advanced user and the default configuration is too restrictive for your workload. If you select this option, you must manually configure the sharding strategy, more info [here](https://www.mongodb.com/docs/atlas/tutorial/create-global-cluster/#select-your-sharding-configuration).
     * 
     */
    @Export(name="globalClusterSelfManagedSharding", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> globalClusterSelfManagedSharding;

    /**
     * @return Flag that indicates if cluster uses Atlas-Managed Sharding (false, default) or Self-Managed Sharding (true). It can only be enabled for Global Clusters (`GEOSHARDED`). It cannot be changed once the cluster is created. Use this mode if you&#39;re an advanced user and the default configuration is too restrictive for your workload. If you select this option, you must manually configure the sharding strategy, more info [here](https://www.mongodb.com/docs/atlas/tutorial/create-global-cluster/#select-your-sharding-configuration).
     * 
     */
    public Output<Boolean> globalClusterSelfManagedSharding() {
        return this.globalClusterSelfManagedSharding;
    }
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below. **DEPRECATED** Use `tags` instead.
     * 
     */
    @Export(name="labels", refs={List.class,AdvancedClusterLabel.class}, tree="[0,1]")
    private Output</* @Nullable */ List<AdvancedClusterLabel>> labels;

    /**
     * @return Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below. **DEPRECATED** Use `tags` instead.
     * 
     */
    public Output<Optional<List<AdvancedClusterLabel>>> labels() {
        return Codegen.optional(this.labels);
    }
    /**
     * Version of the cluster to deploy. Atlas supports all the MongoDB versions that have **not** reached [End of Live](https://www.mongodb.com/legal/support-policy/lifecycles) for M10+ clusters. If omitted, Atlas deploys the cluster with the default version. For more details, see [documentation](https://www.mongodb.com/docs/atlas/reference/faq/database/#which-versions-of-mongodb-do-service-clusters-use-). Atlas always deploys the cluster with the latest stable release of the specified version.  If you set a value to this parameter and set `version_release_system` `CONTINUOUS`, the resource returns an error. Either clear this parameter or set `version_release_system`: `LTS`.
     * 
     */
    @Export(name="mongoDbMajorVersion", refs={String.class}, tree="[0]")
    private Output<String> mongoDbMajorVersion;

    /**
     * @return Version of the cluster to deploy. Atlas supports all the MongoDB versions that have **not** reached [End of Live](https://www.mongodb.com/legal/support-policy/lifecycles) for M10+ clusters. If omitted, Atlas deploys the cluster with the default version. For more details, see [documentation](https://www.mongodb.com/docs/atlas/reference/faq/database/#which-versions-of-mongodb-do-service-clusters-use-). Atlas always deploys the cluster with the latest stable release of the specified version.  If you set a value to this parameter and set `version_release_system` `CONTINUOUS`, the resource returns an error. Either clear this parameter or set `version_release_system`: `LTS`.
     * 
     */
    public Output<String> mongoDbMajorVersion() {
        return this.mongoDbMajorVersion;
    }
    /**
     * Version of MongoDB the cluster runs, in `major-version`.`minor-version` format.
     * 
     */
    @Export(name="mongoDbVersion", refs={String.class}, tree="[0]")
    private Output<String> mongoDbVersion;

    /**
     * @return Version of MongoDB the cluster runs, in `major-version`.`minor-version` format.
     * 
     */
    public Output<String> mongoDbVersion() {
        return this.mongoDbVersion;
    }
    /**
     * Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. **WARNING** Changing the name will result in destruction of the existing cluster and the creation of a new cluster.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. **WARNING** Changing the name will result in destruction of the existing cluster and the creation of a new cluster.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    @Export(name="paused", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> paused;

    public Output<Boolean> paused() {
        return this.paused;
    }
    /**
     * Pins the Feature Compatibility Version (FCV) to the current MongoDB version with a provided expiration date. To unpin the FCV the `pinned_fcv` attribute must be removed. This operation can take several minutes as the request processes through the MongoDB data plane. Once FCV is unpinned it will not be possible to downgrade the `mongo_db_major_version`. It is advised that updates to `pinned_fcv` are done isolated from other cluster changes. If a plan contains multiple changes, the FCV change will be applied first. If FCV is unpinned past the expiration date the `pinned_fcv` attribute must be removed. The following [knowledge hub article](https://kb.corp.mongodb.com/article/000021785/) and [FCV documentation](https://www.mongodb.com/docs/atlas/tutorial/major-version-change/#manage-feature-compatibility--fcv--during-upgrades) can be referenced for more details. See below.
     * 
     */
    @Export(name="pinnedFcv", refs={AdvancedClusterPinnedFcv.class}, tree="[0]")
    private Output</* @Nullable */ AdvancedClusterPinnedFcv> pinnedFcv;

    /**
     * @return Pins the Feature Compatibility Version (FCV) to the current MongoDB version with a provided expiration date. To unpin the FCV the `pinned_fcv` attribute must be removed. This operation can take several minutes as the request processes through the MongoDB data plane. Once FCV is unpinned it will not be possible to downgrade the `mongo_db_major_version`. It is advised that updates to `pinned_fcv` are done isolated from other cluster changes. If a plan contains multiple changes, the FCV change will be applied first. If FCV is unpinned past the expiration date the `pinned_fcv` attribute must be removed. The following [knowledge hub article](https://kb.corp.mongodb.com/article/000021785/) and [FCV documentation](https://www.mongodb.com/docs/atlas/tutorial/major-version-change/#manage-feature-compatibility--fcv--during-upgrades) can be referenced for more details. See below.
     * 
     */
    public Output<Optional<AdvancedClusterPinnedFcv>> pinnedFcv() {
        return Codegen.optional(this.pinnedFcv);
    }
    /**
     * Flag that indicates if the cluster uses Continuous Cloud Backup.
     * 
     */
    @Export(name="pitEnabled", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> pitEnabled;

    /**
     * @return Flag that indicates if the cluster uses Continuous Cloud Backup.
     * 
     */
    public Output<Boolean> pitEnabled() {
        return this.pitEnabled;
    }
    /**
     * Unique ID for the project to create the database user.
     * 
     */
    @Export(name="projectId", refs={String.class}, tree="[0]")
    private Output<String> projectId;

    /**
     * @return Unique ID for the project to create the database user.
     * 
     */
    public Output<String> projectId() {
        return this.projectId;
    }
    /**
     * Flag that enables or disables log redaction, see the [manual](https://www.mongodb.com/docs/manual/administration/monitoring/#log-redaction) for more info. Use this in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements. **Note**: Changing this setting on a cluster will trigger a rolling restart as soon as the cluster is updated.
     * 
     */
    @Export(name="redactClientLogData", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> redactClientLogData;

    /**
     * @return Flag that enables or disables log redaction, see the [manual](https://www.mongodb.com/docs/manual/administration/monitoring/#log-redaction) for more info. Use this in conjunction with Encryption at Rest and TLS/SSL (Transport Encryption) to assist compliance with regulatory requirements. **Note**: Changing this setting on a cluster will trigger a rolling restart as soon as the cluster is updated.
     * 
     */
    public Output<Boolean> redactClientLogData() {
        return this.redactClientLogData;
    }
    /**
     * Replica set scaling mode for your cluster. Valid values are `WORKLOAD_TYPE`, `SEQUENTIAL` and `NODE_TYPE`. By default, Atlas scales under `WORKLOAD_TYPE`. This mode allows Atlas to scale your analytics nodes in parallel to your operational nodes. When configured as `SEQUENTIAL`, Atlas scales all nodes sequentially. This mode is intended for steady-state workloads and applications performing latency-sensitive secondary reads. When configured as `NODE_TYPE`, Atlas scales your electable nodes in parallel with your read-only and analytics nodes. This mode is intended for large, dynamic workloads requiring frequent and timely cluster tier scaling. This is the fastest scaling strategy, but it might impact latency of workloads when performing extensive secondary reads. [Modify the Replica Set Scaling Mode](https://dochub.mongodb.org/core/scale-nodes)
     * 
     */
    @Export(name="replicaSetScalingStrategy", refs={String.class}, tree="[0]")
    private Output<String> replicaSetScalingStrategy;

    /**
     * @return Replica set scaling mode for your cluster. Valid values are `WORKLOAD_TYPE`, `SEQUENTIAL` and `NODE_TYPE`. By default, Atlas scales under `WORKLOAD_TYPE`. This mode allows Atlas to scale your analytics nodes in parallel to your operational nodes. When configured as `SEQUENTIAL`, Atlas scales all nodes sequentially. This mode is intended for steady-state workloads and applications performing latency-sensitive secondary reads. When configured as `NODE_TYPE`, Atlas scales your electable nodes in parallel with your read-only and analytics nodes. This mode is intended for large, dynamic workloads requiring frequent and timely cluster tier scaling. This is the fastest scaling strategy, but it might impact latency of workloads when performing extensive secondary reads. [Modify the Replica Set Scaling Mode](https://dochub.mongodb.org/core/scale-nodes)
     * 
     */
    public Output<String> replicaSetScalingStrategy() {
        return this.replicaSetScalingStrategy;
    }
    /**
     * List of settings that configure your cluster regions. This attribute has one object per shard representing node configurations in each shard. For replica sets there is only one object representing node configurations. If for each replication_spec `num_shards` is configured with a value greater than 1 (using deprecated sharding configurations), then each object represents a zone with one or more shards. See below
     * 
     */
    @Export(name="replicationSpecs", refs={List.class,AdvancedClusterReplicationSpec.class}, tree="[0,1]")
    private Output<List<AdvancedClusterReplicationSpec>> replicationSpecs;

    /**
     * @return List of settings that configure your cluster regions. This attribute has one object per shard representing node configurations in each shard. For replica sets there is only one object representing node configurations. If for each replication_spec `num_shards` is configured with a value greater than 1 (using deprecated sharding configurations), then each object represents a zone with one or more shards. See below
     * 
     */
    public Output<List<AdvancedClusterReplicationSpec>> replicationSpecs() {
        return this.replicationSpecs;
    }
    /**
     * Flag that indicates whether to retain backup snapshots for the deleted dedicated cluster
     * 
     */
    @Export(name="retainBackupsEnabled", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> retainBackupsEnabled;

    /**
     * @return Flag that indicates whether to retain backup snapshots for the deleted dedicated cluster
     * 
     */
    public Output<Optional<Boolean>> retainBackupsEnabled() {
        return Codegen.optional(this.retainBackupsEnabled);
    }
    /**
     * Certificate Authority that MongoDB Atlas clusters use. You can specify ISRGROOTX1 (for ISRG Root X1).
     * 
     */
    @Export(name="rootCertType", refs={String.class}, tree="[0]")
    private Output<String> rootCertType;

    /**
     * @return Certificate Authority that MongoDB Atlas clusters use. You can specify ISRGROOTX1 (for ISRG Root X1).
     * 
     */
    public Output<String> rootCertType() {
        return this.rootCertType;
    }
    /**
     * Current state of the cluster. The possible states are:
     * - IDLE
     * - CREATING
     * - UPDATING
     * - DELETING
     * - DELETED
     * - REPAIRING
     * * `replication_specs.#.container_id` - A key-value map of the Network Peering Container ID(s) for the configuration specified in `region_configs`. The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is `&#34;providerName:regionName&#34; = &#34;containerId&#34;`. Example `AWS:US_EAST_1&#34; = &#34;61e0797dde08fb498ca11a71`.
     * 
     */
    @Export(name="stateName", refs={String.class}, tree="[0]")
    private Output<String> stateName;

    /**
     * @return Current state of the cluster. The possible states are:
     * - IDLE
     * - CREATING
     * - UPDATING
     * - DELETING
     * - DELETED
     * - REPAIRING
     * * `replication_specs.#.container_id` - A key-value map of the Network Peering Container ID(s) for the configuration specified in `region_configs`. The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is `&#34;providerName:regionName&#34; = &#34;containerId&#34;`. Example `AWS:US_EAST_1&#34; = &#34;61e0797dde08fb498ca11a71`.
     * 
     */
    public Output<String> stateName() {
        return this.stateName;
    }
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     * 
     */
    @Export(name="tags", refs={List.class,AdvancedClusterTag.class}, tree="[0,1]")
    private Output</* @Nullable */ List<AdvancedClusterTag>> tags;

    /**
     * @return Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     * 
     */
    public Output<Optional<List<AdvancedClusterTag>>> tags() {
        return Codegen.optional(this.tags);
    }
    /**
     * Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won&#39;t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
     * 
     */
    @Export(name="terminationProtectionEnabled", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> terminationProtectionEnabled;

    /**
     * @return Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won&#39;t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
     * 
     */
    public Output<Boolean> terminationProtectionEnabled() {
        return this.terminationProtectionEnabled;
    }
    /**
     * Release cadence that Atlas uses for this cluster. This parameter defaults to `LTS`. If you set this field to `CONTINUOUS`, you must omit the `mongo_db_major_version` field. Atlas accepts:
     * - `CONTINUOUS`:  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.
     * - `LTS`: Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn&#39;t update your cluster to newer rapid or major MongoDB releases as they become available.
     * 
     */
    @Export(name="versionReleaseSystem", refs={String.class}, tree="[0]")
    private Output<String> versionReleaseSystem;

    /**
     * @return Release cadence that Atlas uses for this cluster. This parameter defaults to `LTS`. If you set this field to `CONTINUOUS`, you must omit the `mongo_db_major_version` field. Atlas accepts:
     * - `CONTINUOUS`:  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.
     * - `LTS`: Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn&#39;t update your cluster to newer rapid or major MongoDB releases as they become available.
     * 
     */
    public Output<String> versionReleaseSystem() {
        return this.versionReleaseSystem;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public AdvancedCluster(java.lang.String name) {
        this(name, AdvancedClusterArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public AdvancedCluster(java.lang.String name, AdvancedClusterArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public AdvancedCluster(java.lang.String name, AdvancedClusterArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("mongodbatlas:index/advancedCluster:AdvancedCluster", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private AdvancedCluster(java.lang.String name, Output<java.lang.String> id, @Nullable AdvancedClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("mongodbatlas:index/advancedCluster:AdvancedCluster", name, state, makeResourceOptions(options, id), false);
    }

    private static AdvancedClusterArgs makeArgs(AdvancedClusterArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? AdvancedClusterArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static AdvancedCluster get(java.lang.String name, Output<java.lang.String> id, @Nullable AdvancedClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new AdvancedCluster(name, id, state, options);
    }
}
