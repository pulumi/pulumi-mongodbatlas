// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Mongodbatlas
{
    /// <summary>
    /// `mongodbatlas.StreamProcessor` provides a Stream Processor resource. The resource lets you create, delete, import, start and stop a stream processor in a stream instance.
    /// 
    /// **NOTE**: When updating an Atlas Stream Processor, the following behavior applies:
    /// 1. If the processor is in a `STARTED` state, it will automatically be stopped before the update is applied
    /// 2. The update will be performed while the processor is in `STOPPED` state
    /// 3. If the processor was originally in `STARTED` state, it will be restarted after the update
    /// 
    /// ## Example Usage
    /// 
    /// ### S
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using System.Text.Json;
    /// using Pulumi;
    /// using Mongodbatlas = Pulumi.Mongodbatlas;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Mongodbatlas.StreamInstance("example", new()
    ///     {
    ///         ProjectId = projectId,
    ///         InstanceName = "InstanceName",
    ///         DataProcessRegion = new Mongodbatlas.Inputs.StreamInstanceDataProcessRegionArgs
    ///         {
    ///             Region = "VIRGINIA_USA",
    ///             CloudProvider = "AWS",
    ///         },
    ///     });
    /// 
    ///     var example_sample = new Mongodbatlas.StreamConnection("example-sample", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ConnectionName = "sample_stream_solar",
    ///         Type = "Sample",
    ///     });
    /// 
    ///     var example_cluster = new Mongodbatlas.StreamConnection("example-cluster", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ConnectionName = "ClusterConnection",
    ///         Type = "Cluster",
    ///         ClusterName = clusterName,
    ///         DbRoleToExecute = new Mongodbatlas.Inputs.StreamConnectionDbRoleToExecuteArgs
    ///         {
    ///             Role = "atlasAdmin",
    ///             Type = "BUILT_IN",
    ///         },
    ///     });
    /// 
    ///     var example_kafka = new Mongodbatlas.StreamConnection("example-kafka", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ConnectionName = "KafkaPlaintextConnection",
    ///         Type = "Kafka",
    ///         Authentication = new Mongodbatlas.Inputs.StreamConnectionAuthenticationArgs
    ///         {
    ///             Mechanism = "PLAIN",
    ///             Username = kafkaUsername,
    ///             Password = kafkaPassword,
    ///         },
    ///         BootstrapServers = "localhost:9092,localhost:9092",
    ///         Config = 
    ///         {
    ///             { "auto.offset.reset", "earliest" },
    ///         },
    ///         Security = new Mongodbatlas.Inputs.StreamConnectionSecurityArgs
    ///         {
    ///             Protocol = "SASL_PLAINTEXT",
    ///         },
    ///     });
    /// 
    ///     var stream_processor_sample_example = new Mongodbatlas.StreamProcessor("stream-processor-sample-example", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ProcessorName = "sampleProcessorName",
    ///         Pipeline = JsonSerializer.Serialize(new[]
    ///         {
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$source"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_sample.ConnectionName,
    ///                 },
    ///             },
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$emit"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_cluster.ConnectionName,
    ///                     ["db"] = "sample",
    ///                     ["coll"] = "solar",
    ///                     ["timeseries"] = new Dictionary&lt;string, object?&gt;
    ///                     {
    ///                         ["timeField"] = "_ts",
    ///                     },
    ///                 },
    ///             },
    ///         }),
    ///         State = "STARTED",
    ///     });
    /// 
    ///     var stream_processor_cluster_to_kafka_example = new Mongodbatlas.StreamProcessor("stream-processor-cluster-to-kafka-example", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ProcessorName = "clusterProcessorName",
    ///         Pipeline = JsonSerializer.Serialize(new[]
    ///         {
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$source"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_cluster.ConnectionName,
    ///                 },
    ///             },
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$emit"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_kafka.ConnectionName,
    ///                     ["topic"] = "topic_from_cluster",
    ///                 },
    ///             },
    ///         }),
    ///         State = "CREATED",
    ///     });
    /// 
    ///     var stream_processor_kafka_to_cluster_example = new Mongodbatlas.StreamProcessor("stream-processor-kafka-to-cluster-example", new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ProcessorName = "kafkaProcessorName",
    ///         Pipeline = JsonSerializer.Serialize(new[]
    ///         {
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$source"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_kafka.ConnectionName,
    ///                     ["topic"] = "topic_source",
    ///                 },
    ///             },
    ///             new Dictionary&lt;string, object?&gt;
    ///             {
    ///                 ["$emit"] = new Dictionary&lt;string, object?&gt;
    ///                 {
    ///                     ["connectionName"] = mongodbatlasStreamConnection.Example_cluster.ConnectionName,
    ///                     ["db"] = "kafka",
    ///                     ["coll"] = "topic_source",
    ///                     ["timeseries"] = new Dictionary&lt;string, object?&gt;
    ///                     {
    ///                         ["timeField"] = "ts",
    ///                     },
    ///                 },
    ///             },
    ///         }),
    ///         State = "CREATED",
    ///         Options = new Mongodbatlas.Inputs.StreamProcessorOptionsArgs
    ///         {
    ///             Dlq = new Mongodbatlas.Inputs.StreamProcessorOptionsDlqArgs
    ///             {
    ///                 Coll = "exampleColumn",
    ///                 ConnectionName = mongodbatlasStreamConnection.Example_cluster.ConnectionName,
    ///                 Db = "exampleDb",
    ///             },
    ///         },
    ///     });
    /// 
    ///     var example_stream_processors = Mongodbatlas.GetStreamProcessors.Invoke(new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///     });
    /// 
    ///     var example_stream_processor = Mongodbatlas.GetStreamProcessor.Invoke(new()
    ///     {
    ///         ProjectId = projectId,
    ///         WorkspaceName = example.InstanceName,
    ///         ProcessorName = stream_processor_sample_example.ProcessorName,
    ///     });
    /// 
    ///     return new Dictionary&lt;string, object?&gt;
    ///     {
    ///         ["streamProcessorsState"] = example_stream_processor.Apply(example_stream_processor =&gt; example_stream_processor.Apply(getStreamProcessorResult =&gt; getStreamProcessorResult.State)),
    ///         ["streamProcessorsResults"] = example_stream_processors.Apply(example_stream_processors =&gt; example_stream_processors.Apply(getStreamProcessorsResult =&gt; getStreamProcessorsResult.Results)),
    ///     };
    /// });
    /// ```
    /// 
    /// ### Further Examples
    /// - Atlas Stream Processor
    /// 
    /// ## Import
    /// 
    /// Stream Processor resource can be imported using the Project ID, Stream Instance name and Stream Processor name, in the format `INSTANCE_NAME-PROJECT_ID-PROCESSOR_NAME`, e.g.
    /// 
    /// For more information see: [MongoDB Atlas API - Stream Processor](https://www.mongodb.com/docs/api/doc/atlas-admin-api-v2/operation/operation-createstreamprocessor) Documentation.
    /// </summary>
    [MongodbatlasResourceType("mongodbatlas:index/streamProcessor:StreamProcessor")]
    public partial class StreamProcessor : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `True` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `False`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `True`, wait before retrying to allow resource deletion to finish. Default is `True`.
        /// </summary>
        [Output("deleteOnCreateTimeout")]
        public Output<bool> DeleteOnCreateTimeout { get; private set; } = null!;

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Output("instanceName")]
        public Output<string?> InstanceName { get; private set; } = null!;

        /// <summary>
        /// Optional configuration for the stream processor.
        /// </summary>
        [Output("options")]
        public Output<Outputs.StreamProcessorOptions?> Options { get; private set; } = null!;

        /// <summary>
        /// Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        /// </summary>
        [Output("pipeline")]
        public Output<string> Pipeline { get; private set; } = null!;

        /// <summary>
        /// Label that identifies the stream processor.
        /// </summary>
        [Output("processorName")]
        public Output<string> ProcessorName { get; private set; } = null!;

        /// <summary>
        /// Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        /// </summary>
        [Output("projectId")]
        public Output<string> ProjectId { get; private set; } = null!;

        /// <summary>
        /// The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
        /// 
        /// **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        /// </summary>
        [Output("state")]
        public Output<string> State { get; private set; } = null!;

        /// <summary>
        /// The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        /// </summary>
        [Output("stats")]
        public Output<string> Stats { get; private set; } = null!;

        [Output("timeouts")]
        public Output<Outputs.StreamProcessorTimeouts?> Timeouts { get; private set; } = null!;

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Output("workspaceName")]
        public Output<string?> WorkspaceName { get; private set; } = null!;


        /// <summary>
        /// Create a StreamProcessor resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public StreamProcessor(string name, StreamProcessorArgs args, CustomResourceOptions? options = null)
            : base("mongodbatlas:index/streamProcessor:StreamProcessor", name, args ?? new StreamProcessorArgs(), MakeResourceOptions(options, ""))
        {
        }

        private StreamProcessor(string name, Input<string> id, StreamProcessorState? state = null, CustomResourceOptions? options = null)
            : base("mongodbatlas:index/streamProcessor:StreamProcessor", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing StreamProcessor resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static StreamProcessor Get(string name, Input<string> id, StreamProcessorState? state = null, CustomResourceOptions? options = null)
        {
            return new StreamProcessor(name, id, state, options);
        }
    }

    public sealed class StreamProcessorArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `True` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `False`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `True`, wait before retrying to allow resource deletion to finish. Default is `True`.
        /// </summary>
        [Input("deleteOnCreateTimeout")]
        public Input<bool>? DeleteOnCreateTimeout { get; set; }

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Input("instanceName")]
        public Input<string>? InstanceName { get; set; }

        /// <summary>
        /// Optional configuration for the stream processor.
        /// </summary>
        [Input("options")]
        public Input<Inputs.StreamProcessorOptionsArgs>? Options { get; set; }

        /// <summary>
        /// Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        /// </summary>
        [Input("pipeline", required: true)]
        public Input<string> Pipeline { get; set; } = null!;

        /// <summary>
        /// Label that identifies the stream processor.
        /// </summary>
        [Input("processorName", required: true)]
        public Input<string> ProcessorName { get; set; } = null!;

        /// <summary>
        /// Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        /// </summary>
        [Input("projectId", required: true)]
        public Input<string> ProjectId { get; set; } = null!;

        /// <summary>
        /// The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
        /// 
        /// **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        /// </summary>
        [Input("state")]
        public Input<string>? State { get; set; }

        [Input("timeouts")]
        public Input<Inputs.StreamProcessorTimeoutsArgs>? Timeouts { get; set; }

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Input("workspaceName")]
        public Input<string>? WorkspaceName { get; set; }

        public StreamProcessorArgs()
        {
        }
        public static new StreamProcessorArgs Empty => new StreamProcessorArgs();
    }

    public sealed class StreamProcessorState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `True` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `False`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `True`, wait before retrying to allow resource deletion to finish. Default is `True`.
        /// </summary>
        [Input("deleteOnCreateTimeout")]
        public Input<bool>? DeleteOnCreateTimeout { get; set; }

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Input("instanceName")]
        public Input<string>? InstanceName { get; set; }

        /// <summary>
        /// Optional configuration for the stream processor.
        /// </summary>
        [Input("options")]
        public Input<Inputs.StreamProcessorOptionsGetArgs>? Options { get; set; }

        /// <summary>
        /// Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
        /// </summary>
        [Input("pipeline")]
        public Input<string>? Pipeline { get; set; }

        /// <summary>
        /// Label that identifies the stream processor.
        /// </summary>
        [Input("processorName")]
        public Input<string>? ProcessorName { get; set; }

        /// <summary>
        /// Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
        /// </summary>
        [Input("projectId")]
        public Input<string>? ProjectId { get; set; }

        /// <summary>
        /// The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
        /// 
        /// **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
        /// </summary>
        [Input("state")]
        public Input<string>? State { get; set; }

        /// <summary>
        /// The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
        /// </summary>
        [Input("stats")]
        public Input<string>? Stats { get; set; }

        [Input("timeouts")]
        public Input<Inputs.StreamProcessorTimeoutsGetArgs>? Timeouts { get; set; }

        /// <summary>
        /// Label that identifies the stream processing workspace.
        /// </summary>
        [Input("workspaceName")]
        public Input<string>? WorkspaceName { get; set; }

        public StreamProcessorState()
        {
        }
        public static new StreamProcessorState Empty => new StreamProcessorState();
    }
}
