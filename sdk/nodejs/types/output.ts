// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface AdvancedClusterAdvancedConfiguration {
    defaultReadConcern: string;
    defaultWriteConcern: string;
    failIndexKeyTooLong: boolean;
    javascriptEnabled: boolean;
    minimumEnabledTlsProtocol: string;
    noTableScan: boolean;
    oplogMinRetentionHours?: number;
    oplogSizeMb: number;
    sampleRefreshIntervalBiConnector: number;
    sampleSizeBiConnector: number;
    transactionLifetimeLimitSeconds: number;
}

export interface AdvancedClusterBiConnectorConfig {
    /**
     * Specifies whether or not BI Connector for Atlas is enabled on the cluster.l
     * *
     * - Set to `true` to enable BI Connector for Atlas.
     * - Set to `false` to disable BI Connector for Atlas.
     */
    enabled: boolean;
    /**
     * Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of [readPreference](https://docs.mongodb.com/manual/core/read-preference/) and [readPreferenceTags](https://docs.mongodb.com/manual/core/read-preference/#tag-sets) options. For details on BI Connector for Atlas read preferences, refer to the [BI Connector Read Preferences Table](https://docs.atlas.mongodb.com/tutorial/create-global-writes-cluster/#bic-read-preferences).
     *
     * - Set to "primary" to have BI Connector for Atlas read from the primary.
     *
     * - Set to "secondary" to have BI Connector for Atlas read from a secondary member. Default if there are no analytics nodes in the cluster.
     *
     * - Set to "analytics" to have BI Connector for Atlas read from an analytics node. Default if the cluster contains analytics nodes.
     */
    readPreference: string;
}

export interface AdvancedClusterConnectionString {
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    /**
     * Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster's nodes.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint. The `mongodb+srv` protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don't need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn't, use `connection_strings.private_endpoint[n].connection_string`
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don't need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn't, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateEndpoints: outputs.AdvancedClusterConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface AdvancedClusterConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.AdvancedClusterConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface AdvancedClusterConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    providerName: string;
    region: string;
}

export interface AdvancedClusterLabel {
    /**
     * The key that you want to write.
     */
    key?: string;
    /**
     * The value that you want to write.
     *
     * > **NOTE:** MongoDB Atlas doesn't display your labels.
     */
    value?: string;
}

export interface AdvancedClusterReplicationSpec {
    containerId: {[key: string]: string};
    id: string;
    /**
     * Provide this value if you set a `clusterType` of SHARDED or GEOSHARDED. Omit this value if you selected a `clusterType` of REPLICASET. This API resource accepts 1 through 50, inclusive. This parameter defaults to 1. If you specify a `numShards` value of 1 and a `clusterType` of SHARDED, Atlas deploys a single-shard [sharded cluster](https://docs.atlas.mongodb.com/reference/glossary/#std-term-sharded-cluster). Don't create a sharded cluster with a single shard for production environments. Single-shard sharded clusters don't provide the same benefits as multi-shard configurations.
     * If you are upgrading a replica set to a sharded cluster, you cannot increase the number of shards in the same update request. You should wait until after the cluster has completed upgrading to sharded and you have reconnected all application clients to the MongoDB router before adding additional shards. Otherwise, your data might become inconsistent once MongoDB Cloud begins distributing data across shards. To learn more, see [Convert a replica set to a sharded cluster documentation](https://www.mongodb.com/docs/atlas/scale-cluster/#convert-a-replica-set-to-a-sharded-cluster) and [Convert a replica set to a sharded cluster tutorial](https://www.mongodb.com/docs/upcoming/tutorial/convert-replica-set-to-replicated-shard-cluster).
     */
    numShards?: number;
    /**
     * Configuration for the hardware specifications for nodes set for a given regionEach `regionConfigs` object describes the region's priority in elections and the number and type of MongoDB nodes that Atlas deploys to the region. Each `regionConfigs` object must have either an `analyticsSpecs` object, `electableSpecs` object, or `readOnlySpecs` object. See below
     */
    regionConfigs: outputs.AdvancedClusterReplicationSpecRegionConfig[];
    /**
     * Name for the zone in a Global Cluster.
     */
    zoneName?: string;
}

export interface AdvancedClusterReplicationSpecRegionConfig {
    /**
     * Configuration for the Collection of settings that configures analytics-auto-scaling information for the cluster. The values for the `analyticsAutoScaling` parameter must be the same for every item in the `replicationSpecs` array. See below
     */
    analyticsAutoScaling: outputs.AdvancedClusterReplicationSpecRegionConfigAnalyticsAutoScaling;
    /**
     * Hardware specifications for [analytics nodes](https://docs.atlas.mongodb.com/reference/faq/deployment/#std-label-analytics-nodes-overview) needed in the region. Analytics nodes handle analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only and can never become the [primary](https://docs.atlas.mongodb.com/reference/glossary/#std-term-primary). If you don't specify this parameter, no analytics nodes deploy to this region. See below
     */
    analyticsSpecs?: outputs.AdvancedClusterReplicationSpecRegionConfigAnalyticsSpecs;
    /**
     * Configuration for the Collection of settings that configures auto-scaling information for the cluster. The values for the `autoScaling` parameter must be the same for every item in the `replicationSpecs` array. See below
     */
    autoScaling: outputs.AdvancedClusterReplicationSpecRegionConfigAutoScaling;
    /**
     * Cloud service provider on which you provision the host for a multi-tenant cluster. Use this only when a `providerName` is `TENANT` and `instanceSize` of a specs is `M2` or `M5`.
     */
    backingProviderName?: string;
    /**
     * Hardware specifications for electable nodes in the region. Electable nodes can become the [primary](https://docs.atlas.mongodb.com/reference/glossary/#std-term-primary) and can enable local reads. If you do not specify this option, no electable nodes are deployed to the region. See below
     */
    electableSpecs?: outputs.AdvancedClusterReplicationSpecRegionConfigElectableSpecs;
    /**
     * Election priority of the region. For regions with only read-only nodes, set this value to 0.
     * * If you have multiple `regionConfigs` objects (your cluster is multi-region or multi-cloud), they must have priorities in descending order. The highest priority is 7.
     * * If your region has set `region_configs.#.electable_specs.0.node_count` to 1 or higher, it must have a priority of exactly one (1) less than another region in the `replication_specs.#.region_configs.#` array. The highest-priority region must have a priority of 7. The lowest possible priority is 1.
     */
    priority: number;
    /**
     * Cloud service provider on which the servers are provisioned.
     * The possible values are:
     */
    providerName: string;
    /**
     * Hardware specifications for read-only nodes in the region. Read-only nodes can become the [primary](https://docs.atlas.mongodb.com/reference/glossary/#std-term-primary) and can enable local reads. If you don't specify this parameter, no read-only nodes are deployed to the region. See below
     */
    readOnlySpecs?: outputs.AdvancedClusterReplicationSpecRegionConfigReadOnlySpecs;
    /**
     * Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the **Atlas region name**, see the reference list for [AWS](https://docs.atlas.mongodb.com/reference/amazon-aws/), [GCP](https://docs.atlas.mongodb.com/reference/google-gcp/), [Azure](https://docs.atlas.mongodb.com/reference/microsoft-azure/).
     */
    regionName: string;
}

export interface AdvancedClusterReplicationSpecRegionConfigAnalyticsAutoScaling {
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if `replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled` is true.
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if `replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_scale_down_enabled` is true.
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down. Atlas requires this parameter if `replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled` : true. If you enable this option, specify a value for `replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_min_instance_size`.
     */
    computeScaleDownEnabled: boolean;
    /**
     * Flag that indicates whether this cluster enables disk auto-scaling. This parameter defaults to true.
     */
    diskGbEnabled: boolean;
}

export interface AdvancedClusterReplicationSpecRegionConfigAnalyticsSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster. Valid values are:
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface AdvancedClusterReplicationSpecRegionConfigAutoScaling {
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if `replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled` is true.
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if `replication_specs.#.region_configs.#.auto_scaling.0.compute_scale_down_enabled` is true.
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down. Atlas requires this parameter if `replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled` : true. If you enable this option, specify a value for `replication_specs.#.region_configs.#.auto_scaling.0.compute_min_instance_size`.
     */
    computeScaleDownEnabled: boolean;
    diskGbEnabled: boolean;
}

export interface AdvancedClusterReplicationSpecRegionConfigElectableSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster. Valid values are:
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface AdvancedClusterReplicationSpecRegionConfigReadOnlySpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can't set this parameter for a multi-cloud cluster. Valid values are:
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface AdvancedClusterTag {
    /**
     * Constant that defines the set of the tag.
     */
    key: string;
    /**
     * Variable that belongs to the set of the tag.
     *
     * To learn more, see [Resource Tags](https://dochub.mongodb.org/core/add-cluster-tag-atlas).
     */
    value: string;
}

export interface AlertConfigurationMatcher {
    fieldName: string;
    operator: string;
    value: string;
}

export interface AlertConfigurationMetricThresholdConfig {
    metricName: string;
    mode?: string;
    operator?: string;
    threshold: number;
    units?: string;
}

export interface AlertConfigurationNotification {
    apiToken?: string;
    channelName?: string;
    datadogApiKey?: string;
    datadogRegion?: string;
    delayMin: number;
    emailAddress?: string;
    emailEnabled: boolean;
    integrationId?: string;
    intervalMin: number;
    microsoftTeamsWebhookUrl?: string;
    mobileNumber?: string;
    notifierId: string;
    opsGenieApiKey?: string;
    opsGenieRegion?: string;
    roles?: string[];
    serviceKey?: string;
    smsEnabled: boolean;
    teamId?: string;
    teamName: string;
    typeName: string;
    username?: string;
    victorOpsApiKey?: string;
    victorOpsRoutingKey?: string;
    webhookSecret?: string;
    webhookUrl?: string;
}

export interface AlertConfigurationThresholdConfig {
    operator?: string;
    threshold: number;
    units?: string;
}

export interface BackupCompliancePolicyOnDemandPolicyItem {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface BackupCompliancePolicyPolicyItemDaily {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface BackupCompliancePolicyPolicyItemHourly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface BackupCompliancePolicyPolicyItemMonthly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface BackupCompliancePolicyPolicyItemWeekly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface BackupCompliancePolicyPolicyItemYearly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface CloudBackupScheduleCopySetting {
    cloudProvider: string;
    frequencies: string[];
    regionName: string;
    replicationSpecId: string;
    shouldCopyOplogs: boolean;
}

export interface CloudBackupScheduleExport {
    /**
     * Unique identifier of the mongodbatlas.CloudBackupSnapshotExportBucket export_bucket_id value.
     */
    exportBucketId: string;
    /**
     * Frequency associated with the export snapshot item.
     */
    frequencyType: string;
}

export interface CloudBackupSchedulePolicyItemDaily {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (daily in this case). The only supported value for daily policies is `1` day.
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For daily policies, the frequency type is defined as `daily`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`.  Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the hourly policy item specifies a retention of two days, the daily retention policy must specify two days or greater.
     */
    retentionValue: number;
}

export interface CloudBackupSchedulePolicyItemHourly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (hourly in this case). The supported values for hourly policies are `1`, `2`, `4`, `6`, `8` or `12` hours. Note that `12` hours is the only accepted value for NVMe clusters.
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For hourly policies, the frequency type is defined as `hourly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`.
     */
    retentionValue: number;
}

export interface CloudBackupSchedulePolicyItemMonthly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (monthly in this case). The supported values for weekly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For monthly policies, the frequency type is defined as `monthly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Monthly policy must have retention days of at least 31 days or 5 weeks or 1 month. Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the weekly policy item specifies a retention of two weeks, the montly retention policy must specify two weeks or greater.
     */
    retentionValue: number;
}

export interface CloudBackupSchedulePolicyItemWeekly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (weekly in this case). The supported values for weekly policies are `1` through `7`, where `1` represents Monday and `7` represents Sunday.
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For weekly policies, the frequency type is defined as `weekly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Weekly policy must have retention of at least 7 days or 1 week. Note that for less frequent policy items, Atlas requires that you specify a retention period greater than or equal to the retention period specified for more frequent policy items. For example: If the daily policy item specifies a retention of two weeks, the weekly retention policy must specify two weeks or greater.
     */
    retentionValue: number;
}

export interface CloudBackupSchedulePolicyItemYearly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface CloudBackupSnapshotExportJobComponent {
    /**
     * _Returned for sharded clusters only._ Export job details for each replica set in the sharded cluster.
     */
    exportId: string;
    /**
     * _Returned for sharded clusters only._ Unique identifier of the export job for the replica set.
     */
    replicaSetName: string;
}

export interface CloudBackupSnapshotExportJobCustomData {
    /**
     * Required if you want to include custom data using `customData` in the metadata file uploaded to the bucket. Key to include in the metadata file that Atlas uploads to the bucket when the export job finishes.
     */
    key: string;
    /**
     * Required if you specify `key`.
     */
    value: string;
}

export interface CloudBackupSnapshotMember {
    /**
     * Cloud provider that stores this snapshot.
     */
    cloudProvider: string;
    /**
     * Unique identifier for the sharded cluster snapshot.
     */
    id: string;
    /**
     * Label given to a shard or config server from which Atlas took this snapshot.
     */
    replicaSetName: string;
}

export interface CloudBackupSnapshotRestoreJobDeliveryTypeConfig {
    automated?: boolean;
    download?: boolean;
    oplogInc?: number;
    oplogTs?: number;
    pointInTime?: boolean;
    pointInTimeUtcSeconds?: number;
    /**
     * Name of the target Atlas cluster to which the restore job restores the snapshot. Only visible if deliveryType is automated.
     */
    targetClusterName?: string;
    /**
     * Name of the target Atlas project of the restore job. Only visible if deliveryType is automated.
     */
    targetProjectId?: string;
}

export interface CloudProviderAccessAuthorizationAws {
    iamAssumedRoleArn: string;
}

export interface CloudProviderAccessAuthorizationAzure {
    atlasAzureAppId: string;
    servicePrincipalId: string;
    tenantId: string;
}

export interface CloudProviderAccessAuthorizationFeatureUsage {
    featureId: {[key: string]: any};
    featureType: string;
}

export interface CloudProviderAccessSetupAwsConfig {
    atlasAssumedRoleExternalId: string;
    atlasAwsAccountArn: string;
}

export interface CloudProviderAccessSetupAzureConfig {
    atlasAzureAppId: string;
    servicePrincipalId: string;
    tenantId: string;
}

export interface ClusterAdvancedConfiguration {
    defaultReadConcern: string;
    defaultWriteConcern: string;
    failIndexKeyTooLong: boolean;
    javascriptEnabled: boolean;
    minimumEnabledTlsProtocol: string;
    noTableScan: boolean;
    oplogMinRetentionHours?: number;
    oplogSizeMb: number;
    sampleRefreshIntervalBiConnector: number;
    sampleSizeBiConnector: number;
    transactionLifetimeLimitSeconds: number;
}

export interface ClusterBiConnectorConfig {
    enabled: boolean;
    readPreference: string;
}

export interface ClusterConnectionString {
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    /**
     * Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster's nodes.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint. The `mongodb+srv` protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don't need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn't, use `connection_strings.private_endpoint[n].connection_string`
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don't need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn't, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateEndpoints: outputs.ClusterConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface ClusterConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.ClusterConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface ClusterConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    /**
     * Cloud service provider on which the servers are provisioned.
     *
     * The possible values are:
     */
    providerName: string;
    region: string;
}

export interface ClusterLabel {
    /**
     * The key that you want to write.
     */
    key?: string;
    /**
     * The value that you want to write.
     *
     * > **NOTE:** MongoDB Atlas doesn't display your labels.
     */
    value?: string;
}

export interface ClusterOutageSimulationOutageFilter {
    /**
     * The cloud provider of the region that undergoes the outage simulation. Following values are supported:
     */
    cloudProvider: string;
    /**
     * The Atlas name of the region to undergo an outage simulation.
     */
    regionName: string;
    /**
     * The type of cluster outage simulation. Following values are supported:
     */
    type: string;
}

export interface ClusterReplicationSpec {
    id: string;
    /**
     * Selects whether the cluster is a replica set or a sharded cluster. If you use the replicationSpecs parameter, you must set num_shards.
     */
    numShards: number;
    regionsConfigs: outputs.ClusterReplicationSpecRegionsConfig[];
    zoneName?: string;
}

export interface ClusterReplicationSpecRegionsConfig {
    analyticsNodes?: number;
    electableNodes: number;
    priority: number;
    readOnlyNodes?: number;
    regionName: string;
}

export interface ClusterSnapshotBackupPolicy {
    /**
     * The cluster ID.
     */
    clusterId: string;
    clusterName: string;
    nextSnapshot: string;
    policies: outputs.ClusterSnapshotBackupPolicyPolicy[];
    referenceHourOfDay: number;
    referenceMinuteOfHour: number;
    restoreWindowDays: number;
    updateSnapshots: boolean;
}

export interface ClusterSnapshotBackupPolicyPolicy {
    id: string;
    policyItems: outputs.ClusterSnapshotBackupPolicyPolicyPolicyItem[];
}

export interface ClusterSnapshotBackupPolicyPolicyPolicyItem {
    frequencyInterval: number;
    frequencyType: string;
    id: string;
    retentionUnit: string;
    retentionValue: number;
}

export interface ClusterTag {
    /**
     * Constant that defines the set of the tag.
     */
    key: string;
    /**
     * Variable that belongs to the set of the tag.
     *
     * To learn more, see [Resource Tags](https://dochub.mongodb.org/core/add-cluster-tag-atlas).
     */
    value: string;
}

export interface CustomDbRoleAction {
    /**
     * Name of the privilege action. For a complete list of actions available in the Atlas API, see [Custom Role Actions](https://docs.atlas.mongodb.com/reference/api/custom-role-actions)
     * > **Note**: The privilege actions available to the Custom Roles API resource represent a subset of the privilege actions available in the Atlas Custom Roles UI.
     */
    action: string;
    /**
     * Contains information on where the action is granted. Each object in the array either indicates a database and collection on which the action is granted, or indicates that the action is granted on the cluster resource.
     *
     * * `resources.#.collection_name` - (Optional) Collection on which the action is granted. If this value is an empty string, the action is granted on all collections within the database specified in the actions.resources.db field.
     *
     * > **NOTE** This field is mutually exclusive with the `actions.resources.cluster` field.
     *
     * * `resources.#.database_name`	Database on which the action is granted.
     *
     * > **NOTE** This field is mutually exclusive with the `actions.resources.cluster` field.
     *
     * * `resources.#.cluster`	(Optional) Set to true to indicate that the action is granted on the cluster resource.
     *
     * > **NOTE** This field is mutually exclusive with the `actions.resources.collection` and `actions.resources.db fields`.
     */
    resources: outputs.CustomDbRoleActionResource[];
}

export interface CustomDbRoleActionResource {
    cluster?: boolean;
    collectionName?: string;
    databaseName?: string;
}

export interface CustomDbRoleInheritedRole {
    /**
     * Database on which the inherited role is granted.
     *
     * > **NOTE** This value should be admin for all roles except read and readWrite.
     */
    databaseName: string;
    /**
     * Name of the inherited role. This can either be another custom role or a built-in role.
     */
    roleName: string;
}

export interface DataLakePipelineIngestionSchedule {
    frequencyInterval: number;
    frequencyType: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.
     */
    id: string;
    retentionUnit: string;
    retentionValue: number;
}

export interface DataLakePipelineSink {
    /**
     * Ordered fields used to physically organize data in the destination.
     * * `partition_fields.#.field_name` - Human-readable label that identifies the field name used to partition data.
     * * `partition_fields.#.order` - Sequence in which MongoDB Atlas slices the collection data to create partitions. The resource expresses this sequence starting with zero.
     */
    partitionFields?: outputs.DataLakePipelineSinkPartitionField[];
    /**
     * Target cloud provider for this Data Lake Pipeline.
     */
    provider: string;
    /**
     * Target cloud provider region for this Data Lake Pipeline. [Supported cloud provider regions](https://www.mongodb.com/docs/datalake/limitations).
     */
    region: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type?: string;
}

export interface DataLakePipelineSinkPartitionField {
    fieldName: string;
    order: number;
}

export interface DataLakePipelineSnapshot {
    copyRegion: string;
    createdAt: string;
    expiresAt: string;
    frequencyYype: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.
     */
    id: string;
    masterKey: string;
    mongodVersion: string;
    policies?: string[];
    /**
     * Target cloud provider for this Data Lake Pipeline.
     */
    provider?: string;
    replicaSetName: string;
    size: number;
    snapshotType: string;
    status: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface DataLakePipelineSource {
    /**
     * Human-readable name that identifies the cluster.
     */
    clusterName?: string;
    /**
     * Human-readable name that identifies the collection.
     */
    collectionName?: string;
    /**
     * Human-readable name that identifies the database.
     */
    databaseName?: string;
    policyItemId?: string;
    /**
     * The unique ID for the project to create a data lake pipeline.
     */
    projectId: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type?: string;
}

export interface DataLakePipelineTransformation {
    field?: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type?: string;
}

export interface DatabaseUserLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface DatabaseUserRole {
    /**
     * Collection for which the role applies. You can specify a collection for the `read` and `readWrite` roles. If you do not specify a collection for `read` and `readWrite`, the role applies to all collections in the database (excluding some collections in the `system`. database).
     */
    collectionName?: string;
    /**
     * Database on which the user has the specified role. A role on the `admin` database can include privileges that apply to the other databases. This field should be set to `admin` for a custom MongoDB role.
     */
    databaseName: string;
    /**
     * Name of the role to grant. See [Create a Database User](https://docs.atlas.mongodb.com/reference/api/database-users-create-a-user/) `roles.roleName` for valid values and restrictions.
     */
    roleName: string;
}

export interface DatabaseUserScope {
    /**
     * Name of the cluster or Atlas Data Lake that the user has access to.
     */
    name?: string;
    /**
     * Type of resource that the user has access to. Valid values are: `CLUSTER` and `DATA_LAKE`
     */
    type?: string;
}

export interface EncryptionAtRestAwsKmsConfig {
    accessKeyId?: string;
    /**
     * The AWS customer master key used to encrypt and decrypt the MongoDB master keys.
     */
    customerMasterKeyId?: string;
    /**
     * Specifies whether Encryption at Rest is enabled for an Atlas project, To disable Encryption at Rest, pass only this parameter with a value of false, When you disable Encryption at Rest, Atlas also removes the configuration details.
     */
    enabled: boolean;
    /**
     * The AWS region in which the AWS customer master key exists: CA_CENTRAL_1, US_EAST_1, US_EAST_2, US_WEST_1, US_WEST_2, SA_EAST_1
     */
    region?: string;
    /**
     * ID of an AWS IAM role authorized to manage an AWS customer master key. To find the ID for an existing IAM role check the `roleId` attribute of the `mongodbatlasCloudProviderAccess` resource.
     */
    roleId?: string;
    secretAccessKey?: string;
}

export interface EncryptionAtRestAzureKeyVaultConfig {
    /**
     * The Azure environment where the Azure account credentials reside. Valid values are the following: AZURE, AZURE_CHINA, AZURE_GERMANY
     */
    azureEnvironment?: string;
    /**
     * The client ID, also known as the application ID, for an Azure application associated with the Azure AD tenant.
     */
    clientId?: string;
    /**
     * Specifies whether Encryption at Rest is enabled for an Atlas project. To disable Encryption at Rest, pass only this parameter with a value of false. When you disable Encryption at Rest, Atlas also removes the configuration details.
     */
    enabled: boolean;
    /**
     * The unique identifier of a key in an Azure Key Vault.
     */
    keyIdentifier?: string;
    /**
     * The name of an Azure Key Vault containing your key.
     */
    keyVaultName?: string;
    /**
     * The name of the Azure Resource group that contains an Azure Key Vault.
     */
    resourceGroupName?: string;
    /**
     * The secret associated with the Azure Key Vault specified by azureKeyVault.tenantID.
     */
    secret?: string;
    /**
     * The unique identifier associated with an Azure subscription.
     */
    subscriptionId?: string;
    /**
     * The unique identifier for an Azure AD tenant within an Azure subscription.
     */
    tenantId?: string;
}

export interface EncryptionAtRestGoogleCloudKmsConfig {
    /**
     * Specifies whether Encryption at Rest is enabled for an Atlas project. To disable Encryption at Rest, pass only this parameter with a value of false. When you disable Encryption at Rest, Atlas also removes the configuration details.
     */
    enabled: boolean;
    /**
     * The Key Version Resource ID from your GCP account.
     */
    keyVersionResourceId?: string;
    /**
     * String-formatted JSON object containing GCP KMS credentials from your GCP account.
     */
    serviceAccountKey?: string;
}

export interface EventTriggerEventProcessors {
    awsEventbridge?: outputs.EventTriggerEventProcessorsAwsEventbridge;
}

export interface EventTriggerEventProcessorsAwsEventbridge {
    configAccountId?: string;
    configRegion?: string;
}

export interface FederatedDatabaseInstanceCloudProviderConfig {
    /**
     * Name of the cloud service that hosts the data lake's data stores.
     */
    aws: outputs.FederatedDatabaseInstanceCloudProviderConfigAws;
}

export interface FederatedDatabaseInstanceCloudProviderConfigAws {
    /**
     * Unique identifier associated with the IAM Role that the Federated Database Instance assumes when accessing the data stores.
     */
    externalId: string;
    /**
     * Amazon Resource Name (ARN) of the IAM Role that the Federated Database Instance assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:
     * * `s3:GetObject`
     * * `s3:ListBucket`
     * * `s3:GetObjectVersion`
     */
    iamAssumedRoleArn: string;
    /**
     * Amazon Resource Name (ARN) of the user that the Federated Database Instance assumes when accessing S3 Bucket data stores.
     */
    iamUserArn: string;
    /**
     * Unique identifier of the role that the data lake can use to access the data stores.
     */
    roleId: string;
    testS3Bucket: string;
}

export interface FederatedDatabaseInstanceDataProcessRegion {
    cloudProvider: string;
    region: string;
}

export interface FederatedDatabaseInstanceStorageDatabase {
    collections: outputs.FederatedDatabaseInstanceStorageDatabaseCollection[];
    maxWildcardCollections: number;
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    views: outputs.FederatedDatabaseInstanceStorageDatabaseView[];
}

export interface FederatedDatabaseInstanceStorageDatabaseCollection {
    dataSources?: outputs.FederatedDatabaseInstanceStorageDatabaseCollectionDataSource[];
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
}

export interface FederatedDatabaseInstanceStorageDatabaseCollectionDataSource {
    allowInsecure: boolean;
    collection: string;
    collectionRegex: string;
    database: string;
    databaseRegex: string;
    datasetName: string;
    defaultFormat: string;
    path: string;
    provenanceFieldName: string;
    storeName: string;
    urls: string[];
}

export interface FederatedDatabaseInstanceStorageDatabaseView {
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    pipeline: string;
    source: string;
}

export interface FederatedDatabaseInstanceStorageStore {
    additionalStorageClasses: string[];
    allowInsecure: boolean;
    bucket: string;
    /**
     * @deprecated This parameter is deprecated and will be removed by September 2024.
     */
    clusterId: string;
    clusterName: string;
    defaultFormat: string;
    delimiter: string;
    includeTags: boolean;
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    prefix: string;
    /**
     * The unique ID for the project to create a Federated Database Instance.
     */
    projectId: string;
    provider: string;
    public: string;
    readPreference: outputs.FederatedDatabaseInstanceStorageStoreReadPreference;
    region: string;
    urls: string[];
}

export interface FederatedDatabaseInstanceStorageStoreReadPreference {
    maxStalenessSeconds: number;
    mode: string;
    tagSets: outputs.FederatedDatabaseInstanceStorageStoreReadPreferenceTagSet[];
}

export interface FederatedDatabaseInstanceStorageStoreReadPreferenceTagSet {
    tags: outputs.FederatedDatabaseInstanceStorageStoreReadPreferenceTagSetTag[];
}

export interface FederatedDatabaseInstanceStorageStoreReadPreferenceTagSetTag {
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    value: string;
}

export interface FederatedSettingsOrgRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId?: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId?: string;
    /**
     * Specifies the Roles that are attached to the Role Mapping. Available role IDs can be found on [the User Roles
     * Reference](https://www.mongodb.com/docs/atlas/reference/user-roles/).
     */
    roles?: string[];
}

export interface Get509AuthenticationDatabaseUserCertificate {
    createdAt: string;
    groupId: string;
    id: number;
    notAfter: string;
    subject: string;
}

export interface GetAccessListApiKeysResult {
    accessCount: number;
    cidrBlock: string;
    created: string;
    ipAddress: string;
    lastUsed: string;
    lastUsedAddress: string;
}

export interface GetAdvancedClusterAdvancedConfiguration {
    /**
     * [Default level of acknowledgment requested from MongoDB for read operations](https://docs.mongodb.com/manual/reference/read-concern/) set for this cluster. MongoDB 4.4 clusters default to [available](https://docs.mongodb.com/manual/reference/read-concern-available/).
     */
    defaultReadConcern: string;
    /**
     * [Default level of acknowledgment requested from MongoDB for write operations](https://docs.mongodb.com/manual/reference/write-concern/) set for this cluster. MongoDB 4.4 clusters default to [1](https://docs.mongodb.com/manual/reference/write-concern/).
     */
    defaultWriteConcern: string;
    /**
     * When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.
     */
    failIndexKeyTooLong: boolean;
    /**
     * When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.
     */
    javascriptEnabled: boolean;
    /**
     * Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:
     */
    minimumEnabledTlsProtocol: string;
    /**
     * When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.
     */
    noTableScan: boolean;
    /**
     * Minimum retention window for cluster's oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.
     */
    oplogMinRetentionHours: number;
    /**
     * The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.
     */
    oplogSizeMb: number;
    /**
     * Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleRefreshIntervalBiConnector: number;
    /**
     * Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleSizeBiConnector: number;
    /**
     * Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.
     */
    transactionLifetimeLimitSeconds: number;
}

export interface GetAdvancedClusterBiConnectorConfig {
    /**
     * Specifies whether or not BI Connector for Atlas is enabled on the cluster.l
     */
    enabled: boolean;
    /**
     * Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of [readPreference](https://docs.mongodb.com/manual/core/read-preference/) and [readPreferenceTags](https://docs.mongodb.com/manual/core/read-preference/#tag-sets) options. For details on BI Connector for Atlas read preferences, refer to the [BI Connector Read Preferences Table](https://docs.atlas.mongodb.com/tutorial/create-global-writes-cluster/#bic-read-preferences).
     */
    readPreference: string;
}

export interface GetAdvancedClusterConnectionString {
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    /**
     * Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster's nodes.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint. The `mongodb+srv` protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don't need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn't, use `connection_strings.private_endpoint[n].connection_string`
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don't need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn't, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateEndpoints: outputs.GetAdvancedClusterConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface GetAdvancedClusterConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.GetAdvancedClusterConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface GetAdvancedClusterConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    /**
     * Cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    region: string;
}

export interface GetAdvancedClusterLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetAdvancedClusterReplicationSpec {
    /**
     * A key-value map of the Network Peering Container ID(s) for the configuration specified in `regionConfigs`. The Container ID is the id of the container either created programmatically by the user before any clusters existed in a project or when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is `"providerName:regionName" = "containerId"`. Example `AWS:US_EAST_1" = "61e0797dde08fb498ca11a71`.
     */
    containerId: {[key: string]: string};
    id: string;
    /**
     * Provide this value if you set a `clusterType` of SHARDED or GEOSHARDED.
     */
    numShards: number;
    /**
     * Configuration for the hardware specifications for nodes set for a given regionEach `regionConfigs` object describes the region's priority in elections and the number and type of MongoDB nodes that Atlas deploys to the region. Each `regionConfigs` object must have either an `analyticsSpecs` object, `electableSpecs` object, or `readOnlySpecs` object. See below
     */
    regionConfigs: outputs.GetAdvancedClusterReplicationSpecRegionConfig[];
    /**
     * Name for the zone in a Global Cluster.
     */
    zoneName: string;
}

export interface GetAdvancedClusterReplicationSpecRegionConfig {
    /**
     * Configuration for the Collection of settings that configures analytics-auto-scaling information for the cluster. See below
     */
    analyticsAutoScalings: outputs.GetAdvancedClusterReplicationSpecRegionConfigAnalyticsAutoScaling[];
    /**
     * Hardware specifications for [analytics nodes](https://docs.atlas.mongodb.com/reference/faq/deployment/#std-label-analytics-nodes-overview) needed in the region. See below
     */
    analyticsSpecs?: outputs.GetAdvancedClusterReplicationSpecRegionConfigAnalyticsSpecs;
    /**
     * Configuration for the Collection of settings that configures auto-scaling information for the cluster. See below
     */
    autoScalings: outputs.GetAdvancedClusterReplicationSpecRegionConfigAutoScaling[];
    /**
     * Cloud service provider on which you provision the host for a multi-tenant cluster.
     */
    backingProviderName: string;
    /**
     * Hardware specifications for electable nodes in the region.
     */
    electableSpecs?: outputs.GetAdvancedClusterReplicationSpecRegionConfigElectableSpecs;
    /**
     * Election priority of the region.
     */
    priority: number;
    /**
     * Cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    /**
     * Hardware specifications for read-only nodes in the region. See below
     */
    readOnlySpecs?: outputs.GetAdvancedClusterReplicationSpecRegionConfigReadOnlySpecs;
    /**
     * Physical location of your MongoDB cluster.
     */
    regionName: string;
}

export interface GetAdvancedClusterReplicationSpecRegionConfigAnalyticsAutoScaling {
    /**
     * Flag that indicates whether instance size auto-scaling is enabled.
     */
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40). 
     * #### Advanced Configuration
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10).
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down.
     */
    computeScaleDownEnabled: boolean;
    /**
     * Flag that indicates whether this cluster enables disk auto-scaling.
     */
    diskGbEnabled: boolean;
}

export interface GetAdvancedClusterReplicationSpecRegionConfigAnalyticsSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClusterReplicationSpecRegionConfigAutoScaling {
    /**
     * Flag that indicates whether instance size auto-scaling is enabled.
     */
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40). 
     * #### Advanced Configuration
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10).
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down.
     */
    computeScaleDownEnabled: boolean;
    /**
     * Flag that indicates whether this cluster enables disk auto-scaling.
     */
    diskGbEnabled: boolean;
}

export interface GetAdvancedClusterReplicationSpecRegionConfigElectableSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClusterReplicationSpecRegionConfigReadOnlySpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClusterTag {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetAdvancedClustersResult {
    /**
     * Get the advanced configuration options. See Advanced Configuration below for more details.
     */
    advancedConfigurations: outputs.GetAdvancedClustersResultAdvancedConfiguration[];
    backupEnabled: boolean;
    /**
     * Configuration settings applied to BI Connector for Atlas on this cluster. See below. **NOTE** Prior version of provider had parameter as `biConnector`
     */
    biConnectorConfigs: outputs.GetAdvancedClustersResultBiConnectorConfig[];
    /**
     * Type of the cluster that you want to create.
     */
    clusterType: string;
    /**
     * Set of connection strings that your applications use to connect to this cluster. More info in [Connection-strings](https://docs.mongodb.com/manual/reference/connection-string/). Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see [Connection String Options](https://docs.atlas.mongodb.com/reference/faq/connection-changes/). NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.
     */
    connectionStrings: outputs.GetAdvancedClustersResultConnectionString[];
    createDate: string;
    /**
     * Capacity, in gigabytes, of the host's root volume.
     */
    diskSizeGb: number;
    /**
     * Possible values are AWS, GCP, AZURE or NONE.
     */
    encryptionAtRestProvider: string;
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     *
     * @deprecated This parameter is deprecated and will be removed by September 2024. Please transition to tags.
     */
    labels: outputs.GetAdvancedClustersResultLabel[];
    /**
     * Version of the cluster to deploy.
     */
    mongoDbMajorVersion: string;
    /**
     * Version of MongoDB the cluster runs, in `major-version`.`minor-version` format.
     */
    mongoDbVersion: string;
    name: string;
    /**
     * Flag that indicates whether the cluster is paused or not.
     */
    paused: boolean;
    /**
     * Flag that indicates if the cluster uses Continuous Cloud Backup.
     */
    pitEnabled: boolean;
    /**
     * Configuration for cluster regions and the hardware provisioned in them. See below
     */
    replicationSpecs: outputs.GetAdvancedClustersResultReplicationSpec[];
    /**
     * Certificate Authority that MongoDB Atlas clusters use.
     */
    rootCertType: string;
    /**
     * Current state of the cluster. The possible states are:
     */
    stateName: string;
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     */
    tags: outputs.GetAdvancedClustersResultTag[];
    /**
     * Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won't delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
     */
    terminationProtectionEnabled: boolean;
    /**
     * Release cadence that Atlas uses for this cluster.
     */
    versionReleaseSystem: string;
}

export interface GetAdvancedClustersResultAdvancedConfiguration {
    /**
     * [Default level of acknowledgment requested from MongoDB for read operations](https://docs.mongodb.com/manual/reference/read-concern/) set for this cluster. MongoDB 4.4 clusters default to [available](https://docs.mongodb.com/manual/reference/read-concern-available/).
     */
    defaultReadConcern: string;
    /**
     * [Default level of acknowledgment requested from MongoDB for write operations](https://docs.mongodb.com/manual/reference/write-concern/) set for this cluster. MongoDB 4.4 clusters default to [1](https://docs.mongodb.com/manual/reference/write-concern/).
     */
    defaultWriteConcern: string;
    /**
     * When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.
     */
    failIndexKeyTooLong: boolean;
    /**
     * When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.
     */
    javascriptEnabled: boolean;
    /**
     * Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:
     */
    minimumEnabledTlsProtocol: string;
    /**
     * When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.
     */
    noTableScan: boolean;
    /**
     * Minimum retention window for cluster's oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.
     */
    oplogMinRetentionHours: number;
    /**
     * The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.
     */
    oplogSizeMb: number;
    /**
     * Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleRefreshIntervalBiConnector: number;
    /**
     * Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleSizeBiConnector: number;
    transactionLifetimeLimitSeconds: number;
}

export interface GetAdvancedClustersResultBiConnectorConfig {
    /**
     * Specifies whether or not BI Connector for Atlas is enabled on the cluster.l
     */
    enabled: boolean;
    /**
     * Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of [readPreference](https://docs.mongodb.com/manual/core/read-preference/) and [readPreferenceTags](https://docs.mongodb.com/manual/core/read-preference/#tag-sets) options. For details on BI Connector for Atlas read preferences, refer to the [BI Connector Read Preferences Table](https://docs.atlas.mongodb.com/tutorial/create-global-writes-cluster/#bic-read-preferences).
     */
    readPreference: string;
}

export interface GetAdvancedClustersResultConnectionString {
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    /**
     * Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster's nodes.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint. The `mongodb+srv` protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don't need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn't, use `connection_strings.private_endpoint[n].connection_string`
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don't need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn't, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateEndpoints: outputs.GetAdvancedClustersResultConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface GetAdvancedClustersResultConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.GetAdvancedClustersResultConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface GetAdvancedClustersResultConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    /**
     * Cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    region: string;
}

export interface GetAdvancedClustersResultLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetAdvancedClustersResultReplicationSpec {
    /**
     * A key-value map of the Network Peering Container ID(s) for the configuration specified in `regionConfigs`. The Container ID is the id of the container either created programmatically by the user before any clusters existed in a project or when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is `"providerName:regionName" = "containerId"`. Example `AWS:US_EAST_1" = "61e0797dde08fb498ca11a71`.
     */
    containerId: {[key: string]: string};
    id: string;
    /**
     * Provide this value if you set a `clusterType` of SHARDED or GEOSHARDED.
     */
    numShards: number;
    /**
     * Configuration for the hardware specifications for nodes set for a given regionEach `regionConfigs` object describes the region's priority in elections and the number and type of MongoDB nodes that Atlas deploys to the region. Each `regionConfigs` object must have either an `analyticsSpecs` object, `electableSpecs` object, or `readOnlySpecs` object. See below
     */
    regionConfigs: outputs.GetAdvancedClustersResultReplicationSpecRegionConfig[];
    /**
     * Name for the zone in a Global Cluster.
     */
    zoneName: string;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfig {
    /**
     * Configuration for the Collection of settings that configures analytis-auto-scaling information for the cluster. See below
     */
    analyticsAutoScalings: outputs.GetAdvancedClustersResultReplicationSpecRegionConfigAnalyticsAutoScaling[];
    /**
     * Hardware specifications for [analytics nodes](https://docs.atlas.mongodb.com/reference/faq/deployment/#std-label-analytics-nodes-overview) needed in the region. See below
     */
    analyticsSpecs?: outputs.GetAdvancedClustersResultReplicationSpecRegionConfigAnalyticsSpecs;
    /**
     * Configuration for the Collection of settings that configures auto-scaling information for the cluster. See below
     */
    autoScalings: outputs.GetAdvancedClustersResultReplicationSpecRegionConfigAutoScaling[];
    /**
     * Cloud service provider on which you provision the host for a multi-tenant cluster.
     */
    backingProviderName: string;
    /**
     * Hardware specifications for electable nodes in the region.
     */
    electableSpecs?: outputs.GetAdvancedClustersResultReplicationSpecRegionConfigElectableSpecs;
    /**
     * Election priority of the region.
     */
    priority: number;
    /**
     * Cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    /**
     * Hardware specifications for read-only nodes in the region. See below
     */
    readOnlySpecs?: outputs.GetAdvancedClustersResultReplicationSpecRegionConfigReadOnlySpecs;
    /**
     * Physical location of your MongoDB cluster.
     */
    regionName: string;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfigAnalyticsAutoScaling {
    /**
     * Flag that indicates whether instance size auto-scaling is enabled.
     */
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40).
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10).
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down.
     */
    computeScaleDownEnabled: boolean;
    /**
     * Flag that indicates whether this cluster enables disk auto-scaling.
     */
    diskGbEnabled: boolean;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfigAnalyticsSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfigAutoScaling {
    /**
     * Flag that indicates whether instance size auto-scaling is enabled.
     */
    computeEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale (such as M40).
     */
    computeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale (such as M10).
     */
    computeMinInstanceSize: string;
    /**
     * Flag that indicates whether the instance size may scale down.
     */
    computeScaleDownEnabled: boolean;
    /**
     * Flag that indicates whether this cluster enables disk auto-scaling.
     */
    diskGbEnabled: boolean;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfigElectableSpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClustersResultReplicationSpecRegionConfigReadOnlySpecs {
    /**
     * Target throughput (IOPS) desired for AWS storage attached to your cluster.
     */
    diskIops: number;
    /**
     * Type of storage you want to attach to your AWS-provisioned cluster.
     */
    ebsVolumeType?: string;
    /**
     * Hardware specification for the instance sizes in this region.
     */
    instanceSize: string;
    /**
     * Number of nodes of the given type for MongoDB Atlas to deploy to the region.
     */
    nodeCount?: number;
}

export interface GetAdvancedClustersResultTag {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetAlertConfigurationMatcher {
    /**
     * Name of the field in the target object to match on.
     */
    fieldName: string;
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Value to test with the specified operator. If `fieldName` is set to TYPE_NAME, you can match on the following values:
     */
    value: string;
}

export interface GetAlertConfigurationMetricThresholdConfig {
    /**
     * Name of the metric to check. The full list being quite large, please refer to atlas docs [here for general metrics](https://docs.atlas.mongodb.com/reference/alert-host-metrics/#measurement-types) and [here for serverless metrics](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-create-config/#serverless-measurements)
     */
    metricName: string;
    /**
     * This must be set to AVERAGE. Atlas computes the current metric value as an average.
     */
    mode: string;
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Threshold value outside of which an alert will be triggered.
     */
    threshold: number;
    /**
     * The units for the threshold value. Depends on the type of metric.
     * Refer to the [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-get-config/#request-body-parameters) for a list of accepted values.
     */
    units: string;
}

export interface GetAlertConfigurationNotification {
    /**
     * Slack API token. Required for the SLACK notifications type. If the token later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.
     */
    apiToken: string;
    /**
     * Slack channel name. Required for the SLACK notifications type.
     */
    channelName: string;
    /**
     * Datadog API Key. Found in the Datadog dashboard. Required for the DATADOG notifications type.
     */
    datadogApiKey: string;
    /**
     * Region that indicates which API URL to use. See the `datadogRegion` field in the `notifications` request parameter of [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/v2/#tag/Alert-Configurations/operation/createAlertConfiguration) for more details. The default Datadog region is US.
     */
    datadogRegion: string;
    /**
     * Number of minutes to wait after an alert condition is detected before sending out the first notification.
     */
    delayMin: number;
    /**
     * Email address to which alert notifications are sent. Required for the EMAIL notifications type.
     */
    emailAddress: string;
    /**
     * Flag indicating email notifications should be sent. Atlas returns this value if `typeName` is set  to `ORG`, `GROUP`, or `USER`.
     */
    emailEnabled: boolean;
    /**
     * The ID of the associated integration, the credentials of which to use for requests.
     */
    integrationId: string;
    /**
     * Number of minutes to wait between successive notifications for unacknowledged alerts that are not resolved. The minimum value is 5.
     */
    intervalMin: number;
    /**
     * Microsoft Teams channel incoming webhook URL. Required for the `MICROSOFT_TEAMS` notifications type.
     */
    microsoftTeamsWebhookUrl: string;
    /**
     * Mobile number to which alert notifications are sent. Required for the SMS notifications type.
     */
    mobileNumber: string;
    /**
     * The notifier ID is a system-generated unique identifier assigned to each notification method. This is needed when updating third-party notifications without requiring explicit authentication credentials.
     */
    notifierId: string;
    /**
     * Opsgenie API Key. Required for the `OPS_GENIE` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.
     */
    opsGenieApiKey: string;
    /**
     * Region that indicates which API URL to use. Accepted regions are: `US` ,`EU`. The default Opsgenie region is US.
     */
    opsGenieRegion: string;
    /**
     * Atlas role in current Project or Organization. Atlas returns this value if you set `typeName` to `ORG` or `GROUP`.
     */
    roles: string[];
    /**
     * PagerDuty service key. Required for the PAGER_DUTY notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    serviceKey: string;
    /**
     * Flag indicating text notifications should be sent. Atlas returns this value if `typeName` is set to `ORG`, `GROUP`, or `USER`.
     */
    smsEnabled: boolean;
    /**
     * Unique identifier of a team.
     */
    teamId: string;
    /**
     * Label for the team that receives this notification.
     */
    teamName: string;
    /**
     * Type of alert notification.
     * Accepted values are:
     */
    typeName: string;
    /**
     * Name of the Atlas user to which to send notifications. Only a user in the project that owns the alert configuration is allowed here. Required for the `USER` notifications type.
     */
    username: string;
    /**
     * VictorOps API key. Required for the `VICTOR_OPS` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    victorOpsApiKey: string;
    /**
     * VictorOps routing key. Optional for the `VICTOR_OPS` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    victorOpsRoutingKey: string;
    /**
     * Authentication secret for the `WEBHOOK` notifications type.
     */
    webhookSecret: string;
    /**
     * Target URL  for the `WEBHOOK` notifications type.
     */
    webhookUrl: string;
}

export interface GetAlertConfigurationOutput {
    label?: string;
    type: string;
    /**
     * Value to test with the specified operator. If `fieldName` is set to TYPE_NAME, you can match on the following values:
     */
    value: string;
}

export interface GetAlertConfigurationThresholdConfig {
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Threshold value outside of which an alert will be triggered.
     */
    threshold: number;
    /**
     * The units for the threshold value. Depends on the type of metric.
     * Refer to the [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-get-config/#request-body-parameters) for a list of accepted values.
     */
    units: string;
}

export interface GetAlertConfigurationsListOption {
    includeCount?: boolean;
    itemsPerPage?: number;
    pageNum?: number;
}

export interface GetAlertConfigurationsResult {
    /**
     * The ID of the alert configuration
     */
    alertConfigurationId: string;
    /**
     * Timestamp in ISO 8601 date and time format in UTC when this alert configuration was created.
     */
    created: string;
    /**
     * If set to true, the alert configuration is enabled. If enabled is not exported it is set to false.
     */
    enabled: boolean;
    /**
     * The type of event that will trigger an alert.
     */
    eventType: string;
    id: string;
    /**
     * Rules to apply when matching an object against this alert configuration. See matchers.
     */
    matchers: outputs.GetAlertConfigurationsResultMatcher[];
    /**
     * The threshold that causes an alert to be triggered. Required if `eventTypeName` : `OUTSIDE_METRIC_THRESHOLD` or `OUTSIDE_SERVERLESS_METRIC_THRESHOLD`. See metric threshold config.
     */
    metricThresholdConfigs: outputs.GetAlertConfigurationsResultMetricThresholdConfig[];
    notifications: outputs.GetAlertConfigurationsResultNotification[];
    /**
     * Requested output string format for the alert configuration
     */
    outputs: outputs.GetAlertConfigurationsResultOutput[];
    /**
     * The unique ID for the project to get the alert configurations.
     */
    projectId: string;
    /**
     * Threshold that triggers an alert. Required if `eventTypeName` is any value other than `OUTSIDE_METRIC_THRESHOLD` or `OUTSIDE_SERVERLESS_METRIC_THRESHOLD`. See threshold config.
     */
    thresholdConfigs: outputs.GetAlertConfigurationsResultThresholdConfig[];
    /**
     * Timestamp in ISO 8601 date and time format in UTC when this alert configuration was last updated.
     */
    updated: string;
}

export interface GetAlertConfigurationsResultMatcher {
    /**
     * Name of the field in the target object to match on.
     */
    fieldName: string;
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Value to test with the specified operator. If `fieldName` is set to TYPE_NAME, you can match on the following values:
     */
    value: string;
}

export interface GetAlertConfigurationsResultMetricThresholdConfig {
    /**
     * Name of the metric to check. The full list being quite large, please refer to atlas docs [here for general metrics](https://docs.atlas.mongodb.com/reference/alert-host-metrics/#measurement-types) and [here for serverless metrics](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-create-config/#serverless-measurements)
     */
    metricName: string;
    /**
     * This must be set to AVERAGE. Atlas computes the current metric value as an average.
     */
    mode: string;
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Threshold value outside of which an alert will be triggered.
     */
    threshold: number;
    /**
     * The units for the threshold value. Depends on the type of metric.
     * Refer to the [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-get-config/#request-body-parameters) for a list of accepted values.
     */
    units: string;
}

export interface GetAlertConfigurationsResultNotification {
    /**
     * Slack API token. Required for the SLACK notifications type. If the token later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.
     */
    apiToken: string;
    /**
     * Slack channel name. Required for the SLACK notifications type.
     */
    channelName: string;
    /**
     * Datadog API Key. Found in the Datadog dashboard. Required for the DATADOG notifications type.
     */
    datadogApiKey: string;
    /**
     * Region that indicates which API URL to use. See the `datadogRegion` field in the `notifications` request parameter of [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/v2/#tag/Alert-Configurations/operation/createAlertConfiguration) for more details. The default Datadog region is US.
     */
    datadogRegion: string;
    /**
     * Number of minutes to wait after an alert condition is detected before sending out the first notification.
     */
    delayMin: number;
    /**
     * Email address to which alert notifications are sent. Required for the EMAIL notifications type.
     */
    emailAddress: string;
    /**
     * Flag indicating email notifications should be sent. Atlas returns this value if `typeName` is set  to `ORG`, `GROUP`, or `USER`.
     */
    emailEnabled: boolean;
    /**
     * The ID of the associated integration, the credentials of which to use for requests.
     */
    integrationId: string;
    /**
     * Number of minutes to wait between successive notifications for unacknowledged alerts that are not resolved. The minimum value is 5.
     */
    intervalMin: number;
    /**
     * Microsoft Teams channel incoming webhook URL. Required for the `MICROSOFT_TEAMS` notifications type.
     */
    microsoftTeamsWebhookUrl: string;
    /**
     * Mobile number to which alert notifications are sent. Required for the SMS notifications type.
     */
    mobileNumber: string;
    /**
     * The notifier ID is a system-generated unique identifier assigned to each notification method. This is needed when updating third-party notifications without requiring explicit authentication credentials.
     */
    notifierId: string;
    /**
     * Opsgenie API Key. Required for the `OPS_GENIE` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.
     */
    opsGenieApiKey: string;
    /**
     * Region that indicates which API URL to use. Accepted regions are: `US` ,`EU`. The default Opsgenie region is US.
     */
    opsGenieRegion: string;
    /**
     * Atlas role in current Project or Organization. Atlas returns this value if you set `typeName` to `ORG` or `GROUP`.
     */
    roles: string[];
    /**
     * PagerDuty service key. Required for the PAGER_DUTY notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    serviceKey: string;
    /**
     * Flag indicating text notifications should be sent. Atlas returns this value if `typeName` is set to `ORG`, `GROUP`, or `USER`.
     */
    smsEnabled: boolean;
    /**
     * Unique identifier of a team.
     */
    teamId: string;
    /**
     * Label for the team that receives this notification.
     */
    teamName: string;
    /**
     * Type of alert notification.
     * Accepted values are:
     */
    typeName: string;
    /**
     * Name of the Atlas user to which to send notifications. Only a user in the project that owns the alert configuration is allowed here. Required for the `USER` notifications type.
     */
    username: string;
    /**
     * VictorOps API key. Required for the `VICTOR_OPS` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    victorOpsApiKey: string;
    /**
     * VictorOps routing key. Optional for the `VICTOR_OPS` notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.
     */
    victorOpsRoutingKey: string;
    /**
     * Authentication secret for the `WEBHOOK` notifications type.
     */
    webhookSecret: string;
    /**
     * Target URL  for the `WEBHOOK` notifications type.
     */
    webhookUrl: string;
}

export interface GetAlertConfigurationsResultOutput {
    label: string;
    type: string;
    /**
     * Value to test with the specified operator. If `fieldName` is set to TYPE_NAME, you can match on the following values:
     */
    value: string;
}

export interface GetAlertConfigurationsResultThresholdConfig {
    /**
     * The operator to apply when checking the current metric value against the threshold value.
     * Accepted values are:
     */
    operator: string;
    /**
     * Threshold value outside of which an alert will be triggered.
     */
    threshold: number;
    /**
     * The units for the threshold value. Depends on the type of metric.
     * Refer to the [MongoDB API Alert Configuration documentation](https://www.mongodb.com/docs/atlas/reference/api/alert-configurations-get-config/#request-body-parameters) for a list of accepted values.
     */
    units: string;
}

export interface GetApiKeysResult {
    apiKeyId: string;
    description: string;
    publicKey: string;
    roleNames: string[];
}

export interface GetAtlasUserLink {
    href: string;
    rel: string;
}

export interface GetAtlasUserRole {
    groupId: string;
    orgId: string;
    roleName: string;
}

export interface GetAtlasUsersResult {
    /**
     * Two alphabet characters that identifies MongoDB Cloud user's geographic location. This parameter uses the ISO 3166-1a2 code format.
     */
    country: string;
    /**
     * Date and time when the current account is created. This value is in the ISO 8601 timestamp format in UTC.
     */
    createdAt: string;
    /**
     * Email address that belongs to the MongoDB Atlas user.
     */
    emailAddress: string;
    /**
     * First or given name that belongs to the MongoDB Atlas user.
     */
    firstName: string;
    id: string;
    /**
     * Date and time when the current account last authenticated. This value is in the ISO 8601 timestamp format in UTC.
     */
    lastAuth: string;
    /**
     * Last name, family name, or surname that belongs to the MongoDB Atlas user.
     */
    lastName: string;
    links: outputs.GetAtlasUsersResultLink[];
    /**
     * Mobile phone number that belongs to the MongoDB Atlas user.
     */
    mobileNumber: string;
    roles: outputs.GetAtlasUsersResultRole[];
    /**
     * List of unique 24-hexadecimal digit strings that identifies the teams to which this MongoDB Atlas user belongs.
     * * `links.#.href` - Uniform Resource Locator (URL) that points another API resource to which this response has some relationship. This URL often begins with https://cloud.mongodb.com/api/atlas.
     * * `links.#.rel` - Uniform Resource Locator (URL) that defines the semantic relationship between this resource and another API resource. This URL often begins with https://cloud.mongodb.com/api/atlas.
     * * `roles.#.group_id` - Unique 24-hexadecimal digit string that identifies the project to which this role belongs. You can set a value for this parameter or orgId but not both in the same request.
     * * `roles.#.org_id` - Unique 24-hexadecimal digit string that identifies the organization to which this role belongs. You can set a value for this parameter or groupId but not both in the same request.
     * * `roles.#.role_name` - Human-readable label that identifies the collection of privileges that MongoDB Atlas grants a specific API key, user, or team. These roles include organization- and project-level roles. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#service-user-roles) describes the valid roles that can be assigned.
     */
    teamIds: string[];
    /**
     * Unique 24-hexadecimal digit string that identifies this user.
     */
    userId: string;
    /**
     * Email address that belongs to the MongoDB Atlas user account. You cannot modify this address after creating the user.
     */
    username: string;
}

export interface GetAtlasUsersResultLink {
    href: string;
    rel: string;
}

export interface GetAtlasUsersResultRole {
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization whose users you want to return. Also needed when `teamId` attributes is defined.
     */
    orgId: string;
    roleName: string;
}

export interface GetBackupCompliancePolicyOnDemandPolicyItem {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetBackupCompliancePolicyPolicyItemDaily {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetBackupCompliancePolicyPolicyItemHourly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetBackupCompliancePolicyPolicyItemMonthly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetBackupCompliancePolicyPolicyItemWeekly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetBackupCompliancePolicyPolicyItemYearly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupScheduleCopySetting {
    /**
     * Human-readable label that identifies the cloud provider that stores the snapshot copy. i.e. "AWS" "AZURE" "GCP"
     */
    cloudProvider: string;
    /**
     * List that describes which types of snapshots to copy. i.e. "HOURLY" "DAILY" "WEEKLY" "MONTHLY" "YEARLY" "ON_DEMAND"
     */
    frequencies: string[];
    /**
     * Target region to copy snapshots belonging to replicationSpecId to. Please supply the 'Atlas Region' which can be found under https://www.mongodb.com/docs/atlas/reference/cloud-providers/ 'regions' link
     */
    regionName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the replication object for a zone in a cluster. For global clusters, there can be multiple zones to choose from. For sharded clusters and replica set clusters, there is only one zone in the cluster. To find the Replication Spec Id, consult the replicationSpecs array returned from [Return One Multi-Cloud Cluster in One Project](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/v2/#tag/Clusters/operation/getCluster).
     */
    replicationSpecId: string;
    /**
     * Flag that indicates whether to copy the oplogs to the target region. You can use the oplogs to perform point-in-time restores.
     */
    shouldCopyOplogs: boolean;
}

export interface GetCloudBackupScheduleExport {
    /**
     * Unique identifier of the mongodbatlas.CloudBackupSnapshotExportBucket export_bucket_id value.
     */
    exportBucketId: string;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
}

export interface GetCloudBackupSchedulePolicyItemDaily {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupSchedulePolicyItemHourly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupSchedulePolicyItemMonthly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupSchedulePolicyItemWeekly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupSchedulePolicyItemYearly {
    /**
     * Desired frequency of the new backup policy item specified by `frequencyType` (yearly in this case). The supported values for yearly policies are
     */
    frequencyInterval: number;
    /**
     * Frequency associated with the backup policy item. For yearly policies, the frequency type is defined as `yearly`. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.
     */
    frequencyType: string;
    /**
     * Unique identifier of the backup policy item.
     */
    id: string;
    /**
     * Scope of the backup policy item: `days`, `weeks`, `months`, or `years`.
     */
    retentionUnit: string;
    /**
     * Value to associate with `retentionUnit`. Yearly policy must have retention of at least 1 year.
     */
    retentionValue: number;
}

export interface GetCloudBackupSnapshotExportBucketsResult {
    /**
     * Name of the bucket that the provided role ID is authorized to access. You must also specify the `iamRoleId`.
     */
    bucketName: string;
    /**
     * Name of the provider of the cloud service where Atlas can access the S3 bucket. Atlas only supports `AWS`.
     */
    cloudProvider: string;
    /**
     * Unique identifier of the snapshot bucket id.
     */
    exportBucketId: string;
    /**
     * Unique identifier of the role that Atlas can use to access the bucket. You must also specify the `bucketName`.
     */
    iamRoleId: string;
}

export interface GetCloudBackupSnapshotExportJobComponent {
    /**
     * _Returned for sharded clusters only._ Export job details for each replica set in the sharded cluster.
     */
    exportId: string;
    /**
     * _Returned for sharded clusters only._ Unique identifier of the export job for the replica set.
     */
    replicaSetName: string;
}

export interface GetCloudBackupSnapshotExportJobCustomData {
    /**
     * Custom data specified as key in the key and value pair.
     */
    key: string;
    /**
     * Value for the key specified using `key`.
     */
    value: string;
}

export interface GetCloudBackupSnapshotExportJobsResult {
    /**
     * _Returned for sharded clusters only._ Export job details for each replica set in the sharded cluster.
     */
    components: outputs.GetCloudBackupSnapshotExportJobsResultComponent[];
    /**
     * Timestamp in ISO 8601 date and time format in UTC when the export job was created.
     */
    createdAt: string;
    /**
     * Custom data to include in the metadata file named `.complete` that Atlas uploads to the bucket when the export job finishes. Custom data can be specified as key and value pairs.
     */
    customDatas: outputs.GetCloudBackupSnapshotExportJobsResultCustomData[];
    /**
     * Error message, only if the export job failed.
     */
    errMsg: string;
    /**
     * Unique identifier of the AWS bucket to export the Cloud Backup snapshot to.
     */
    exportBucketId: string;
    /**
     * Unique identifier of the export job.
     * * `prefix ` - Full path on the cloud provider bucket to the folder where the snapshot is exported. The path is in the following format:`/exported_snapshots/{ORG-NAME}/{PROJECT-NAME}/{CLUSTER-NAME}/{SNAPSHOT-INITIATION-DATE}/{TIMESTAMP}`
     */
    exportJobId: string;
    exportStatusExportedCollections: number;
    exportStatusTotalCollections: number;
    /**
     * Timestamp in ISO 8601 date and time format in UTC when the export job completes.
     */
    finishedAt: string;
    prefix: string;
    /**
     * Unique identifier of the Cloud Backup snapshot to export.
     */
    snapshotId: string;
    /**
     * Status of the export job. Value can be one of the following:
     */
    state: string;
}

export interface GetCloudBackupSnapshotExportJobsResultComponent {
    /**
     * _Returned for sharded clusters only._ Export job details for each replica set in the sharded cluster.
     */
    exportId: string;
    /**
     * _Returned for sharded clusters only._ Unique identifier of the export job for the replica set.
     */
    replicaSetName: string;
}

export interface GetCloudBackupSnapshotExportJobsResultCustomData {
    /**
     * Custom data specified as key in the key and value pair.
     */
    key: string;
    /**
     * Value for the key specified using `key`.
     */
    value: string;
}

export interface GetCloudBackupSnapshotMember {
    /**
     * Cloud provider that stores this snapshot.
     */
    cloudProvider: string;
    /**
     * Unique identifier for the sharded cluster snapshot.
     */
    id: string;
    /**
     * Label given to a shard or config server from which Atlas took this snapshot.
     */
    replicaSetName: string;
}

export interface GetCloudBackupSnapshotRestoreJobsResult {
    /**
     * Indicates whether the restore job was canceled.
     */
    cancelled: boolean;
    /**
     * UTC ISO 8601 formatted point in time when Atlas created the restore job.
     */
    createdAt: string;
    /**
     * Type of restore job to create. Possible values are: automated and download.
     */
    deliveryType: string;
    /**
     * One or more URLs for the compressed snapshot files for manual download. Only visible if deliveryType is download.
     */
    deliveryUrls: string[];
    /**
     * Indicates whether the restore job expired.
     */
    expired: boolean;
    /**
     * UTC ISO 8601 formatted point in time when the restore job expires.
     */
    expiresAt: string;
    /**
     * UTC ISO 8601 formatted point in time when the restore job completed.
     */
    finishedAt: string;
    /**
     * The unique identifier of the restore job.
     */
    id: string;
    oplogInc: number;
    oplogTs: number;
    pointInTimeUtcSeconds: number;
    /**
     * Unique identifier of the source snapshot ID of the restore job.
     */
    snapshotId: string;
    /**
     * Name of the target Atlas cluster to which the restore job restores the snapshot. Only visible if deliveryType is automated.
     */
    targetClusterName: string;
    /**
     * Name of the target Atlas project of the restore job. Only visible if deliveryType is automated.
     */
    targetProjectId: string;
    /**
     * Timestamp in ISO 8601 date and time format in UTC when the snapshot associated to snapshotId was taken.
     */
    timestamp: string;
}

export interface GetCloudBackupSnapshotsResult {
    /**
     * Cloud provider that stores this snapshot.
     */
    cloudProvider: string;
    /**
     * UTC ISO 8601 formatted point in time when Atlas took the snapshot.
     */
    createdAt: string;
    /**
     * UDescription of the snapshot. Only present for on-demand snapshots.
     */
    description: string;
    /**
     * UTC ISO 8601 formatted point in time when Atlas will delete the snapshot.
     */
    expiresAt: string;
    /**
     * Unique identifier for the sharded cluster snapshot.
     */
    id: string;
    /**
     * Unique ID of the AWS KMS Customer Master Key used to encrypt the snapshot. Only visible for clusters using Encryption at Rest via Customer KMS.
     */
    masterKeyUuid: string;
    /**
     * Block of List of snapshots and the cloud provider where the snapshots are stored. See below
     */
    members: outputs.GetCloudBackupSnapshotsResultMember[];
    /**
     * Version of the MongoDB server.
     */
    mongodVersion: string;
    /**
     * Label given to a shard or config server from which Atlas took this snapshot.
     */
    replicaSetName: string;
    /**
     * Unique identifiers of the snapshots created for the shards and config server for a sharded cluster.
     */
    snapshotIds: string[];
    /**
     * Specified the type of snapshot. Valid values are onDemand and scheduled.
     */
    snapshotType: string;
    /**
     * Current status of the snapshot. One of the following values: queued, inProgress, completed, failed.
     */
    status: string;
    /**
     * Specifies the size of the snapshot in bytes.
     */
    storageSizeBytes: number;
    /**
     * Specifies the type of cluster: replicaSet or shardedCluster.
     */
    type: string;
}

export interface GetCloudBackupSnapshotsResultMember {
    /**
     * Cloud provider that stores this snapshot.
     */
    cloudProvider: string;
    /**
     * Unique identifier for the sharded cluster snapshot.
     */
    id: string;
    /**
     * Label given to a shard or config server from which Atlas took this snapshot.
     */
    replicaSetName: string;
}

export interface GetCloudProviderAccessSetupAwsConfig {
    /**
     * Unique external ID Atlas uses when assuming the IAM role in your AWS account.
     */
    atlasAssumedRoleExternalId: string;
    /**
     * ARN associated with the Atlas AWS account used to assume IAM roles in your AWS account.
     */
    atlasAwsAccountArn: string;
}

export interface GetCloudProviderAccessSetupAzureConfig {
    /**
     * Azure Active Directory Application ID of Atlas.
     */
    atlasAzureAppId: string;
    /**
     * UUID string that identifies the Azure Service Principal.
     */
    servicePrincipalId: string;
    /**
     * UUID String that identifies the Azure Active Directory Tenant ID.
     */
    tenantId: string;
}

export interface GetClusterAdvancedConfiguration {
    /**
     * [Default level of acknowledgment requested from MongoDB for read operations](https://docs.mongodb.com/manual/reference/read-concern/) set for this cluster. MongoDB 4.4 clusters default to [available](https://docs.mongodb.com/manual/reference/read-concern-available/).
     */
    defaultReadConcern: string;
    /**
     * [Default level of acknowledgment requested from MongoDB for write operations](https://docs.mongodb.com/manual/reference/write-concern/) set for this cluster. MongoDB 4.4 clusters default to [1](https://docs.mongodb.com/manual/reference/write-concern/).
     */
    defaultWriteConcern: string;
    /**
     * When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.
     */
    failIndexKeyTooLong: boolean;
    /**
     * When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.
     */
    javascriptEnabled: boolean;
    /**
     * Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:
     */
    minimumEnabledTlsProtocol: string;
    /**
     * When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.
     */
    noTableScan: boolean;
    /**
     * Minimum retention window for cluster's oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.
     */
    oplogMinRetentionHours: number;
    /**
     * The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.
     */
    oplogSizeMb: number;
    /**
     * Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleRefreshIntervalBiConnector: number;
    /**
     * Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleSizeBiConnector: number;
    /**
     * Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.
     */
    transactionLifetimeLimitSeconds: number;
}

export interface GetClusterBiConnectorConfig {
    /**
     * Indicates whether or not BI Connector for Atlas is enabled on the cluster.
     */
    enabled: boolean;
    /**
     * Indicates the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of [readPreference](https://docs.mongodb.com/manual/core/read-preference/) and [readPreferenceTags](https://docs.mongodb.com/manual/core/read-preference/#tag-sets) options. For details on BI Connector for Atlas read preferences, refer to the [BI Connector Read Preferences Table](https://docs.atlas.mongodb.com/tutorial/create-global-writes-cluster/#bic-read-preferences).
     */
    readPreference: string;
}

export interface GetClusterConnectionString {
    awsPrivateLink: {[key: string]: any};
    awsPrivateLinkSrv: {[key: string]: any};
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    privateEndpoints: outputs.GetClusterConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t, use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface GetClusterConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.GetClusterConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface GetClusterConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    /**
     * Indicates the cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    region: string;
}

export interface GetClusterLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetClusterOutageSimulationOutageFilter {
    /**
     * The cloud provider of the region that undergoes the outage simulation. Following values are supported:
     */
    cloudProvider: string;
    /**
     * The Atlas name of the region undergoing an outage simulation.
     */
    regionName: string;
    /**
     * The type of cluster outage simulation. Following values are supported:
     */
    type: string;
}

export interface GetClusterReplicationSpec {
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    /**
     * Number of shards to deploy in the specified zone.
     */
    numShards: number;
    /**
     * Describes the physical location of the region. Each regionsConfig document describes the region’s priority in elections and the number and type of MongoDB nodes Atlas deploys to the region. You must order each regionsConfigs document by regionsConfig.priority, descending. See Region Config below for more details.
     */
    regionsConfigs: outputs.GetClusterReplicationSpecRegionsConfig[];
    /**
     * Indicates the n ame for the zone in a Global Cluster.
     */
    zoneName: string;
}

export interface GetClusterReplicationSpecRegionsConfig {
    /**
     * Indicates the number of analytics nodes for Atlas to deploy to the region. Analytics nodes are useful for handling analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only, and can never become the primary.
     */
    analyticsNodes: number;
    /**
     * Number of electable nodes for Atlas to deploy to the region.
     */
    electableNodes: number;
    /**
     * Election priority of the region. For regions with only read-only nodes, set this value to 0.
     */
    priority: number;
    /**
     * Number of read-only nodes for Atlas to deploy to the region. Read-only nodes can never become the primary, but can facilitate local-reads. Specify 0 if you do not want any read-only nodes in the region.
     */
    readOnlyNodes: number;
    /**
     * Name for the region specified.
     */
    regionName: string;
}

export interface GetClusterSnapshotBackupPolicy {
    clusterId: string;
    clusterName: string;
    nextSnapshot: string;
    policies: outputs.GetClusterSnapshotBackupPolicyPolicy[];
    referenceHourOfDay: number;
    referenceMinuteOfHour: number;
    restoreWindowDays: number;
    updateSnapshots: boolean;
}

export interface GetClusterSnapshotBackupPolicyPolicy {
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    policyItems: outputs.GetClusterSnapshotBackupPolicyPolicyPolicyItem[];
}

export interface GetClusterSnapshotBackupPolicyPolicyPolicyItem {
    frequencyInterval: number;
    frequencyType: string;
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    retentionUnit: string;
    retentionValue: number;
}

export interface GetClusterTag {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetClustersResult {
    /**
     * Get the advanced configuration options. See Advanced Configuration below for more details.
     */
    advancedConfigurations: outputs.GetClustersResultAdvancedConfiguration[];
    /**
     * Specifies whether cluster tier auto-scaling is enabled. The default is false.
     */
    autoScalingComputeEnabled: boolean;
    /**
     * * `autoScalingComputeScaleDownEnabled` - Specifies whether cluster tier auto-down-scaling is enabled.
     */
    autoScalingComputeScaleDownEnabled: boolean;
    /**
     * Indicates whether disk auto-scaling is enabled.
     */
    autoScalingDiskGbEnabled: boolean;
    /**
     * Indicates Cloud service provider on which the server for a multi-tenant cluster is provisioned.
     */
    backingProviderName: string;
    /**
     * Legacy Option, Indicates whether Atlas continuous backups are enabled for the cluster.
     */
    backupEnabled: boolean;
    /**
     * Indicates BI Connector for Atlas configuration on this cluster. BI Connector for Atlas is only available for M10+ clusters. See BI Connector below for more details.
     */
    biConnectorConfigs: outputs.GetClustersResultBiConnectorConfig[];
    /**
     * Indicates the type of the cluster that you want to modify. You cannot convert a sharded cluster deployment to a replica set deployment.
     */
    clusterType: string;
    /**
     * Set of connection strings that your applications use to connect to this cluster. More info in [Connection-strings](https://docs.mongodb.com/manual/reference/connection-string/). Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see [Connection String Options](https://docs.atlas.mongodb.com/reference/faq/connection-changes/). NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.
     */
    connectionStrings: outputs.GetClustersResultConnectionString[];
    /**
     * The Network Peering Container ID.
     */
    containerId: string;
    /**
     * Indicates the size in gigabytes of the server’s root volume (AWS/GCP Only).
     */
    diskSizeGb: number;
    /**
     * Indicates whether Encryption at Rest is enabled or disabled.
     */
    encryptionAtRestProvider: string;
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below. **DEPRECATED** Use `tags` instead.
     *
     * @deprecated This parameter is deprecated and will be removed by September 2024. Please transition to tags.
     */
    labels: outputs.GetClustersResultLabel[];
    /**
     * Indicates the version of the cluster to deploy.
     */
    mongoDbMajorVersion: string;
    /**
     * Version of MongoDB the cluster runs, in `major-version`.`minor-version` format.
     */
    mongoDbVersion: string;
    /**
     * Base connection string for the cluster. Atlas only displays this field after the cluster is operational, not while it builds the cluster.
     */
    mongoUri: string;
    /**
     * Lists when the connection string was last updated. The connection string changes, for example, if you change a replica set to a sharded cluster.
     */
    mongoUriUpdated: string;
    /**
     * Describes connection string for connecting to the Atlas cluster. Includes the replicaSet, ssl, and authSource query parameters in the connection string with values appropriate for the cluster.
     */
    mongoUriWithOptions: string;
    /**
     * The name of the current plugin
     */
    name: string;
    /**
     * Number of shards to deploy in the specified zone.
     */
    numShards: number;
    /**
     * Flag that indicates whether the cluster is paused or not.
     */
    paused: boolean;
    /**
     * Flag that indicates if the cluster uses Continuous Cloud Backup.
     */
    pitEnabled: boolean;
    /**
     * Maximum instance size to which your cluster can automatically scale.
     */
    providerAutoScalingComputeMaxInstanceSize: string;
    /**
     * Minimum instance size to which your cluster can automatically scale.
     */
    providerAutoScalingComputeMinInstanceSize: string;
    /**
     * Flag indicating if the cluster uses Cloud Backup Snapshots for backups. **DEPRECATED** Use `cloudBackup` instead.
     */
    providerBackupEnabled: boolean;
    /**
     * Indicates the maximum input/output operations per second (IOPS) the system can perform. The possible values depend on the selected providerSettings.instanceSizeName and diskSizeGB.
     */
    providerDiskIops: number;
    /**
     * Describes Azure disk type of the server’s root volume (Azure Only).
     */
    providerDiskTypeName: string;
    /**
     * **(DEPRECATED)** Indicates whether the Amazon EBS encryption is enabled. This feature encrypts the server’s root volume for both data at rest within the volume and data moving between the volume and the instance. By default this attribute is always enabled, per deprecation process showing the real value at `providerEncryptEbsVolumeFlag` computed attribute.
     */
    providerEncryptEbsVolume: boolean;
    /**
     * Atlas provides different instance sizes, each with a default storage capacity and RAM size.
     */
    providerInstanceSizeName: string;
    /**
     * Indicates the cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    /**
     * Indicates Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases. Requires the Atlas Region name, see the reference list for [AWS](https://docs.atlas.mongodb.com/reference/amazon-aws/), [GCP](https://docs.atlas.mongodb.com/reference/google-gcp/), [Azure](https://docs.atlas.mongodb.com/reference/microsoft-azure/).
     */
    providerRegionName: string;
    /**
     * Indicates the type of the volume. The possible values are: `STANDARD` and `PROVISIONED`.
     * > **NOTE:** `STANDARD` is not available for NVME clusters.
     */
    providerVolumeType: string;
    /**
     * (Deprecated) Number of replica set members. Each member keeps a copy of your databases, providing high availability and data redundancy. The possible values are 3, 5, or 7. The default value is 3.
     */
    replicationFactor: number;
    /**
     * Configuration for cluster regions.  See Replication Spec below for more details.
     */
    replicationSpecs: outputs.GetClustersResultReplicationSpec[];
    /**
     * current snapshot schedule and retention settings for the cluster.
     */
    snapshotBackupPolicies: outputs.GetClustersResultSnapshotBackupPolicy[];
    /**
     * Connection string for connecting to the Atlas cluster. The +srv modifier forces the connection to use TLS/SSL. See the mongoURI for additional options.
     */
    srvAddress: string;
    /**
     * Indicates the current state of the cluster. The possible states are:
     * - IDLE
     * - CREATING
     * - UPDATING
     * - DELETING
     * - DELETED
     * - REPAIRING
     */
    stateName: string;
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     */
    tags: outputs.GetClustersResultTag[];
    /**
     * Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won't delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
     */
    terminationProtectionEnabled: boolean;
    /**
     * Release cadence that Atlas uses for this cluster.
     */
    versionReleaseSystem: string;
}

export interface GetClustersResultAdvancedConfiguration {
    /**
     * [Default level of acknowledgment requested from MongoDB for read operations](https://docs.mongodb.com/manual/reference/read-concern/) set for this cluster. MongoDB 4.4 clusters default to [available](https://docs.mongodb.com/manual/reference/read-concern-available/).
     */
    defaultReadConcern: string;
    /**
     * [Default level of acknowledgment requested from MongoDB for write operations](https://docs.mongodb.com/manual/reference/write-concern/) set for this cluster. MongoDB 4.4 clusters default to [1](https://docs.mongodb.com/manual/reference/write-concern/).
     */
    defaultWriteConcern: string;
    /**
     * When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.
     */
    failIndexKeyTooLong: boolean;
    /**
     * When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.
     */
    javascriptEnabled: boolean;
    /**
     * Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:
     */
    minimumEnabledTlsProtocol: string;
    /**
     * When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.
     */
    noTableScan: boolean;
    /**
     * Minimum retention window for cluster's oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.
     */
    oplogMinRetentionHours: number;
    /**
     * The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.
     */
    oplogSizeMb: number;
    /**
     * Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleRefreshIntervalBiConnector: number;
    /**
     * Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.
     */
    sampleSizeBiConnector: number;
    transactionLifetimeLimitSeconds: number;
}

export interface GetClustersResultBiConnectorConfig {
    /**
     * Indicates whether or not BI Connector for Atlas is enabled on the cluster.
     */
    enabled: boolean;
    /**
     * Indicates the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of [readPreference](https://docs.mongodb.com/manual/core/read-preference/) and [readPreferenceTags](https://docs.mongodb.com/manual/core/read-preference/#tag-sets) options. For details on BI Connector for Atlas read preferences, refer to the [BI Connector Read Preferences Table](https://docs.atlas.mongodb.com/tutorial/create-global-writes-cluster/#bic-read-preferences).
     */
    readPreference: string;
}

export interface GetClustersResultConnectionString {
    awsPrivateLink: {[key: string]: any};
    awsPrivateLinkSrv: {[key: string]: any};
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     */
    private: string;
    privateEndpoints: outputs.GetClustersResultConnectionStringPrivateEndpoint[];
    /**
     * [Network-peering-endpoint-aware](https://docs.atlas.mongodb.com/security-vpc-peering/#vpc-peering) mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.
     * - `connection_strings.private_endpoint.#.connection_string` - Private-endpoint-aware `mongodb://`connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_connection_string` - Private-endpoint-aware `mongodb+srv://` connection string for this private endpoint.
     * - `connection_strings.private_endpoint.#.srv_shard_optimized_connection_string` - Private endpoint-aware connection string optimized for sharded clusters that uses the `mongodb+srv://` protocol to connect to MongoDB Cloud through a private endpoint.
     * - `connection_strings.private_endpoint.#.type` - Type of MongoDB process that you connect to with the connection strings. Atlas returns `MONGOD` for replica sets, or `MONGOS` for sharded clusters.
     * - `connection_strings.private_endpoint.#.endpoints` - Private endpoint through which you connect to Atlas when you use `connection_strings.private_endpoint[n].connection_string` or `connection_strings.private_endpoint[n].srv_connection_string`
     * - `connection_strings.private_endpoint.#.endpoints.#.endpoint_id` - Unique identifier of the private endpoint.
     * - `connection_strings.private_endpoint.#.endpoints.#.provider_name` - Cloud provider to which you deployed the private endpoint. Atlas returns `AWS` or `AZURE`.
     * - `connection_strings.private_endpoint.#.endpoints.#.region` - Region to which you deployed the private endpoint.
     */
    privateSrv: string;
    /**
     * Public mongodb:// connection string for this cluster.
     */
    standard: string;
    /**
     * Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t, use connectionStrings.standard.
     */
    standardSrv: string;
}

export interface GetClustersResultConnectionStringPrivateEndpoint {
    connectionString: string;
    endpoints: outputs.GetClustersResultConnectionStringPrivateEndpointEndpoint[];
    srvConnectionString: string;
    srvShardOptimizedConnectionString: string;
    type: string;
}

export interface GetClustersResultConnectionStringPrivateEndpointEndpoint {
    endpointId: string;
    /**
     * Indicates the cloud service provider on which the servers are provisioned.
     */
    providerName: string;
    region: string;
}

export interface GetClustersResultLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetClustersResultReplicationSpec {
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    /**
     * Number of shards to deploy in the specified zone.
     */
    numShards: number;
    /**
     * Describes the physical location of the region. Each regionsConfig document describes the region’s priority in elections and the number and type of MongoDB nodes Atlas deploys to the region. You must order each regionsConfigs document by regionsConfig.priority, descending. See Region Config below for more details.
     */
    regionsConfigs: outputs.GetClustersResultReplicationSpecRegionsConfig[];
    /**
     * Indicates the n ame for the zone in a Global Cluster.
     */
    zoneName: string;
}

export interface GetClustersResultReplicationSpecRegionsConfig {
    /**
     * Indicates the number of analytics nodes for Atlas to deploy to the region. Analytics nodes are useful for handling analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only, and can never become the primary.
     */
    analyticsNodes: number;
    /**
     * Number of electable nodes for Atlas to deploy to the region.
     */
    electableNodes: number;
    /**
     * Election priority of the region. For regions with only read-only nodes, set this value to 0.
     */
    priority: number;
    /**
     * Number of read-only nodes for Atlas to deploy to the region. Read-only nodes can never become the primary, but can facilitate local-reads. Specify 0 if you do not want any read-only nodes in the region.
     */
    readOnlyNodes: number;
    /**
     * Name for the region specified.
     */
    regionName: string;
}

export interface GetClustersResultSnapshotBackupPolicy {
    clusterId: string;
    clusterName: string;
    nextSnapshot: string;
    policies: outputs.GetClustersResultSnapshotBackupPolicyPolicy[];
    referenceHourOfDay: number;
    referenceMinuteOfHour: number;
    restoreWindowDays: number;
    updateSnapshots: boolean;
}

export interface GetClustersResultSnapshotBackupPolicyPolicy {
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    policyItems: outputs.GetClustersResultSnapshotBackupPolicyPolicyPolicyItem[];
}

export interface GetClustersResultSnapshotBackupPolicyPolicyPolicyItem {
    frequencyInterval: number;
    frequencyType: string;
    /**
     * Unique identifer of the replication document for a zone in a Global Cluster.
     */
    id: string;
    retentionUnit: string;
    retentionValue: number;
}

export interface GetClustersResultTag {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetCustomDbRoleAction {
    /**
     * (Required) Name of the privilege action. For a complete list of actions available in the Atlas API, see Custom Role Actions.
     */
    action: string;
    /**
     * (Required) Contains information on where the action is granted. Each object in the array either indicates a database and collection on which the action is granted, or indicates that the action is granted on the cluster resource.
     */
    resources: outputs.GetCustomDbRoleActionResource[];
}

export interface GetCustomDbRoleActionResource {
    cluster: boolean;
    collectionName: string;
    /**
     * (Required) Database on which the inherited role is granted.
     */
    databaseName: string;
}

export interface GetCustomDbRoleInheritedRole {
    /**
     * (Required) Database on which the inherited role is granted.
     */
    databaseName: string;
    /**
     * Name of the custom role.
     */
    roleName: string;
}

export interface GetCustomDbRolesResult {
    actions: outputs.GetCustomDbRolesResultAction[];
    inheritedRoles: outputs.GetCustomDbRolesResultInheritedRole[];
    /**
     * (Required) Name of the inherited role. This can either be another custom role or a built-in role.
     */
    roleName: string;
}

export interface GetCustomDbRolesResultAction {
    /**
     * (Required) Name of the privilege action. For a complete list of actions available in the Atlas API, see Custom Role Actions.
     */
    action: string;
    /**
     * (Required) Contains information on where the action is granted. Each object in the array either indicates a database and collection on which the action is granted, or indicates that the action is granted on the cluster resource.
     */
    resources: outputs.GetCustomDbRolesResultActionResource[];
}

export interface GetCustomDbRolesResultActionResource {
    cluster: boolean;
    collectionName: string;
    /**
     * (Required) Database on which the inherited role is granted.
     */
    databaseName: string;
}

export interface GetCustomDbRolesResultInheritedRole {
    /**
     * (Required) Database on which the inherited role is granted.
     */
    databaseName: string;
    /**
     * (Required) Name of the inherited role. This can either be another custom role or a built-in role.
     */
    roleName: string;
}

export interface GetDataLakePipelineIngestionSchedule {
    frequencyInterval: number;
    frequencyType: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.
     */
    id: string;
    retentionUnit: string;
    retentionValue: number;
}

export interface GetDataLakePipelineRunStat {
    /**
     * Total data size in bytes exported for this pipeline run.
     */
    bytesExported: number;
    /**
     * Number of docs ingested for a this pipeline run.
     */
    numDocs: number;
}

export interface GetDataLakePipelineRunsResult {
    /**
     * Backup schedule interval of the Data Lake Pipeline.
     */
    backupFrequencyType: string;
    /**
     * Timestamp that indicates when the pipeline run was created.
     */
    createdDate: string;
    /**
     * Unique 24-hexadecimal character string that identifies a Data Lake Pipeline run.
     */
    id: string;
    /**
     * Unique 24-hexadecimal character string that identifies a Data Lake Pipeline run.
     */
    lastUpdatedDate: string;
    /**
     * Processing phase of the Data Lake Pipeline.
     */
    phase: string;
    /**
     * Unique 24-hexadecimal character string that identifies a Data Lake Pipeline.
     */
    pipelineId: string;
    /**
     * Unique 24-hexadecimal character string that identifies a Data Lake Pipeline run.
     */
    pipelineRunId: string;
    /**
     * Unique 24-hexadecimal character string that identifies the snapshot of a cluster.
     */
    snapshotId: string;
    /**
     * State of the pipeline run.
     */
    state: string;
    /**
     * Runtime statistics for this Data Lake Pipeline run.
     */
    stats: outputs.GetDataLakePipelineRunsResultStat[];
}

export interface GetDataLakePipelineRunsResultStat {
    /**
     * Total data size in bytes exported for this pipeline run.
     */
    bytesExported: number;
    /**
     * Number of docs ingested for a this pipeline run.
     */
    numDocs: number;
}

export interface GetDataLakePipelineSink {
    /**
     * Ordered fields used to physically organize data in the destination.
     * * `partition_fields.#.field_name` - Human-readable label that identifies the field name used to partition data.
     * * `partition_fields.#.order` - Sequence in which MongoDB Atlas slices the collection data to create partitions. The resource expresses this sequence starting with zero.
     */
    partitionFields: outputs.GetDataLakePipelineSinkPartitionField[];
    /**
     * Target cloud provider for this Data Lake Pipeline.
     */
    provider: string;
    /**
     * Target cloud provider region for this Data Lake Pipeline. [Supported cloud provider regions](https://www.mongodb.com/docs/datalake/limitations).
     */
    region: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelineSinkPartitionField {
    fieldName: string;
    order: number;
}

export interface GetDataLakePipelineSnapshot {
    copyRegion: string;
    createdAt: string;
    expiresAt: string;
    frequencyYype: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.
     */
    id: string;
    masterKey: string;
    mongodVersion: string;
    policies: string[];
    /**
     * Target cloud provider for this Data Lake Pipeline.
     */
    provider: string;
    replicaSetName: string;
    size: number;
    status: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelineSource {
    /**
     * Human-readable name that identifies the cluster.
     */
    clusterName: string;
    /**
     * Human-readable name that identifies the collection.
     */
    collectionName: string;
    /**
     * Human-readable name that identifies the database.
     */
    databaseName: string;
    /**
     * The unique ID for the project to create a Data Lake Pipeline.
     */
    projectId: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelineTransformation {
    field: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelinesResult {
    /**
     * Timestamp that indicates when the Data Lake Pipeline was created.
     */
    createdDate: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.
     */
    id: string;
    /**
     * Timestamp that indicates the last time that the Data Lake Pipeline was updated.
     */
    lastUpdatedDate: string;
    name: string;
    /**
     * The unique ID for the project to create a data lake pipeline.
     */
    projectId: string;
    sinks: outputs.GetDataLakePipelinesResultSink[];
    sources: outputs.GetDataLakePipelinesResultSource[];
    /**
     * State of this Data Lake Pipeline.
     */
    state: string;
    /**
     * Fields to be excluded for this Data Lake Pipeline.
     * * `transformations.#.field` - Key in the document.
     * * `transformations.#.type` - Type of transformation applied during the export of the namespace in a Data Lake Pipeline.
     */
    transformations: outputs.GetDataLakePipelinesResultTransformation[];
}

export interface GetDataLakePipelinesResultSink {
    /**
     * Ordered fields used to physically organize data in the destination.
     * * `partition_fields.#.field_name` - Human-readable label that identifies the field name used to partition data.
     * * `partition_fields.#.order` - Sequence in which MongoDB Atlas slices the collection data to create partitions. The resource expresses this sequence starting with zero.
     */
    partitionFields: outputs.GetDataLakePipelinesResultSinkPartitionField[];
    /**
     * Target cloud provider for this Data Lake Pipeline.
     */
    provider: string;
    /**
     * Target cloud provider region for this Data Lake Pipeline. [Supported cloud provider regions](https://www.mongodb.com/docs/datalake/limitations).
     */
    region: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelinesResultSinkPartitionField {
    fieldName: string;
    order: number;
}

export interface GetDataLakePipelinesResultSource {
    /**
     * Human-readable name that identifies the cluster.
     */
    clusterName: string;
    /**
     * Human-readable name that identifies the collection.
     */
    collectionName: string;
    /**
     * Human-readable name that identifies the database.
     */
    databaseName: string;
    /**
     * The unique ID for the project to create a data lake pipeline.
     */
    projectId: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDataLakePipelinesResultTransformation {
    field: string;
    /**
     * Type of ingestion source of this Data Lake Pipeline.
     */
    type: string;
}

export interface GetDatabaseUserLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetDatabaseUserRole {
    /**
     * Collection for which the role applies. You can specify a collection for the `read` and `readWrite` roles. If you do not specify a collection for `read` and `readWrite`, the role applies to all collections in the database (excluding some collections in the `system`. database).
     */
    collectionName: string;
    /**
     * Database on which the user has the specified role. A role on the `admin` database can include privileges that apply to the other databases.
     */
    databaseName: string;
    roleName: string;
}

export interface GetDatabaseUserScope {
    /**
     * Name of the role to grant.
     */
    name: string;
    /**
     * Type of resource that the user has access to. Valid values are: `CLUSTER` and `DATA_LAKE`
     */
    type: string;
}

export interface GetDatabaseUsersResult {
    /**
     * (Required) Database against which Atlas authenticates the user. A user must provide both a username and authentication database to log into MongoDB.
     * Possible values include:
     */
    authDatabaseName: string;
    /**
     * The new database user authenticates with AWS IAM credentials. Default is `NONE`, `USER` means user has AWS IAM user credentials, `ROLE` - means user has credentials associated with an AWS IAM role.
     */
    awsIamType: string;
    /**
     * Autogenerated Unique ID for this data source.
     */
    id: string;
    labels: outputs.GetDatabaseUsersResultLabel[];
    /**
     * Method by which the provided username is authenticated. Default is `NONE`. Other valid values are: `USER`, `GROUP`.
     */
    ldapAuthType: string;
    /**
     * (Optional) Human-readable label that indicates whether the new database user authenticates with OIDC (OpenID Connect) federated authentication. If no value is given, Atlas uses the default value of `NONE`. The accepted types are:
     */
    oidcAuthType: string;
    /**
     * The unique ID for the project to get all database users.
     */
    projectId: string;
    /**
     * List of user’s roles and the databases / collections on which the roles apply. A role allows the user to perform particular actions on the specified database. A role on the admin database can include privileges that apply to the other databases as well. See Roles below for more details.
     */
    roles: outputs.GetDatabaseUsersResultRole[];
    /**
     * Array of clusters and Atlas Data Lakes that this user has access to.
     */
    scopes: outputs.GetDatabaseUsersResultScope[];
    /**
     * Username for authenticating to MongoDB.
     */
    username: string;
    /**
     * X.509 method by which the provided username is authenticated.
     */
    x509Type: string;
}

export interface GetDatabaseUsersResultLabel {
    /**
     * The key that you want to write.
     */
    key: string;
    /**
     * The value that you want to write.
     */
    value: string;
}

export interface GetDatabaseUsersResultRole {
    /**
     * Collection for which the role applies. You can specify a collection for the `read` and `readWrite` roles. If you do not specify a collection for `read` and `readWrite`, the role applies to all collections in the database (excluding some collections in the `system`. database).
     */
    collectionName: string;
    /**
     * Database on which the user has the specified role. A role on the `admin` database can include privileges that apply to the other databases.
     */
    databaseName: string;
    roleName: string;
}

export interface GetDatabaseUsersResultScope {
    /**
     * Name of the role to grant.
     */
    name: string;
    /**
     * Type of resource that the user has access to. Valid values are: `CLUSTER` and `DATA_LAKE`
     */
    type: string;
}

export interface GetEventTriggerEventProcessor {
    awsEventbridges: outputs.GetEventTriggerEventProcessorAwsEventbridge[];
}

export interface GetEventTriggerEventProcessorAwsEventbridge {
    /**
     * AWS Account ID.
     */
    configAccountId: string;
    /**
     * Region of AWS Account.
     */
    configRegion: string;
}

export interface GetEventTriggersResult {
    /**
     * The name of the MongoDB collection that the trigger watches for change events.
     */
    configCollection: string;
    /**
     * The name of the MongoDB database to watch.
     */
    configDatabase: string;
    /**
     * If true, indicates that `UPDATE` change events should include the most current [majority-committed](https://docs.mongodb.com/manual/reference/read-concern-majority/) version of the modified document in the fullDocument field.
     */
    configFullDocument: boolean;
    configFullDocumentBefore: boolean;
    /**
     * A [$match](https://docs.mongodb.com/manual/reference/operator/aggregation/match/) expression document that MongoDB Realm includes in the underlying change stream pipeline for the trigger.
     */
    configMatch: string;
    /**
     * The [authentication operation type](https://docs.mongodb.com/realm/triggers/authentication-triggers/#std-label-authentication-event-operation-types) to listen for.
     */
    configOperationType: string;
    /**
     * The [database event operation types](https://docs.mongodb.com/realm/triggers/database-triggers/#std-label-database-events) to listen for.
     */
    configOperationTypes: string[];
    /**
     * A [$project](https://docs.mongodb.com/manual/reference/operator/aggregation/project/) expression document that Realm uses to filter the fields that appear in change event objects.
     */
    configProject: string;
    /**
     * A list of one or more [authentication provider](https://docs.mongodb.com/realm/authentication/providers/) id values. The trigger will only listen for authentication events produced by these providers.
     */
    configProviders: string[];
    /**
     * A [cron expression](https://docs.mongodb.com/realm/triggers/cron-expressions/) that defines the trigger schedule.
     */
    configSchedule: string;
    configScheduleType: string;
    /**
     * The ID of the MongoDB Service associated with the trigger.
     */
    configServiceId: string;
    /**
     * Status of a trigger.
     */
    disabled: boolean;
    /**
     * An object where each field name is an event processor ID and each value is an object that configures its corresponding event processor.
     */
    eventProcessors: outputs.GetEventTriggersResultEventProcessor[];
    /**
     * The ID of the function associated with the trigger.
     */
    functionId: string;
    /**
     * The name of the function associated with the trigger.
     */
    functionName: string;
    /**
     * The name of the trigger.
     */
    name: string;
    triggerId: string;
    /**
     * The type of the trigger. Possible Values: `DATABASE`, `AUTHENTICATION`
     */
    type: string;
    /**
     * Sort order for `DATABASE` type.
     */
    unordered: boolean;
}

export interface GetEventTriggersResultEventProcessor {
    awsEventbridges: outputs.GetEventTriggersResultEventProcessorAwsEventbridge[];
}

export interface GetEventTriggersResultEventProcessorAwsEventbridge {
    /**
     * AWS Account ID.
     */
    configAccountId: string;
    /**
     * Region of AWS Account.
     */
    configRegion: string;
}

export interface GetFederatedDatabaseInstanceCloudProviderConfig {
    aws: outputs.GetFederatedDatabaseInstanceCloudProviderConfigAws;
}

export interface GetFederatedDatabaseInstanceCloudProviderConfigAws {
    /**
     * Unique identifier associated with the IAM Role that the Federated Database Instance assumes when accessing the data stores.
     */
    externalId: string;
    /**
     * Amazon Resource Name (ARN) of the IAM Role that the Federated Database Instance assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:
     * * `s3:GetObject`
     * * `s3:ListBucket`
     * * `s3:GetObjectVersion`
     */
    iamAssumedRoleArn: string;
    /**
     * Amazon Resource Name (ARN) of the user that the Federated Database Instance assumes when accessing S3 Bucket data stores.
     */
    iamUserArn: string;
    /**
     * Unique identifier of the role that the data lake can use to access the data stores.
     */
    roleId: string;
    testS3Bucket: string;
}

export interface GetFederatedDatabaseInstanceDataProcessRegion {
    /**
     * Name of the cloud service provider. Atlas Federated Database only supports AWS.
     */
    cloudProvider: string;
    /**
     * Name of the region to which the Federanted Instnace routes client connections for data processing.
     */
    region: string;
}

export interface GetFederatedDatabaseInstanceStorageDatabase {
    collections: outputs.GetFederatedDatabaseInstanceStorageDatabaseCollection[];
    maxWildcardCollections: number;
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    views: outputs.GetFederatedDatabaseInstanceStorageDatabaseView[];
}

export interface GetFederatedDatabaseInstanceStorageDatabaseCollection {
    dataSources: outputs.GetFederatedDatabaseInstanceStorageDatabaseCollectionDataSource[];
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
}

export interface GetFederatedDatabaseInstanceStorageDatabaseCollectionDataSource {
    allowInsecure: boolean;
    collection: string;
    collectionRegex: string;
    database: string;
    databaseRegex: string;
    datasetName: string;
    defaultFormat: string;
    path: string;
    provenanceFieldName: string;
    storeName: string;
    urls: string[];
}

export interface GetFederatedDatabaseInstanceStorageDatabaseView {
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    pipeline: string;
    source: string;
}

export interface GetFederatedDatabaseInstanceStorageStore {
    additionalStorageClasses: string[];
    allowInsecure: boolean;
    bucket: string;
    /**
     * @deprecated This parameter is deprecated and will be removed by September 2024.
     */
    clusterId: string;
    clusterName: string;
    defaultFormat: string;
    delimiter: string;
    includeTags: boolean;
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    prefix: string;
    /**
     * The unique ID for the project to create a Federated Database Instance.
     */
    projectId: string;
    provider: string;
    public: string;
    readPreferences: outputs.GetFederatedDatabaseInstanceStorageStoreReadPreference[];
    /**
     * Name of the region to which the Federanted Instnace routes client connections for data processing.
     */
    region: string;
    urls: string[];
}

export interface GetFederatedDatabaseInstanceStorageStoreReadPreference {
    maxStalenessSeconds: number;
    mode: string;
    tagSets: outputs.GetFederatedDatabaseInstanceStorageStoreReadPreferenceTagSet[];
}

export interface GetFederatedDatabaseInstanceStorageStoreReadPreferenceTagSet {
    tags: outputs.GetFederatedDatabaseInstanceStorageStoreReadPreferenceTagSetTag[];
}

export interface GetFederatedDatabaseInstanceStorageStoreReadPreferenceTagSetTag {
    /**
     * Name of the Atlas Federated Database Instance.
     */
    name: string;
    value: string;
}

export interface GetFederatedDatabaseInstancesResult {
    cloudProviderConfig: outputs.GetFederatedDatabaseInstancesResultCloudProviderConfig;
    dataProcessRegions: outputs.GetFederatedDatabaseInstancesResultDataProcessRegion[];
    /**
     * The list of hostnames assigned to the Federated Database Instance. Each string in the array is a hostname assigned to the Federated Database Instance.
     */
    hostnames: string[];
    name: string;
    /**
     * The unique ID for the project to create a Federated Database Instance.
     */
    projectId: string;
    /**
     * Current state of the Federated Database Instance:
     */
    state: string;
    /**
     * Configuration details for mapping each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see [databases](https://docs.mongodb.com/datalake/reference/format/data-lake-configuration#std-label-datalake-databases-reference). An empty object indicates that the Federated Database Instance has no mapping configuration for any data store.
     * * `storage_databases.#.name` - Name of the database to which the Federated Database Instance maps the data contained in the data store.
     * * `storage_databases.#.collections` -     Array of objects where each object represents a collection and data sources that map to a [stores](https://docs.mongodb.com/datalake/reference/format/data-lake-configuration#mongodb-datalakeconf-datalakeconf.stores) data store.
     * * `storage_databases.#.collections.#.name` - Name of the collection.
     * * `storage_databases.#.collections.#.data_sources` -     Array of objects where each object represents a stores data store to map with the collection.
     * * `storage_databases.#.collections.#.data_sources.#.store_name` -     Name of a data store to map to the `<collection>`. Must match the name of an object in the stores array.
     * * `storage_databases.#.collections.#.data_sources.#.dataset_name` -     Human-readable label that identifies the dataset that Atlas generates for an ingestion pipeline run or Online Archive.
     * * `storage_databases.#.collections.#.data_sources.#.default_format` - Default format that Federated Database assumes if it encounters a file without an extension while searching the storeName.
     * * `storage_databases.#.collections.#.data_sources.#.path` - File path that controls how MongoDB Cloud searches for and parses files in the storeName before mapping them to a collection. Specify / to capture all files and folders from the prefix path.
     * * `storage_databases.#.collections.#.data_sources.#.database` - Human-readable label that identifies the database, which contains the collection in the cluster.
     * * `storage_databases.#.collections.#.data_sources.#.allow_insecure` - Flag that validates the scheme in the specified URLs. If true, allows insecure HTTP scheme, doesn't verify the server's certificate chain and hostname, and accepts any certificate with any hostname presented by the server. If false, allows secure HTTPS scheme only.
     * * `storage_databases.#.collections.#.data_sources.#.database_regex` - Regex pattern to use for creating the wildcard database.
     * * `storage_databases.#.collections.#.data_sources.#.collection` - Human-readable label that identifies the collection in the database.
     * * `storage_databases.#.collections.#.data_sources.#.collection_regex` - Regex pattern to use for creating the wildcard (*) collection.
     * * `storage_databases.#.collections.#.data_sources.#.provenance_field_name` - Name for the field that includes the provenance of the documents in the results.
     * * `storage_databases.#.collections.#.data_sources.#.storeName` - Human-readable label that identifies the data store that MongoDB Cloud maps to the collection.
     * * `storage_databases.#.collections.#.data_sources.#.urls` - URLs of the publicly accessible data files. You can't specify URLs that require authentication.
     * * `storage_databases.#.views` -     Array of objects where each object represents an [aggregation pipeline](https://docs.mongodb.com/manual/core/aggregation-pipeline/#id1) on a collection. To learn more about views, see [Views](https://docs.mongodb.com/manual/core/views/).
     * * `storage_databases.#.views.#.name` - Name of the view.
     * * `storage_databases.#.views.#.source` -  Name of the source collection for the view.
     * * `storage_databases.#.views.#.pipeline`- Aggregation pipeline stage(s) to apply to the source collection.
     */
    storageDatabases: outputs.GetFederatedDatabaseInstancesResultStorageDatabase[];
    /**
     * Each object in the array represents a data store. Federated Database uses the storage.databases configuration details to map data in each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see [stores](https://docs.mongodb.com/datalake/reference/format/data-lake-configuration#std-label-datalake-stores-reference). An empty object indicates that the Federated Database Instance has no configured data stores.
     * * `storage_stores.#.name` - Name of the data store.
     * * `storage_stores.#.provider` - Defines where the data is stored.
     * * `storage_stores.#.region` - Name of the AWS region in which the S3 bucket is hosted.
     * * `storage_stores.#.bucket` - Name of the AWS S3 bucket.
     * * `storage_stores.#.prefix` - Prefix the Federated Database Instance applies when searching for files in the S3 bucket.
     * * `storage_stores.#.delimiter` - The delimiter that separates `storage_databases.#.collections.#.data_sources.#.path` segments in the data store.
     * * `storage_stores.#.include_tags` - Determines whether or not to use S3 tags on the files in the given path as additional partition attributes.
     * * `storage_stores.#.cluster_name` - Human-readable label of the MongoDB Cloud cluster on which the store is based.
     * * `storage_stores.#.cluster_id` - ID of the Cluster the Online Archive belongs to.
     * * `storage_stores.#.allow_insecure` - Flag that validates the scheme in the specified URLs.
     * * `storage_stores.#.public` - Flag that indicates whether the bucket is public.
     * * `storage_stores.#.default_format` - Default format that Data Lake assumes if it encounters a file without an extension while searching the storeName.
     * * `storage_stores.#.urls` - Comma-separated list of publicly accessible HTTP URLs where data is stored.
     * * `storage_stores.#.read_preference` - MongoDB Cloud cluster read preference, which describes how to route read requests to the cluster.
     * * `storage_stores.#.read_preference.maxStalenessSeconds` - Maximum replication lag, or staleness, for reads from secondaries.
     * * `storage_stores.#.read_preference.mode` - Read preference mode that specifies to which replica set member to route the read requests.
     * * `storage_stores.#.read_preference.tag_sets` - List that contains tag sets or tag specification documents.
     * * `storage_stores.#.read_preference.tags` - List of all tags within a tag set
     * * `storage_stores.#.read_preference.tags.name` - Human-readable label of the tag.
     * * `storage_stores.#.read_preference.tags.value` - Value of the tag.
     */
    storageStores: outputs.GetFederatedDatabaseInstancesResultStorageStore[];
}

export interface GetFederatedDatabaseInstancesResultCloudProviderConfig {
    aws: outputs.GetFederatedDatabaseInstancesResultCloudProviderConfigAws;
}

export interface GetFederatedDatabaseInstancesResultCloudProviderConfigAws {
    /**
     * Unique identifier associated with the IAM Role that the Federated Database Instance assumes when accessing the data stores.
     */
    externalId: string;
    /**
     * Amazon Resource Name (ARN) of the IAM Role that the Federated Database Instance assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:
     * * `s3:GetObject`
     * * `s3:ListBucket`
     * * `s3:GetObjectVersion`
     */
    iamAssumedRoleArn: string;
    /**
     * Amazon Resource Name (ARN) of the user that the Federated Database Instance assumes when accessing S3 Bucket data stores.
     */
    iamUserArn: string;
    /**
     * Unique identifier of the role that the data lake can use to access the data stores.
     * #### `dataProcessRegion` - The cloud provider region to which the Federated Instance routes client connections for data processing.
     */
    roleId: string;
    testS3Bucket: string;
}

export interface GetFederatedDatabaseInstancesResultDataProcessRegion {
    /**
     * Name of the cloud service provider. Atlas Federated Database only supports AWS.
     */
    cloudProvider: string;
    /**
     * Name of the region to which the Federanted Instnace routes client connections for data processing.
     */
    region: string;
}

export interface GetFederatedDatabaseInstancesResultStorageDatabase {
    collections: outputs.GetFederatedDatabaseInstancesResultStorageDatabaseCollection[];
    maxWildcardCollections: number;
    name: string;
    views: outputs.GetFederatedDatabaseInstancesResultStorageDatabaseView[];
}

export interface GetFederatedDatabaseInstancesResultStorageDatabaseCollection {
    dataSources: outputs.GetFederatedDatabaseInstancesResultStorageDatabaseCollectionDataSource[];
    name: string;
}

export interface GetFederatedDatabaseInstancesResultStorageDatabaseCollectionDataSource {
    allowInsecure: boolean;
    collection: string;
    collectionRegex: string;
    database: string;
    databaseRegex: string;
    datasetName: string;
    defaultFormat: string;
    path: string;
    provenanceFieldName: string;
    storeName: string;
    urls: string[];
}

export interface GetFederatedDatabaseInstancesResultStorageDatabaseView {
    name: string;
    pipeline: string;
    source: string;
}

export interface GetFederatedDatabaseInstancesResultStorageStore {
    additionalStorageClasses: string[];
    allowInsecure: boolean;
    bucket: string;
    /**
     * @deprecated This parameter is deprecated and will be removed by September 2024.
     */
    clusterId: string;
    clusterName: string;
    defaultFormat: string;
    delimiter: string;
    includeTags: boolean;
    name: string;
    prefix: string;
    /**
     * The unique ID for the project to create a Federated Database Instance.
     */
    projectId: string;
    provider: string;
    public: string;
    readPreferences: outputs.GetFederatedDatabaseInstancesResultStorageStoreReadPreference[];
    /**
     * Name of the region to which the Federanted Instnace routes client connections for data processing.
     */
    region: string;
    urls: string[];
}

export interface GetFederatedDatabaseInstancesResultStorageStoreReadPreference {
    maxStalenessSeconds: number;
    mode: string;
    tagSets: outputs.GetFederatedDatabaseInstancesResultStorageStoreReadPreferenceTagSet[];
}

export interface GetFederatedDatabaseInstancesResultStorageStoreReadPreferenceTagSet {
    tags: outputs.GetFederatedDatabaseInstancesResultStorageStoreReadPreferenceTagSetTag[];
}

export interface GetFederatedDatabaseInstancesResultStorageStoreReadPreferenceTagSetTag {
    name: string;
    value: string;
}

export interface GetFederatedQueryLimitsResult {
    /**
     * Amount that indicates the current usage of the limit.
     */
    currentUsage: number;
    /**
     * Default value of the limit.
     */
    defaultLimit: number;
    lastModifiedDate: string;
    limitName: string;
    maximumLimit: number;
    overrunPolicy: string;
    /**
     * The unique ID for the project to create a Federated Database Instance.
     */
    projectId: string;
    /**
     * Name of the Atlas Federated Database Instance.
     */
    tenantName: string;
    value: number;
}

export interface GetFederatedSettingsIdentityProviderAssociatedOrg {
    /**
     * List that contains the approved domains from which organization users can log in.
     */
    domainAllowLists: string[];
    /**
     * Flag that indicates whether domain restriction is enabled for the connected organization.
     */
    domainRestrictionEnabled: boolean;
    /**
     * Unique 24-hexadecimal digit string that identifies the IdP.
     */
    identityProviderId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * List that contains the default roles granted to users who authenticate through the IdP in a connected organization. If you provide a postAuthRoleGrants field in the request, the array that you provide replaces the current postAuthRoleGrants.
     */
    postAuthRoleGrants: string[];
    roleMappings: outputs.GetFederatedSettingsIdentityProviderAssociatedOrgRoleMapping[];
    userConflicts: outputs.GetFederatedSettingsIdentityProviderAssociatedOrgUserConflict[];
}

export interface GetFederatedSettingsIdentityProviderAssociatedOrgRoleMapping {
    /**
     * Unique human-readable label that identifies the identity provider group to which this role mapping applies.
     */
    externalGroupName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies this role mapping.
     */
    id: string;
    /**
     * Atlas roles and the unique identifiers of the groups and organizations associated with each role.
     */
    roleAssignments: outputs.GetFederatedSettingsIdentityProviderAssociatedOrgRoleMappingRoleAssignment[];
}

export interface GetFederatedSettingsIdentityProviderAssociatedOrgRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetFederatedSettingsIdentityProviderAssociatedOrgUserConflict {
    /**
     * Email address of the the user that conflicts with selected domains.
     */
    emailAddress: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    federationSettingsId: string;
    /**
     * First name of the the user that conflicts with selected domains.
     */
    firstName: string;
    /**
     * Last name of the the user that conflicts with selected domains.
     */
    lastName: string;
    /**
     * Name of the Atlas user that conflicts with selected domains.
     */
    userId: string;
}

export interface GetFederatedSettingsIdentityProviderPemFileInfo {
    certificates: outputs.GetFederatedSettingsIdentityProviderPemFileInfoCertificate[];
    /**
     * Filename of certificate
     */
    fileName: string;
}

export interface GetFederatedSettingsIdentityProviderPemFileInfoCertificate {
    /**
     * Expiration  Date.
     */
    notAfter: string;
    /**
     * Start Date.
     */
    notBefore: string;
}

export interface GetFederatedSettingsIdentityProvidersResult {
    /**
     * Assertion consumer service URL to which the IdP sends the SAML response.
     */
    acsUrl: string;
    /**
     * List that contains the configured domains from which users can log in for this IdP.
     */
    associatedDomains: string[];
    /**
     * List that contains the configured domains from which users can log in for this IdP.
     */
    associatedOrgs: outputs.GetFederatedSettingsIdentityProvidersResultAssociatedOrg[];
    /**
     * Identifier of the intended recipient of the token.
     */
    audienceClaims: string[];
    /**
     * Identifier for the intended audience of the SAML Assertion.
     */
    audienceUri: string;
    /**
     * Client identifier that is assigned to an application by the Identity Provider.
     */
    clientId: string;
    /**
     * Human-readable label that identifies the IdP.
     */
    displayName: string;
    /**
     * Identifier of the claim which contains IdP Group IDs in the token.
     */
    groupsClaim: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the IdP.
     */
    idpId: string;
    /**
     * Identifier for the issuer of the SAML Assertion.
     */
    issuerUri: string;
    oktaIdpId: string;
    pemFileInfos: outputs.GetFederatedSettingsIdentityProvidersResultPemFileInfo[];
    /**
     * The protocol of the identity provider
     */
    protocol: string;
    /**
     * SAML Authentication Request Protocol binding used to send the AuthNRequest. Atlas supports the following binding values:
     * - HTTP POST
     * - HTTP REDIRECT
     */
    requestBinding: string;
    /**
     * Scopes that MongoDB applications will request from the authorization endpoint.
     */
    requestedScopes: string[];
    /**
     * Algorithm used to encrypt the IdP signature. Atlas supports the following signature algorithm values:
     * - SHA-1
     * - SHA-256
     */
    responseSignatureAlgorithm: string;
    /**
     * Flag that indicates whether the IdP has enabled Bypass SAML Mode. Enabling this mode generates a URL that allows you bypass SAML and login to your organizations at any point. You can authenticate with this special URL only when Bypass Mode is enabled. Set this parameter to true during testing. This keeps you from getting locked out of MongoDB.
     */
    ssoDebugEnabled: boolean;
    /**
     * URL of the receiver of the SAML AuthNRequest.
     */
    ssoUrl: string;
    /**
     * Label that indicates whether the identity provider is active. The IdP is Inactive until you map at least one domain to the IdP.
     */
    status: string;
    /**
     * Identifier of the claim which contains the user ID in the token.
     */
    userClaim: string;
}

export interface GetFederatedSettingsIdentityProvidersResultAssociatedOrg {
    /**
     * List that contains the approved domains from which organization users can log in.
     */
    domainAllowLists: string[];
    /**
     * Flag that indicates whether domain restriction is enabled for the connected organization.
     */
    domainRestrictionEnabled: boolean;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    identityProviderId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * List that contains the default roles granted to users who authenticate through the IdP in a connected organization. If you provide a postAuthRoleGrants field in the request, the array that you provide replaces the current postAuthRoleGrants.
     */
    postAuthRoleGrants: string[];
    roleMappings: outputs.GetFederatedSettingsIdentityProvidersResultAssociatedOrgRoleMapping[];
    userConflicts: outputs.GetFederatedSettingsIdentityProvidersResultAssociatedOrgUserConflict[];
}

export interface GetFederatedSettingsIdentityProvidersResultAssociatedOrgRoleMapping {
    /**
     * Unique human-readable label that identifies the identity provider group to which this role mapping applies.
     */
    externalGroupName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies this role mapping.
     */
    id: string;
    /**
     * Atlas roles and the unique identifiers of the groups and organizations associated with each role.
     */
    roleAssignments: outputs.GetFederatedSettingsIdentityProvidersResultAssociatedOrgRoleMappingRoleAssignment[];
}

export interface GetFederatedSettingsIdentityProvidersResultAssociatedOrgRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetFederatedSettingsIdentityProvidersResultAssociatedOrgUserConflict {
    /**
     * Email address of the the user that conflicts with selected domains.
     */
    emailAddress: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    federationSettingsId: string;
    /**
     * First name of the the user that conflicts with selected domains.
     */
    firstName: string;
    /**
     * Last name of the the user that conflicts with selected domains.
     */
    lastName: string;
    /**
     * Name of the Atlas user that conflicts with selected domains.
     */
    userId: string;
}

export interface GetFederatedSettingsIdentityProvidersResultPemFileInfo {
    certificates: outputs.GetFederatedSettingsIdentityProvidersResultPemFileInfoCertificate[];
    /**
     * Filename of certificate
     */
    fileName: string;
}

export interface GetFederatedSettingsIdentityProvidersResultPemFileInfoCertificate {
    /**
     * Expiration  Date.
     */
    notAfter: string;
    /**
     * Start Date.
     */
    notBefore: string;
}

export interface GetFederatedSettingsOrgConfigRoleMapping {
    /**
     * Unique human-readable label that identifies the identity provider group to which this role mapping applies.
     */
    externalGroupName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies this role mapping.
     */
    id: string;
    /**
     * Atlas roles and the unique identifiers of the groups and organizations associated with each role.
     */
    roleAssignments: outputs.GetFederatedSettingsOrgConfigRoleMappingRoleAssignment[];
}

export interface GetFederatedSettingsOrgConfigRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetFederatedSettingsOrgConfigUserConflict {
    /**
     * Email address of the the user that conflicts with selected domains.
     */
    emailAddress: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    federationSettingsId: string;
    /**
     * First name of the the user that conflicts with selected domains.
     */
    firstName: string;
    /**
     * Last name of the the user that conflicts with selected domains.
     */
    lastName: string;
    /**
     * Name of the Atlas user that conflicts with selected domains.
     */
    userId: string;
}

export interface GetFederatedSettingsOrgConfigsResult {
    /**
     * List that contains the approved domains from which organization users can log in.
     */
    domainAllowLists: string[];
    /**
     * Flag that indicates whether domain restriction is enabled for the connected organization.
     */
    domainRestrictionEnabled: boolean;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    identityProviderId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * List that contains the default roles granted to users who authenticate through the IdP in a connected organization.
     */
    postAuthRoleGrants: string[];
    roleMappings: outputs.GetFederatedSettingsOrgConfigsResultRoleMapping[];
    userConflicts: outputs.GetFederatedSettingsOrgConfigsResultUserConflict[];
}

export interface GetFederatedSettingsOrgConfigsResultRoleMapping {
    /**
     * Unique human-readable label that identifies the identity provider group to which this role mapping applies.
     */
    externalGroupName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies this role mapping.
     */
    id: string;
    /**
     * Atlas roles and the unique identifiers of the groups and organizations associated with each role.
     */
    roleAssignments: outputs.GetFederatedSettingsOrgConfigsResultRoleMappingRoleAssignment[];
}

export interface GetFederatedSettingsOrgConfigsResultRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetFederatedSettingsOrgConfigsResultUserConflict {
    /**
     * Email address of the the user that conflicts with selected domains.
     */
    emailAddress: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the federated authentication configuration.
     */
    federationSettingsId: string;
    /**
     * First name of the the user that conflicts with selected domains.
     */
    firstName: string;
    /**
     * Last name of the the user that conflicts with selected domains.
     */
    lastName: string;
    /**
     * Name of the Atlas user that conflicts with selected domains.
     */
    userId: string;
}

export interface GetFederatedSettingsOrgRoleMappingRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetFederatedSettingsOrgRoleMappingsResult {
    /**
     * Unique human-readable label that identifies the identity provider group to which this role mapping applies.
     */
    externalGroupName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies this role mapping.
     */
    id: string;
    /**
     * Atlas roles and the unique identifiers of the groups and organizations associated with each role.
     */
    roleAssignments: outputs.GetFederatedSettingsOrgRoleMappingsResultRoleAssignment[];
}

export interface GetFederatedSettingsOrgRoleMappingsResultRoleAssignment {
    /**
     * Unique identifier of the project to which you want the role mapping to apply.
     */
    groupId: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the organization that contains your projects.
     */
    orgId: string;
    /**
     * Specifies the Role that is attached to the Role Mapping.
     */
    role: string;
}

export interface GetGlobalClusterConfigManagedNamespace {
    /**
     * (Required) The name of the collection associated with the managed namespace.
     */
    collection: string;
    /**
     * (Required)	The custom shard key for the collection. Global Clusters require a compound shard key consisting of a location field and a user-selected second key, the custom shard key.
     */
    customShardKey: string;
    /**
     * (Required) The name of the database containing the collection.
     */
    db: string;
    /**
     * Specifies whether the custom shard key for the collection is [hashed](https://docs.mongodb.com/manual/reference/method/sh.shardCollection/#hashed-shard-keys). If omitted, defaults to `false`. If `false`, Atlas uses [ranged sharding](https://docs.mongodb.com/manual/core/ranged-sharding/). This is only available for Atlas clusters with MongoDB v4.4 and later.
     */
    isCustomShardKeyHashed: boolean;
    /**
     * Specifies whether the underlying index enforces a unique constraint. If omitted, defaults to false. You cannot specify true when using [hashed shard keys](https://docs.mongodb.com/manual/core/hashed-sharding/#std-label-sharding-hashed).
     */
    isShardKeyUnique: boolean;
}

export interface GetLdapConfigurationUserToDnMapping {
    /**
     * An LDAP query formatting template that inserts the LDAP name matched by the `match` regular expression into an LDAP query URI as specified by RFC 4515 and RFC 4516.
     */
    ldapQuery: string;
    /**
     * A regular expression to match against a provided LDAP username.
     */
    match: string;
    /**
     * An LDAP Distinguished Name (DN) formatting template that converts the LDAP name matched by the `match` regular expression into an LDAP Distinguished Name.
     */
    substitution: string;
}

export interface GetLdapVerifyLink {
    href: string;
    rel: string;
}

export interface GetLdapVerifyValidation {
    /**
     * The current status of the LDAP over TLS/SSL configuration.
     */
    status: string;
    validationType: string;
}

export interface GetNetworkContainersResult {
    /**
     * CIDR block that Atlas uses for your clusters. Atlas uses the specified CIDR block for all other Network Peering connections created in the project. The Atlas CIDR block must be at least a /24 and at most a /21 in one of the following [private networks](https://tools.ietf.org/html/rfc1918.html#section-3).
     */
    atlasCidrBlock: string;
    /**
     * Unique identifer of the Azure subscription in which the VNet resides.
     */
    azureSubscriptionId: string;
    /**
     * Unique identifier of the GCP project in which the Network Peering connection resides.
     */
    gcpProjectId: string;
    /**
     * The Network Peering Container ID.
     */
    id: string;
    /**
     * Name of the Network Peering connection in the Atlas project.
     */
    networkName: string;
    /**
     * Cloud provider for this Network peering container. Accepted values are AWS, GCP, and Azure.
     */
    providerName: string;
    /**
     * Indicates whether the project has Network Peering connections deployed in the container.
     */
    provisioned: boolean;
    /**
     * The Atlas Azure region name for where this container exists.
     */
    region: string;
    /**
     * The Atlas AWS region name for where this container exists.
     */
    regionName: string;
    /**
     * Atlas GCP regions where the container resides.
     */
    regions: string[];
    /**
     * The name of the Azure VNet. This value is null until you provision an Azure VNet in the container.
     */
    vnetName: string;
    /**
     * Unique identifier of the project’s VPC.
     */
    vpcId: string;
}

export interface GetNetworkPeeringsResult {
    /**
     * Specifies the region where the peer VPC resides. For complete lists of supported regions, see [Amazon Web Services](https://docs.atlas.mongodb.com/reference/amazon-aws/).
     */
    accepterRegionName: string;
    atlasCidrBlock: string;
    /**
     * Account ID of the owner of the peer VPC.
     */
    awsAccountId: string;
    /**
     * Unique identifier for an Azure AD directory.
     */
    azureDirectoryId: string;
    /**
     * Unique identifer of the Azure subscription in which the VNet resides.
     */
    azureSubscriptionId: string;
    /**
     * Unique identifier for the peering connection.
     */
    connectionId: string;
    containerId: string;
    /**
     * When `"status" : "FAILED"`, Atlas provides a description of the error.
     */
    errorMessage: string;
    /**
     * Description of the Atlas error when `status` is `Failed`, Otherwise, Atlas returns `null`.
     */
    errorState: string;
    /**
     * Error state, if any. The VPC peering connection error state value can be one of the following: `REJECTED`, `EXPIRED`, `INVALID_ARGUMENT`.
     */
    errorStateName: string;
    /**
     * GCP project ID of the owner of the network peer.
     */
    gcpProjectId: string;
    /**
     * Name of the network peer to which Atlas connects.
     */
    networkName: string;
    /**
     * Atlas assigned unique ID for the peering connection.
     */
    peeringId: string;
    /**
     * Cloud provider for this VPC peering connection. If omitted, Atlas sets this parameter to AWS. (Possible Values `AWS`, `AZURE`, `GCP`).
     */
    providerName: string;
    /**
     * Name of your Azure resource group.
     */
    resourceGroupName: string;
    /**
     * Peer VPC CIDR block or subnet.
     */
    routeTableCidrBlock: string;
    /**
     * Status of the Atlas network peering connection: `ADDING_PEER`, `AVAILABLE`, `FAILED`, `DELETING`, `WAITING_FOR_USER`.
     */
    status: string;
    /**
     * The VPC peering connection status value can be one of the following: `INITIATING`, `PENDING_ACCEPTANCE`, `FAILED`, `FINALIZING`, `AVAILABLE`, `TERMINATING`.
     */
    statusName: string;
    /**
     * Name of your Azure VNet.
     */
    vnetName: string;
    /**
     * Unique identifier of the peer VPC.
     */
    vpcId: string;
}

export interface GetOnlineArchiveCriteria {
    dateField: string;
    dateFormat: string;
    expireAfterDays: number;
    query: string;
    type: string;
}

export interface GetOnlineArchiveDataExpirationRule {
    expireAfterDays: number;
}

export interface GetOnlineArchiveDataProcessRegion {
    cloudProvider: string;
    region: string;
}

export interface GetOnlineArchivePartitionField {
    fieldName: string;
    fieldType: string;
    order: number;
}

export interface GetOnlineArchiveSchedule {
    dayOfMonth?: number;
    dayOfWeek?: number;
    endHour: number;
    endMinute: number;
    startHour: number;
    startMinute: number;
    type: string;
}

export interface GetOnlineArchivesResult {
    archiveId: string;
    /**
     * Name of the cluster that contains the collection.
     *
     * # Attributes Reference
     *
     * In addition to all arguments above, the following attributes are exported:
     */
    clusterName: string;
    collName: string;
    collectionType: string;
    criterias: outputs.GetOnlineArchivesResultCriteria[];
    dataExpirationRules: outputs.GetOnlineArchivesResultDataExpirationRule[];
    dataProcessRegions: outputs.GetOnlineArchivesResultDataProcessRegion[];
    dbName: string;
    partitionFields: outputs.GetOnlineArchivesResultPartitionField[];
    paused: boolean;
    /**
     * The unique ID for the project.
     */
    projectId: string;
    schedules: outputs.GetOnlineArchivesResultSchedule[];
    state: string;
}

export interface GetOnlineArchivesResultCriteria {
    dateField: string;
    dateFormat: string;
    expireAfterDays: number;
    query: string;
    type: string;
}

export interface GetOnlineArchivesResultDataExpirationRule {
    expireAfterDays: number;
}

export interface GetOnlineArchivesResultDataProcessRegion {
    cloudProvider: string;
    region: string;
}

export interface GetOnlineArchivesResultPartitionField {
    fieldName: string;
    fieldType: string;
    order: number;
}

export interface GetOnlineArchivesResultSchedule {
    dayOfMonth?: number;
    dayOfWeek?: number;
    endHour: number;
    endMinute: number;
    startHour: number;
    startMinute: number;
    type: string;
}

export interface GetOrganizationLink {
    href: string;
    rel: string;
}

export interface GetOrganizationsResult {
    apiAccessListRequired: boolean;
    /**
     * Autogenerated Unique ID for this data source.
     */
    id: string;
    isDeleted: boolean;
    links: outputs.GetOrganizationsResultLink[];
    multiFactorAuthRequired: boolean;
    name: string;
    restrictEmployeeAccess: boolean;
}

export interface GetOrganizationsResultLink {
    href: string;
    rel: string;
}

export interface GetPrivateLinkEndpointServiceEndpoint {
    /**
     * Forwarding rule that corresponds to the endpoint you created in GCP.
     */
    endpointName: string;
    /**
     * Private IP address of the network endpoint group you created in GCP.
     */
    ipAddress: string;
    /**
     * Unique alphanumeric and special character strings that identify the service attachment associated with the endpoint.
     */
    serviceAttachmentName: string;
    /**
     * Status of the endpoint. Atlas returns one of the [values shown above](https://docs.atlas.mongodb.com/reference/api/private-endpoints-endpoint-create-one/#std-label-ref-status-field).
     */
    status: string;
}

export interface GetPrivatelinkEndpointServiceDataFederationOnlineArchivesResult {
    /**
     * Human-readable string to associate with this private endpoint.
     */
    comment: string;
    /**
     * (Optional) Human-readable label to identify VPC endpoint DNS name.
     */
    customerEndpointDnsName: string;
    /**
     * Unique 22-character alphanumeric string that identifies the private endpoint. See [Atlas Data Lake supports Amazon Web Services private endpoints using the AWS PrivateLink feature](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Data-Federation/operation/createDataFederationPrivateEndpoint:~:text=Atlas%20Data%20Lake%20supports%20Amazon%20Web%20Services%20private%20endpoints%20using%20the%20AWS%20PrivateLink%20feature).
     */
    endpointId: string;
    /**
     * Human-readable label that identifies the cloud service provider.
     */
    providerName: string;
    /**
     * Human-readable label to identify the region of VPC endpoint.  Requires the **Atlas region name**, see the reference list for [AWS](https://docs.atlas.mongodb.com/reference/amazon-aws/), [GCP](https://docs.atlas.mongodb.com/reference/google-gcp/), [Azure](https://docs.atlas.mongodb.com/reference/microsoft-azure/).
     */
    region: string;
    /**
     * Human-readable label that identifies the resource type associated with this private endpoint.
     */
    type: string;
}

export interface GetPrivatelinkEndpointsServiceServerlessResult {
    /**
     * Unique string that identifies the private endpoint's network interface.
     */
    cloudProviderEndpointId: string;
    /**
     * Human-readable string to associate with this private endpoint.
     */
    comment: string;
    /**
     * (Required) Unique 22-character alphanumeric string that identifies the private endpoint. Atlas supports AWS private endpoints using the [AWS PrivateLink](https://aws.amazon.com/privatelink/) feature.
     */
    endpointId: string;
    /**
     * Unique string that identifies the PrivateLink endpoint service. MongoDB Cloud returns null while it creates the endpoint service.
     */
    endpointServiceName: string;
    errorMessage: string;
    /**
     * IPv4 address of the private endpoint in your Azure VNet that someone added to this private endpoint service.
     */
    privateEndpointIpAddress: string;
    /**
     * Root-relative path that identifies the Azure Private Link Service that MongoDB Cloud manages.
     */
    privateLinkServiceResourceId: string;
    /**
     * Human-readable label that indicates the current operating status of the private endpoint. Values include: RESERVATION_REQUESTED, RESERVED, INITIATING, AVAILABLE, FAILED, DELETING.
     */
    status: string;
}

export interface GetProjectApiKeyProjectAssignment {
    /**
     * The unique ID for the project.
     */
    projectId: string;
    /**
     * List of Project roles that the Programmatic API key needs to have. Ensure you provide: at least one role and ensure all roles are valid for the Project. You must specify an array even if you are only associating a single role with the Programmatic API key. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#project-roles) describes the valid roles that can be assigned.
     */
    roleNames: string[];
}

export interface GetProjectApiKeysResult {
    /**
     * Unique identifier for the API key you want to update. Use the /orgs/{ORG-ID}/apiKeys endpoint to retrieve all API keys to which the authenticated user has access for the specified organization.
     */
    apiKeyId: string;
    /**
     * Description of this Project API key.
     */
    description: string;
    privateKey: string;
    projectAssignments?: outputs.GetProjectApiKeysResultProjectAssignment[];
    publicKey: string;
}

export interface GetProjectApiKeysResultProjectAssignment {
    /**
     * The unique ID for the project.
     */
    projectId: string;
    /**
     * List of Project roles that the Programmatic API key needs to have. Ensure you provide: at least one role and ensure all roles are valid for the Project. You must specify an array even if you are only associating a single role with the Programmatic API key. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#project-roles) describes the valid roles that can be assigned.
     */
    roleNames: string[];
}

export interface GetProjectIpAddresses {
    services: outputs.GetProjectIpAddressesServices;
}

export interface GetProjectIpAddressesServices {
    clusters: outputs.GetProjectIpAddressesServicesCluster[];
}

export interface GetProjectIpAddressesServicesCluster {
    clusterName: string;
    inbounds: string[];
    outbounds: string[];
}

export interface GetProjectLimit {
    /**
     * Amount that indicates the current usage of the limit.
     */
    currentUsage: number;
    /**
     * Default value of the limit.
     */
    defaultLimit: number;
    /**
     * Maximum value of the limit.
     */
    maximumLimit: number;
    /**
     * The unique ID for the project.
     *
     * > **IMPORTANT:** Either `projectId` or `name` must be configurated.
     */
    name: string;
    /**
     * Amount the limit is set to.
     */
    value: number;
}

export interface GetProjectTeam {
    /**
     * Each string in the array represents a project role assigned to the team. Every user associated with the team inherits these roles. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#organization-roles) describes the roles a user can have.
     */
    roleNames: string[];
    /**
     * The unique identifier of the team you want to associate with the project. The team and project must share the same parent organization.
     */
    teamId: string;
}

export interface GetProjectsResult {
    clusterCount: number;
    created: string;
    /**
     * Autogenerated Unique ID for this data source.
     */
    id: string;
    ipAddresses: outputs.GetProjectsResultIpAddresses;
    isCollectDatabaseSpecificsStatisticsEnabled: boolean;
    isDataExplorerEnabled: boolean;
    isExtendedStorageSizesEnabled: boolean;
    isPerformanceAdvisorEnabled: boolean;
    isRealtimePerformancePanelEnabled: boolean;
    isSchemaAdvisorEnabled: boolean;
    limits: outputs.GetProjectsResultLimit[];
    name: string;
    orgId: string;
    projectId: string;
    regionUsageRestrictions: string;
    tags: {[key: string]: string};
    teams: outputs.GetProjectsResultTeam[];
}

export interface GetProjectsResultIpAddresses {
    services: outputs.GetProjectsResultIpAddressesServices;
}

export interface GetProjectsResultIpAddressesServices {
    clusters: outputs.GetProjectsResultIpAddressesServicesCluster[];
}

export interface GetProjectsResultIpAddressesServicesCluster {
    clusterName: string;
    inbounds: string[];
    outbounds: string[];
}

export interface GetProjectsResultLimit {
    /**
     * Amount that indicates the current usage of the limit.
     */
    currentUsage: number;
    /**
     * Default value of the limit.
     */
    defaultLimit: number;
    /**
     * Maximum value of the limit.
     */
    maximumLimit: number;
    /**
     * Human-readable label that identifies this project limit.
     */
    name: string;
    /**
     * Amount the limit is set to.
     */
    value: number;
}

export interface GetProjectsResultTeam {
    /**
     * Each string in the array represents a project role assigned to the team. Every user associated with the team inherits these roles. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#organization-roles) describes the roles a user can have.
     */
    roleNames: string[];
    /**
     * The unique identifier of the team you want to associate with the project. The team and project must share the same parent organization.
     */
    teamId: string;
}

export interface GetSearchDeploymentSpec {
    /**
     * Hardware specification for the search node instance sizes. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Atlas-Search/operation/createAtlasSearchDeployment) describes the valid values. More details can also be found in the [Search Node Documentation](https://www.mongodb.com/docs/atlas/cluster-config/multi-cloud-distribution/#search-tier).
     */
    instanceSize: string;
    /**
     * Number of search nodes in the cluster.
     */
    nodeCount: number;
}

export interface GetSearchIndexSynonym {
    /**
     * [Analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use when creating the index.
     */
    analyzer: string;
    /**
     * Name of the index.
     */
    name: string;
    sourceCollection: string;
}

export interface GetSearchIndexesResult {
    /**
     * [Analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use when creating the index.
     */
    analyzer?: string;
    /**
     * [Custom analyzers](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/custom/#std-label-custom-analyzers) to use in this index (this is an array of objects).
     */
    analyzers?: string;
    /**
     * Name of the cluster containing the collection with one or more Atlas Search indexes.
     */
    clusterName: string;
    /**
     * Name of the collection with one or more Atlas Search indexes.
     */
    collectionName: string;
    /**
     * (Required) Name of the database the collection is in.
     */
    database: string;
    fields?: string;
    indexId: string;
    /**
     * Flag indicating whether the index uses dynamic or static mappings.
     */
    mappingsDynamic?: boolean;
    /**
     * Object containing one or more field specifications.
     */
    mappingsFields?: string;
    /**
     * Name of the index.
     */
    name: string;
    /**
     * Unique identifier for the [project](https://docs.atlas.mongodb.com/organizations-projects/#std-label-projects) that contains the specified cluster.
     */
    projectId: string;
    /**
     * [Analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use when searching the index.
     */
    searchAnalyzer?: string;
    /**
     * Current status of the index.
     */
    status: string;
    /**
     * Synonyms mapping definition to use in this index.
     * * `synonyms.#.name` - Name of the [synonym mapping definition](https://docs.atlas.mongodb.com/reference/atlas-search/synonyms/#std-label-synonyms-ref).
     * * `synonyms.#.source_collection` - Name of the source MongoDB collection for the synonyms.
     * * `synonyms.#.analyzer` - Name of the [analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use with this synonym mapping.
     */
    synonyms?: outputs.GetSearchIndexesResultSynonym[];
    type?: string;
    waitForIndexBuildCompletion?: boolean;
}

export interface GetSearchIndexesResultSynonym {
    /**
     * [Analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use when creating the index.
     */
    analyzer: string;
    /**
     * Name of the index.
     */
    name: string;
    sourceCollection: string;
}

export interface GetServerlessInstanceLink {
    href: string;
    rel: string;
}

export interface GetServerlessInstanceTag {
    /**
     * Constant that defines the set of the tag.
     */
    key: string;
    /**
     * Variable that belongs to the set of the tag.
     */
    value: string;
}

export interface GetServerlessInstancesResult {
    /**
     * Flag that indicates whether the serverless instance uses [Serverless Auto Indexing](https://www.mongodb.com/docs/atlas/performance-advisor/auto-index-serverless/).
     */
    autoIndexing: boolean;
    connectionStringsPrivateEndpointSrvs: string[];
    /**
     * Public `mongodb+srv://` connection string that you can use to connect to this serverless instance.
     */
    connectionStringsStandardSrv: string;
    /**
     * Flag that indicates whether the serverless instance uses Serverless Continuous Backup.
     */
    continuousBackupEnabled: boolean;
    createDate: string;
    /**
     * Unique 24-hexadecimal digit string that identifies the serverless instance.
     */
    id: string;
    links: outputs.GetServerlessInstancesResultLink[];
    /**
     * Version of MongoDB that the serverless instance runs, in `<major version>`.`<minor version>` format.
     */
    mongoDbVersion: string;
    /**
     * (Required) Human-readable label that identifies your serverless instance.
     */
    name: string;
    /**
     * Unique identifier for the [project](https://docs.atlas.mongodb.com/organizations-projects/#std-label-projects) that contains the specified cluster.
     */
    projectId: string;
    /**
     * Cloud service provider on which MongoDB Cloud provisioned the serverless instance.
     */
    providerSettingsBackingProviderName: string;
    /**
     * Cloud service provider that applies to the provisioned the serverless instance.
     */
    providerSettingsProviderName: string;
    /**
     * Human-readable label that identifies the physical location of your MongoDB serverless instance. The region you choose can affect network latency for clients accessing your databases.
     */
    providerSettingsRegionName: string;
    /**
     * Stage of deployment of this serverless instance when the resource made its request.
     */
    stateName: string;
    /**
     * Set that contains key-value pairs between 1 to 255 characters in length for tagging and categorizing the cluster. See below.
     */
    tags: outputs.GetServerlessInstancesResultTag[];
    /**
     * Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won't delete the cluster. If set to false, MongoDB Cloud will delete the cluster.
     */
    terminationProtectionEnabled: boolean;
}

export interface GetServerlessInstancesResultLink {
    href: string;
    rel: string;
}

export interface GetServerlessInstancesResultTag {
    /**
     * Constant that defines the set of the tag.
     */
    key: string;
    /**
     * Variable that belongs to the set of the tag.
     */
    value: string;
}

export interface GetSharedTierRestoreJobsResult {
    deliveryType: string;
    expirationDate: string;
    jobId: string;
    restoreFinishedDate: string;
    restoreScheduledDate: string;
    snapshotFinishedDate: string;
    snapshotId: string;
    snapshotUrl: string;
    status: string;
    targetDeploymentItemName: string;
    targetProjectId: string;
}

export interface GetSharedTierSnapshotsResult {
    expiration: string;
    finishTime: string;
    mongoDbVersion: string;
    scheduledTime: string;
    snapshotId: string;
    startTime: string;
    status: string;
}

export interface GetStreamConnectionAuthentication {
    /**
     * Style of authentication. Can be one of `PLAIN`, `SCRAM-256`, or `SCRAM-512`.
     */
    mechanism: string;
    /**
     * Password of the account to connect to the Kafka cluster.
     */
    password: string;
    /**
     * Username of the account to connect to the Kafka cluster.
     */
    username: string;
}

export interface GetStreamConnectionDbRoleToExecute {
    /**
     * The name of the role to use. Can be a built in role or a custom role.
     */
    role: string;
    /**
     * Type of the DB role. Can be either BUILT_IN or CUSTOM.
     */
    type: string;
}

export interface GetStreamConnectionSecurity {
    /**
     * A trusted, public x509 certificate for connecting to Kafka over SSL. String value of the certificate must be defined in the attribute.
     */
    brokerPublicCertificate: string;
    /**
     * Describes the transport type. Can be either `PLAINTEXT` or `SSL`.
     */
    protocol: string;
}

export interface GetStreamConnectionsResult {
    /**
     * User credentials required to connect to a Kafka cluster. Includes the authentication type, as well as the parameters for that authentication mode. See authentication.
     */
    authentication: outputs.GetStreamConnectionsResultAuthentication;
    /**
     * Comma separated list of server addresses.
     */
    bootstrapServers: string;
    /**
     * Name of the cluster configured for this connection.
     */
    clusterName: string;
    /**
     * A map of Kafka key-value pairs for optional configuration. This is a flat object, and keys can have '.' characters.
     */
    config: {[key: string]: string};
    /**
     * Human-readable label that identifies the stream connection. In the case of the Sample type, this is the name of the sample source.
     */
    connectionName: string;
    /**
     * The name of a Built in or Custom DB Role to connect to an Atlas Cluster. See DBRoleToExecute.
     */
    dbRoleToExecute: outputs.GetStreamConnectionsResultDbRoleToExecute;
    id: string;
    /**
     * Human-readable label that identifies the stream instance.
     */
    instanceName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies your project.
     */
    projectId: string;
    /**
     * Properties for the secure transport connection to Kafka. For SSL, this can include the trusted certificate to use. See security.
     */
    security: outputs.GetStreamConnectionsResultSecurity;
    /**
     * Type of the DB role. Can be either BUILT_IN or CUSTOM.
     */
    type: string;
}

export interface GetStreamConnectionsResultAuthentication {
    /**
     * Style of authentication. Can be one of `PLAIN`, `SCRAM-256`, or `SCRAM-512`.
     */
    mechanism: string;
    /**
     * Password of the account to connect to the Kafka cluster.
     */
    password: string;
    /**
     * Username of the account to connect to the Kafka cluster.
     */
    username: string;
}

export interface GetStreamConnectionsResultDbRoleToExecute {
    /**
     * The name of the role to use. Can be a built in role or a custom role.
     */
    role: string;
    /**
     * Type of the DB role. Can be either BUILT_IN or CUSTOM.
     */
    type: string;
}

export interface GetStreamConnectionsResultSecurity {
    /**
     * A trusted, public x509 certificate for connecting to Kafka over SSL. String value of the certificate must be defined in the attribute.
     */
    brokerPublicCertificate: string;
    /**
     * Describes the transport type. Can be either `PLAINTEXT` or `SSL`.
     */
    protocol: string;
}

export interface GetStreamInstanceDataProcessRegion {
    /**
     * Label that identifies the cloud service provider where MongoDB Cloud performs stream processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    cloudProvider: string;
    /**
     * Name of the cloud provider region hosting Atlas Stream Processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    region: string;
}

export interface GetStreamInstanceStreamConfig {
    /**
     * Selected tier for the Stream Instance. Configures Memory / VCPU allowances. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    tier: string;
}

export interface GetStreamInstancesResult {
    /**
     * Defines the cloud service provider and region where MongoDB Cloud performs stream processing. See data process region.
     */
    dataProcessRegion: outputs.GetStreamInstancesResultDataProcessRegion;
    /**
     * List that contains the hostnames assigned to the stream instance.
     */
    hostnames: string[];
    id: string;
    /**
     * Human-readable label that identifies the stream instance.
     */
    instanceName: string;
    /**
     * Unique 24-hexadecimal digit string that identifies your project.
     */
    projectId: string;
    /**
     * Defines the configuration options for an Atlas Stream Processing Instance. See stream config
     */
    streamConfig: outputs.GetStreamInstancesResultStreamConfig;
}

export interface GetStreamInstancesResultDataProcessRegion {
    /**
     * Label that identifies the cloud service provider where MongoDB Cloud performs stream processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    cloudProvider: string;
    /**
     * Name of the cloud provider region hosting Atlas Stream Processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    region: string;
}

export interface GetStreamInstancesResultStreamConfig {
    /**
     * Selected tier for the Stream Instance. Configures Memory / VCPU allowances. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    tier: string;
}

export interface GetThirdPartyIntegrationsResult {
    accountId: string;
    /**
     * Your API Key.
     */
    apiKey: string;
    channelName: string;
    /**
     * Whether your cluster has Prometheus enabled.
     */
    enabled?: boolean;
    /**
     * Unique identifier of the integration.
     */
    id: string;
    /**
     * Your Microsoft Teams incoming webhook URL.
     */
    microsoftTeamsWebhookUrl?: string;
    /**
     * The unique ID for the project to get all Third-Party service integrations
     */
    projectId: string;
    /**
     * Two-letter code that indicates which API URL to use. See the `region` response field of [MongoDB API Third-Party Service Integration documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/v2/#tag/Third-Party-Integrations/operation/getThirdPartyIntegration) for more details. Opsgenie will use US by default.
     */
    region: string;
    /**
     * An optional field for your Routing Key.
     */
    routingKey: string;
    /**
     * Your Prometheus protocol scheme configured for requests. **Note** This attribute is deprecated as it is not being used.
     *
     * @deprecated This parameter is deprecated and will be removed in version 1.18.0.
     */
    scheme?: string;
    /**
     * An optional field for your webhook secret.
     */
    secret: string;
    /**
     * Indicates which service discovery method is used, either file or http.
     */
    serviceDiscovery?: string;
    /**
     * Your Service Key.
     */
    serviceKey: string;
    teamName: string;
    /**
     * Thirt-Party service integration type.
     */
    type: string;
    /**
     * Your webhook URL.
     */
    url: string;
    /**
     * Your Prometheus username.
     */
    userName?: string;
}

export interface GetX509AuthenticationDatabaseUserCertificate {
    createdAt: string;
    groupId: string;
    id: number;
    notAfter: string;
    subject: string;
}

export interface GlobalClusterConfigCustomZoneMapping {
    location: string;
    zone: string;
}

export interface GlobalClusterConfigManagedNamespace {
    collection: string;
    customShardKey: string;
    db: string;
    isCustomShardKeyHashed: boolean;
    isShardKeyUnique: boolean;
}

export interface LdapConfigurationUserToDnMapping {
    ldapQuery: string;
    match: string;
    substitution: string;
}

export interface LdapVerifyLink {
    href: string;
    rel: string;
}

export interface LdapVerifyValidation {
    /**
     * The current status of the LDAP over TLS/SSL configuration. One of the following values: `PENDING`, `SUCCESS`, and `FAILED`.
     */
    status: string;
    validationType: string;
}

export interface OnlineArchiveCriteria {
    /**
     * Indexed database parameter that stores the date that determines when data moves to the online archive. MongoDB Cloud archives the data when the current date exceeds the date in this database parameter plus the number of days specified through the expireAfterDays parameter.
     */
    dateField?: string;
    /**
     * Syntax used to write the date after which data moves to the online archive. Date can be expressed as ISO 8601 or Epoch timestamps. The Epoch timestamp can be expressed as nanoseconds, milliseconds, or seconds. You must set `type` to `DATE` if `collectionType` is `TIMESERIES`. Valid values:  ISODATE (default), EPOCH_SECONDS, EPOCH_MILLIS, EPOCH_NANOSECONDS.
     */
    dateFormat: string;
    /**
     * Number of days after the value in the criteria.dateField when MongoDB Cloud archives data in the specified cluster.
     *
     * **_NOTE: if `DATE` is selected, the `partition_fields.field_name` must be completed with the `dateField` value_**
     *
     * The only field required for criteria type `CUSTOM`
     */
    expireAfterDays?: number;
    /**
     * JSON query to use to select documents for archiving. Atlas uses the specified query with the db.collection.find(query) command. The empty document {} to return all documents is not supported.
     */
    query?: string;
    /**
     * Type of criteria (DATE, CUSTOM)
     *
     * The following fields are required for criteria type `DATE`
     */
    type: string;
}

export interface OnlineArchiveDataExpirationRule {
    /**
     * Number of days used in the date criteria for nominating documents for deletion. Value must be between 7 and 9215.
     */
    expireAfterDays: number;
}

export interface OnlineArchiveDataProcessRegion {
    /**
     * Human-readable label that identifies the Cloud service provider where you wish to store your archived data. `AZURE` may be selected only if Azure is the Cloud service provider for the cluster and no AWS online archive has been created for the cluster.
     */
    cloudProvider: string;
    /**
     * Human-readable label that identifies the geographic location of the region where you wish to store your archived data. For allowed values, see [MongoDB Atlas API documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/v2/#tag/Online-Archive/operation/createOnlineArchive)
     */
    region: string;
}

export interface OnlineArchivePartitionField {
    fieldName: string;
    fieldType: string;
    order: number;
}

export interface OnlineArchiveSchedule {
    /**
     * Day of the month when the scheduled archive starts. This field should be provided only when schedule `type` is `MONTHLY`.
     */
    dayOfMonth?: number;
    /**
     * Day of the week when the scheduled archive starts. The week starts with Monday (1) and ends with Sunday (7). This field should be provided only when schedule `type` is `WEEKLY`.
     */
    dayOfWeek?: number;
    /**
     * Hour of the day when the scheduled window to run one online archive ends.
     */
    endHour?: number;
    /**
     * Minute of the hour when the scheduled window to run one online archive ends.
     */
    endMinute?: number;
    /**
     * Hour of the day when the when the scheduled window to run one online archive starts.
     */
    startHour?: number;
    /**
     * Minute of the hour when the scheduled window to run one online archive starts.
     */
    startMinute?: number;
    /**
     * Type of schedule (``DAILY`, `MONTHLY`, `WEEKLY`).
     */
    type: string;
}

export interface PrivateLinkEndpointServiceEndpoint {
    /**
     * Forwarding rule that corresponds to the endpoint you created in GCP.
     */
    endpointName?: string;
    /**
     * Private IP address of the endpoint you created in GCP.
     */
    ipAddress?: string;
    /**
     * Unique alphanumeric and special character strings that identify the service attachment associated with the endpoint.
     */
    serviceAttachmentName: string;
    /**
     * Status of the endpoint. Atlas returns one of the [values shown above](https://docs.atlas.mongodb.com/reference/api/private-endpoints-endpoint-create-one/#std-label-ref-status-field).
     */
    status: string;
}

export interface ProjectApiKeyProjectAssignment {
    /**
     * Project ID to assign to Access Key
     */
    projectId: string;
    /**
     * List of Project roles that the Programmatic API key needs to have. Ensure you provide: at least one role and ensure all roles are valid for the Project. You must specify an array even if you are only associating a single role with the Programmatic API key. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#project-roles) describes the valid roles that can be assigned.
     */
    roleNames: string[];
}

export interface ProjectIpAccessListTimeouts {
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
     */
    delete?: string;
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Read operations occur during any refresh or planning operation when refresh is enabled.
     */
    read?: string;
}

export interface ProjectIpAddresses {
    services: outputs.ProjectIpAddressesServices;
}

export interface ProjectIpAddressesServices {
    clusters: outputs.ProjectIpAddressesServicesCluster[];
}

export interface ProjectIpAddressesServicesCluster {
    clusterName: string;
    inbounds: string[];
    outbounds: string[];
}

export interface ProjectLimit {
    currentUsage: number;
    defaultLimit: number;
    maximumLimit: number;
    /**
     * Human-readable label that identifies this project limit. See [Project Limit Documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Projects/operation/setProjectLimit) under `limitName` parameter to find all the limits that can be defined.
     */
    name: string;
    /**
     * Amount to set the limit to. Use the [Project Limit Documentation](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Projects/operation/setProjectLimit) under `limitName` parameter to verify the override limits.
     */
    value: number;
}

export interface ProjectTeam {
    /**
     * Each string in the array represents a project role you want to assign to the team. Every user associated with the team inherits these roles. You must specify an array even if you are only associating a single role with the team. The [MongoDB Documentation](https://www.mongodb.com/docs/atlas/reference/user-roles/#organization-roles) describes the roles a user can have.
     *
     * > **NOTE:** Project created by API Keys must belong to an existing organization.
     */
    roleNames: string[];
    /**
     * The unique identifier of the team you want to associate with the project. The team and project must share the same parent organization.
     */
    teamId: string;
}

export interface PushBasedLogExportTimeouts {
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
     */
    create?: string;
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
     */
    delete?: string;
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
     */
    update?: string;
}

export interface SearchDeploymentSpec {
    /**
     * Hardware specification for the search node instance sizes. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Atlas-Search/operation/createAtlasSearchDeployment) describes the valid values. More details can also be found in the [Search Node Documentation](https://www.mongodb.com/docs/atlas/cluster-config/multi-cloud-distribution/#search-tier).
     */
    instanceSize: string;
    /**
     * Number of search nodes in the cluster.
     */
    nodeCount: number;
}

export interface SearchDeploymentTimeouts {
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
     */
    create?: string;
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
     */
    delete?: string;
    /**
     * A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
     */
    update?: string;
}

export interface SearchIndexSynonym {
    /**
     * [Analyzer](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/#std-label-analyzers-ref) to use when creating the index. Defaults to [lucene.standard](https://docs.atlas.mongodb.com/reference/atlas-search/analyzers/standard/#std-label-ref-standard-analyzer)
     */
    analyzer: string;
    /**
     * The name of the search index you want to create.
     */
    name: string;
    /**
     * (Required) Name of the source MongoDB collection for the synonyms. Documents in this collection must be in the format described in the [Synonyms Source Collection Documents](https://docs.atlas.mongodb.com/reference/atlas-search/synonyms/#std-label-synonyms-coll-spec).
     */
    sourceCollection: string;
}

export interface ServerlessInstanceLink {
    href: string;
    rel: string;
}

export interface ServerlessInstanceTag {
    /**
     * Constant that defines the set of the tag.
     */
    key: string;
    /**
     * Variable that belongs to the set of the tag.
     *
     * To learn more, see [Resource Tags](https://dochub.mongodb.org/core/add-cluster-tag-atlas).
     */
    value: string;
}

export interface StreamConnectionAuthentication {
    /**
     * Style of authentication. Can be one of `PLAIN`, `SCRAM-256`, or `SCRAM-512`.
     */
    mechanism?: string;
    /**
     * Password of the account to connect to the Kafka cluster.
     */
    password?: string;
    /**
     * Username of the account to connect to the Kafka cluster.
     */
    username?: string;
}

export interface StreamConnectionDbRoleToExecute {
    role: string;
    /**
     * Type of connection. Can be either `Cluster`, `Kafka` or `Sample`.
     */
    type: string;
}

export interface StreamConnectionSecurity {
    /**
     * A trusted, public x509 certificate for connecting to Kafka over SSL. String value of the certificate must be defined in the attribute.
     */
    brokerPublicCertificate?: string;
    /**
     * Describes the transport type. Can be either `PLAINTEXT` or `SSL`.
     */
    protocol?: string;
}

export interface StreamInstanceDataProcessRegion {
    /**
     * Label that identifies the cloud service provider where MongoDB Cloud performs stream processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    cloudProvider: string;
    /**
     * Name of the cloud provider region hosting Atlas Stream Processing. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    region: string;
}

export interface StreamInstanceStreamConfig {
    /**
     * Selected tier for the Stream Instance. Configures Memory / VCPU allowances. The [MongoDB Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Streams/operation/createStreamInstance) describes the valid values.
     */
    tier: string;
}

export interface X509AuthenticationDatabaseUserCertificate {
    createdAt: string;
    groupId: string;
    id: number;
    notAfter: string;
    subject: string;
}

export namespace config {
    export interface AssumeRole {
        /**
         * The duration, between 15 minutes and 12 hours, of the role session. Valid time units are ns, us (or µs), ms, s, h, or m.
         */
        duration?: string;
        /**
         * A unique identifier that might be required when you assume a role in another account.
         */
        externalId?: string;
        /**
         * IAM Policy JSON describing further restricting permissions for the IAM Role being assumed.
         */
        policy?: string;
        /**
         * Amazon Resource Names (ARNs) of IAM Policies describing further restricting permissions for the IAM Role being assumed.
         */
        policyArns?: string[];
        /**
         * Amazon Resource Name (ARN) of an IAM Role to assume prior to making API calls.
         */
        roleArn?: string;
        /**
         * An identifier for the assumed role session.
         */
        sessionName?: string;
        /**
         * Source identity specified by the principal assuming the role.
         */
        sourceIdentity?: string;
        /**
         * Assume role session tags.
         */
        tags?: {[key: string]: string};
        /**
         * Assume role session tag keys to pass to any subsequent sessions.
         */
        transitiveTagKeys?: string[];
    }

}
