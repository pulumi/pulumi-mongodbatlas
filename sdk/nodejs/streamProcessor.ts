// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * `mongodbatlas.StreamProcessor` provides a Stream Processor resource. The resource lets you create, delete, import, start and stop a stream processor in a stream instance.
 *
 * **NOTE**: When updating an Atlas Stream Processor, the following behavior applies:
 * 1. If the processor is in a `STARTED` state, it will automatically be stopped before the update is applied
 * 2. The update will be performed while the processor is in `STOPPED` state
 * 3. If the processor was originally in `STARTED` state, it will be restarted after the update
 *
 * ## Example Usage
 *
 * ### S
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as mongodbatlas from "@pulumi/mongodbatlas";
 *
 * const example = new mongodbatlas.StreamInstance("example", {
 *     projectId: projectId,
 *     instanceName: "InstanceName",
 *     dataProcessRegion: {
 *         region: "VIRGINIA_USA",
 *         cloudProvider: "AWS",
 *     },
 * });
 * const example_sample = new mongodbatlas.StreamConnection("example-sample", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     connectionName: "sample_stream_solar",
 *     type: "Sample",
 * });
 * const example_cluster = new mongodbatlas.StreamConnection("example-cluster", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     connectionName: "ClusterConnection",
 *     type: "Cluster",
 *     clusterName: clusterName,
 *     dbRoleToExecute: {
 *         role: "atlasAdmin",
 *         type: "BUILT_IN",
 *     },
 * });
 * const example_kafka = new mongodbatlas.StreamConnection("example-kafka", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     connectionName: "KafkaPlaintextConnection",
 *     type: "Kafka",
 *     authentication: {
 *         mechanism: "PLAIN",
 *         username: kafkaUsername,
 *         password: kafkaPassword,
 *     },
 *     bootstrapServers: "localhost:9092,localhost:9092",
 *     config: {
 *         "auto.offset.reset": "earliest",
 *     },
 *     security: {
 *         protocol: "SASL_PLAINTEXT",
 *     },
 * });
 * const stream_processor_sample_example = new mongodbatlas.StreamProcessor("stream-processor-sample-example", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     processorName: "sampleProcessorName",
 *     pipeline: JSON.stringify([
 *         {
 *             $source: {
 *                 connectionName: mongodbatlasStreamConnection["example-sample"].connectionName,
 *             },
 *         },
 *         {
 *             $emit: {
 *                 connectionName: mongodbatlasStreamConnection["example-cluster"].connectionName,
 *                 db: "sample",
 *                 coll: "solar",
 *                 timeseries: {
 *                     timeField: "_ts",
 *                 },
 *             },
 *         },
 *     ]),
 *     state: "STARTED",
 *     tier: "SP30",
 * });
 * const stream_processor_cluster_to_kafka_example = new mongodbatlas.StreamProcessor("stream-processor-cluster-to-kafka-example", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     processorName: "clusterProcessorName",
 *     pipeline: JSON.stringify([
 *         {
 *             $source: {
 *                 connectionName: mongodbatlasStreamConnection["example-cluster"].connectionName,
 *             },
 *         },
 *         {
 *             $emit: {
 *                 connectionName: mongodbatlasStreamConnection["example-kafka"].connectionName,
 *                 topic: "topic_from_cluster",
 *             },
 *         },
 *     ]),
 *     state: "CREATED",
 * });
 * const stream_processor_kafka_to_cluster_example = new mongodbatlas.StreamProcessor("stream-processor-kafka-to-cluster-example", {
 *     projectId: projectId,
 *     workspaceName: example.instanceName,
 *     processorName: "kafkaProcessorName",
 *     pipeline: JSON.stringify([
 *         {
 *             $source: {
 *                 connectionName: mongodbatlasStreamConnection["example-kafka"].connectionName,
 *                 topic: "topic_source",
 *             },
 *         },
 *         {
 *             $emit: {
 *                 connectionName: mongodbatlasStreamConnection["example-cluster"].connectionName,
 *                 db: "kafka",
 *                 coll: "topic_source",
 *                 timeseries: {
 *                     timeField: "ts",
 *                 },
 *             },
 *         },
 *     ]),
 *     state: "CREATED",
 *     options: {
 *         dlq: {
 *             coll: "exampleColumn",
 *             connectionName: mongodbatlasStreamConnection["example-cluster"].connectionName,
 *             db: "exampleDb",
 *         },
 *     },
 * });
 * const example_stream_processors = example.instanceName.apply(instanceName => mongodbatlas.getStreamProcessorsOutput({
 *     projectId: projectId,
 *     workspaceName: instanceName,
 * }));
 * const example_stream_processor = pulumi.all([example.instanceName, stream_processor_sample_example.processorName]).apply(([instanceName, processorName]) => mongodbatlas.getStreamProcessorOutput({
 *     projectId: projectId,
 *     workspaceName: instanceName,
 *     processorName: processorName,
 * }));
 * export const streamProcessorsState = example_stream_processor.apply(example_stream_processor => example_stream_processor.state);
 * export const streamProcessorsResults = example_stream_processors.apply(example_stream_processors => example_stream_processors.results);
 * ```
 *
 * ### Further Examples
 * - Atlas Stream Processor
 *
 * ## Import
 *
 * Stream Processor resource can be imported using the Project ID, Stream Instance name and Stream Processor name, in the format `INSTANCE_NAME-PROJECT_ID-PROCESSOR_NAME`, e.g.
 *
 * For more information see: [MongoDB Atlas API - Stream Processor](https://www.mongodb.com/docs/api/doc/atlas-admin-api-v2/operation/operation-createstreamprocessor) Documentation.
 */
export class StreamProcessor extends pulumi.CustomResource {
    /**
     * Get an existing StreamProcessor resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: StreamProcessorState, opts?: pulumi.CustomResourceOptions): StreamProcessor {
        return new StreamProcessor(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'mongodbatlas:index/streamProcessor:StreamProcessor';

    /**
     * Returns true if the given object is an instance of StreamProcessor.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is StreamProcessor {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === StreamProcessor.__pulumiType;
    }

    /**
     * Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
     */
    declare public readonly deleteOnCreateTimeout: pulumi.Output<boolean>;
    /**
     * Label that identifies the stream processing workspace.
     *
     * @deprecated This parameter is deprecated. Please transition to workspace_name.
     */
    declare public readonly instanceName: pulumi.Output<string | undefined>;
    /**
     * Optional configuration for the stream processor.
     */
    declare public readonly options: pulumi.Output<outputs.StreamProcessorOptions | undefined>;
    /**
     * Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
     */
    declare public readonly pipeline: pulumi.Output<string>;
    /**
     * Label that identifies the stream processor.
     */
    declare public readonly processorName: pulumi.Output<string>;
    /**
     * Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
     */
    declare public readonly projectId: pulumi.Output<string>;
    /**
     * The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
     *
     * **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
     */
    declare public readonly state: pulumi.Output<string>;
    /**
     * The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
     */
    declare public /*out*/ readonly stats: pulumi.Output<string>;
    /**
     * Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
     */
    declare public readonly tier: pulumi.Output<string>;
    declare public readonly timeouts: pulumi.Output<outputs.StreamProcessorTimeouts | undefined>;
    /**
     * Label that identifies the stream processing workspace.
     */
    declare public readonly workspaceName: pulumi.Output<string | undefined>;

    /**
     * Create a StreamProcessor resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: StreamProcessorArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: StreamProcessorArgs | StreamProcessorState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as StreamProcessorState | undefined;
            resourceInputs["deleteOnCreateTimeout"] = state?.deleteOnCreateTimeout;
            resourceInputs["instanceName"] = state?.instanceName;
            resourceInputs["options"] = state?.options;
            resourceInputs["pipeline"] = state?.pipeline;
            resourceInputs["processorName"] = state?.processorName;
            resourceInputs["projectId"] = state?.projectId;
            resourceInputs["state"] = state?.state;
            resourceInputs["stats"] = state?.stats;
            resourceInputs["tier"] = state?.tier;
            resourceInputs["timeouts"] = state?.timeouts;
            resourceInputs["workspaceName"] = state?.workspaceName;
        } else {
            const args = argsOrState as StreamProcessorArgs | undefined;
            if (args?.pipeline === undefined && !opts.urn) {
                throw new Error("Missing required property 'pipeline'");
            }
            if (args?.processorName === undefined && !opts.urn) {
                throw new Error("Missing required property 'processorName'");
            }
            if (args?.projectId === undefined && !opts.urn) {
                throw new Error("Missing required property 'projectId'");
            }
            resourceInputs["deleteOnCreateTimeout"] = args?.deleteOnCreateTimeout;
            resourceInputs["instanceName"] = args?.instanceName;
            resourceInputs["options"] = args?.options;
            resourceInputs["pipeline"] = args?.pipeline;
            resourceInputs["processorName"] = args?.processorName;
            resourceInputs["projectId"] = args?.projectId;
            resourceInputs["state"] = args?.state;
            resourceInputs["tier"] = args?.tier;
            resourceInputs["timeouts"] = args?.timeouts;
            resourceInputs["workspaceName"] = args?.workspaceName;
            resourceInputs["stats"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(StreamProcessor.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering StreamProcessor resources.
 */
export interface StreamProcessorState {
    /**
     * Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
     */
    deleteOnCreateTimeout?: pulumi.Input<boolean>;
    /**
     * Label that identifies the stream processing workspace.
     *
     * @deprecated This parameter is deprecated. Please transition to workspace_name.
     */
    instanceName?: pulumi.Input<string>;
    /**
     * Optional configuration for the stream processor.
     */
    options?: pulumi.Input<inputs.StreamProcessorOptions>;
    /**
     * Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
     */
    pipeline?: pulumi.Input<string>;
    /**
     * Label that identifies the stream processor.
     */
    processorName?: pulumi.Input<string>;
    /**
     * Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
     */
    projectId?: pulumi.Input<string>;
    /**
     * The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
     *
     * **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
     */
    state?: pulumi.Input<string>;
    /**
     * The stats associated with the stream processor. Refer to the [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/manage-stream-processor/#view-statistics-of-a-stream-processor) for more information.
     */
    stats?: pulumi.Input<string>;
    /**
     * Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
     */
    tier?: pulumi.Input<string>;
    timeouts?: pulumi.Input<inputs.StreamProcessorTimeouts>;
    /**
     * Label that identifies the stream processing workspace.
     */
    workspaceName?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a StreamProcessor resource.
 */
export interface StreamProcessorArgs {
    /**
     * Indicates whether to delete the resource being created if a timeout is reached when waiting for completion. When set to `true` and timeout occurs, it triggers the deletion and returns immediately without waiting for deletion to complete. When set to `false`, the timeout will not trigger resource deletion. If you suspect a transient error when the value is `true`, wait before retrying to allow resource deletion to finish. Default is `true`.
     */
    deleteOnCreateTimeout?: pulumi.Input<boolean>;
    /**
     * Label that identifies the stream processing workspace.
     *
     * @deprecated This parameter is deprecated. Please transition to workspace_name.
     */
    instanceName?: pulumi.Input<string>;
    /**
     * Optional configuration for the stream processor.
     */
    options?: pulumi.Input<inputs.StreamProcessorOptions>;
    /**
     * Stream aggregation pipeline you want to apply to your streaming data. [MongoDB Atlas Docs](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/#std-label-stream-aggregation) contain more information. Using jsonencode is recommended when setting this attribute. For more details see the [Aggregation Pipelines Documentation](https://www.mongodb.com/docs/atlas/atlas-stream-processing/stream-aggregation/)
     */
    pipeline: pulumi.Input<string>;
    /**
     * Label that identifies the stream processor.
     */
    processorName: pulumi.Input<string>;
    /**
     * Unique 24-hexadecimal digit string that identifies your project. Use the /groups endpoint to retrieve all projects to which the authenticated user has access.
     */
    projectId: pulumi.Input<string>;
    /**
     * The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'. Used to start or stop the Stream Processor. Valid values are `CREATED`, `STARTED` or `STOPPED`. When a Stream Processor is created without specifying the state, it will default to `CREATED` state. When a Stream Processor is updated without specifying the state, it will default to the Previous state. 
     *
     * **NOTE** When a Stream Processor is updated without specifying the state, it is stopped and then restored to previous state upon update completion.
     */
    state?: pulumi.Input<string>;
    /**
     * Selected tier to start a stream processor on rather than defaulting to the workspace setting. Configures Memory / VCPU allowances. Valid options are SP2, SP5, SP10, SP30, and SP50.
     */
    tier?: pulumi.Input<string>;
    timeouts?: pulumi.Input<inputs.StreamProcessorTimeouts>;
    /**
     * Label that identifies the stream processing workspace.
     */
    workspaceName?: pulumi.Input<string>;
}
